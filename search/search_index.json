{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Regulatory AI Docs Welcome to the Regulatory AI Docs \u2014 the official documentation for the Regulatory AI backend and AI-assisted regulatory automation workflows. This site provides comprehensive guidance for developers, operators, and contributors to understand, extend, and operate the system. \ud83d\udd17 Quick Links Getting Started \u2014 Learn how to set up and run the development environment locally. API Reference \u2014 Overview of all REST endpoints, their inputs/outputs, and workflows. Database & Schemas \u2014 Explanation of storage layers, data models, and response structures. AI Backend \u2014 Details on workflow chains, agents, graph nodes, prompts, and output models. FAQ \u2014 Common questions, troubleshooting, and environment notes. \u2699\ufe0f About Regulatory AI Regulatory AI is a backend-first orchestration platform designed to automate regulatory engineering tasks for medical devices. It integrates: FastAPI for service endpoints Modular Chains & Agents to manage workflows Pluggable LLM Providers for intelligent reasoning and document generation Memory Layers (Milvus, Redis) for context awareness Graph Knowledge Nodes (Neo4j) for structured regulatory logic Domain-specific generators for GSPR, design inputs/outputs, risk evaluation, and standards mapping It transforms device information into regulatory-ready documentation using multi-agent processing pipelines. \ud83d\ude80 Core Capabilities Multi-stage workflow pipelines with agents and graph nodes GSPR generation with applicability and justification logic Risk and classification modeling (FDA/MDR) Device component recommendation using controlled vocabularies Design input/output generation with traceability Standards mapping and alignment (ISO, IEC, MDR) Biocompatibility, cybersecurity, human factors, and performance requirement generation Configurable LLM backends with prompt and temperature management \ud83e\uddd1\u200d\ud83d\udcbb Quick Start Clone the repository. Start the development stack with Docker or local Python environment. Run FastAPI and explore the system using interactive endpoints. Detailed setup instructions are provided in the documentation. \ud83e\udd1d Contributing Contributions can include: New chains or workflow modules Enhanced LLM prompts or logic Additional API routes Integrations with services or models Documentation improvements Before submitting PRs, ensure tests pass, code is linted, and descriptions are clear. \ud83d\udccd Recommended Next Steps Explore system architecture for component responsibilities Run the dev stack to see workflows in action Examine workflow chains and agents to understand orchestration logic For support, open an issue with reproduction steps or contact maintainers.","title":"Home"},{"location":"#regulatory-ai-docs","text":"Welcome to the Regulatory AI Docs \u2014 the official documentation for the Regulatory AI backend and AI-assisted regulatory automation workflows. This site provides comprehensive guidance for developers, operators, and contributors to understand, extend, and operate the system.","title":"Regulatory AI Docs"},{"location":"#quick-links","text":"Getting Started \u2014 Learn how to set up and run the development environment locally. API Reference \u2014 Overview of all REST endpoints, their inputs/outputs, and workflows. Database & Schemas \u2014 Explanation of storage layers, data models, and response structures. AI Backend \u2014 Details on workflow chains, agents, graph nodes, prompts, and output models. FAQ \u2014 Common questions, troubleshooting, and environment notes.","title":"\ud83d\udd17 Quick Links"},{"location":"#about-regulatory-ai","text":"Regulatory AI is a backend-first orchestration platform designed to automate regulatory engineering tasks for medical devices. It integrates: FastAPI for service endpoints Modular Chains & Agents to manage workflows Pluggable LLM Providers for intelligent reasoning and document generation Memory Layers (Milvus, Redis) for context awareness Graph Knowledge Nodes (Neo4j) for structured regulatory logic Domain-specific generators for GSPR, design inputs/outputs, risk evaluation, and standards mapping It transforms device information into regulatory-ready documentation using multi-agent processing pipelines.","title":"\u2699\ufe0f About Regulatory AI"},{"location":"#core-capabilities","text":"Multi-stage workflow pipelines with agents and graph nodes GSPR generation with applicability and justification logic Risk and classification modeling (FDA/MDR) Device component recommendation using controlled vocabularies Design input/output generation with traceability Standards mapping and alignment (ISO, IEC, MDR) Biocompatibility, cybersecurity, human factors, and performance requirement generation Configurable LLM backends with prompt and temperature management","title":"\ud83d\ude80 Core Capabilities"},{"location":"#quick-start","text":"Clone the repository. Start the development stack with Docker or local Python environment. Run FastAPI and explore the system using interactive endpoints. Detailed setup instructions are provided in the documentation.","title":"\ud83e\uddd1\u200d\ud83d\udcbb Quick Start"},{"location":"#contributing","text":"Contributions can include: New chains or workflow modules Enhanced LLM prompts or logic Additional API routes Integrations with services or models Documentation improvements Before submitting PRs, ensure tests pass, code is linted, and descriptions are clear.","title":"\ud83e\udd1d Contributing"},{"location":"#recommended-next-steps","text":"Explore system architecture for component responsibilities Run the dev stack to see workflows in action Examine workflow chains and agents to understand orchestration logic For support, open an issue with reproduction steps or contact maintainers.","title":"\ud83d\udccd Recommended Next Steps"},{"location":"ARCHITECTURE_FLOW/","text":"","title":"ARCHITECTURE FLOW"},{"location":"README_FILE/","text":"","title":"README FILE"},{"location":"faq/","text":"\u2753 Frequently Asked Questions (Enhanced) This FAQ compiles common questions from developers, operators, and contributors working with the Regulatory AI platform. Each answer links the reader to relevant modules, configuration files, and best practices to help you navigate the system efficiently. \ud83d\ude80 How do I run the project locally? Recommended: Full Development Stack (Docker Compose) Spin up FastAPI , vector databases, graph engines, storage layers, and middleware in one command: docker-compose -f docker-compose.dev.yaml up --build This method ensures your local environment mirrors staging/production reliably. Advanced: Local Python Execution (for targeted development) If you prefer running only the application layer: python3 -m venv .venv source .venv/bin/activate uvicorn regulatory.app.main:app --reload --host 0.0.0.0 --port 8765 Note: The FastAPI app uses port 8765 , while the dev Dockerfile exposes 8000 internally. Adjust your tooling accordingly. \ud83d\udd10 Where are configuration and secrets stored? Configuration is centralized via environment variables defined in .env* files (e.g., .env.dev ). Core configuration lives in: src/regulatory/app/core/config.py Security Reminder: Never commit secrets. Use Vault, AWS/GCP Secret Manager, or CI/CD secret injection for real deployments. \ud83e\uddea How do I run tests and linters? Use pytest for tests and ruff for formatting/linting. pytest -q ruff check . ruff format . Unit and integration tests are under: tests/ tests/core/ tests/chains/ Run selective tests for faster iteration. \ud83d\udd27 How do I add a new chain, prompt, or model integration? Chains Add new chains to: src/regulatory/chains/ Include tests in: tests/chains/ Prompts Add or modify prompt templates under: src/regulatory/prompts/ src/regulatory/llm/prompts/ Model Integrations Add new LLM or embedding provider adapters in: src/regulatory/services/ Wire new models through: src/regulatory/app/core/config.py For public API routes, register them under: src/regulatory/app/api/routes/ \ud83d\udcc8 Where are logs and how is observability handled? Logs are handled by helper utilities in: src/regulatory/utils/logger/ Docker Compose includes healthchecks, and FastAPI exposes readiness/liveness endpoints. \ud83d\udcda Where should documentation, diagrams, or design notes go? Place all documentation under: src/regulatory/docs/ If the project uses MkDocs, you can update the site structure via: mkdocs.yml Examples include: ARCHITECTURE_FLOW.md API_REFERENCE.md DEV_NOTES.md \ud83e\uddd1\u200d\ud83d\udcbc Who do I contact for help or resource access? Open a GitHub issue or refer to maintainers listed in README.md . When contacting maintainers, include: Command used Logs Environment details Steps to reproduce This speeds up debugging. \ud83d\udee0\ufe0f Troubleshooting \u2014 Common Issues Service unhealthy in Docker Compose Check logs: docker-compose -f docker-compose.dev.yaml logs <service> Sometimes increasing start_period helps. Missing environment variables Double-check .env.dev and required fields in: src/regulatory/app/core/config.py Tests failing due to external services Start dev stack before running integration tests. Use mocks for isolated testing. If the answer isn't here, open an issue or ask in the project chat with: Logs Commands executed System info Folder structure if relevant This ensures fast and effective support.","title":"FAQ"},{"location":"faq/#frequently-asked-questions-enhanced","text":"This FAQ compiles common questions from developers, operators, and contributors working with the Regulatory AI platform. Each answer links the reader to relevant modules, configuration files, and best practices to help you navigate the system efficiently.","title":"\u2753 Frequently Asked Questions (Enhanced)"},{"location":"faq/#how-do-i-run-the-project-locally","text":"","title":"\ud83d\ude80 How do I run the project locally?"},{"location":"faq/#recommended-full-development-stack-docker-compose","text":"Spin up FastAPI , vector databases, graph engines, storage layers, and middleware in one command: docker-compose -f docker-compose.dev.yaml up --build This method ensures your local environment mirrors staging/production reliably.","title":"Recommended: Full Development Stack (Docker Compose)"},{"location":"faq/#advanced-local-python-execution-for-targeted-development","text":"If you prefer running only the application layer: python3 -m venv .venv source .venv/bin/activate uvicorn regulatory.app.main:app --reload --host 0.0.0.0 --port 8765 Note: The FastAPI app uses port 8765 , while the dev Dockerfile exposes 8000 internally. Adjust your tooling accordingly.","title":"Advanced: Local Python Execution (for targeted development)"},{"location":"faq/#where-are-configuration-and-secrets-stored","text":"Configuration is centralized via environment variables defined in .env* files (e.g., .env.dev ). Core configuration lives in: src/regulatory/app/core/config.py Security Reminder: Never commit secrets. Use Vault, AWS/GCP Secret Manager, or CI/CD secret injection for real deployments.","title":"\ud83d\udd10 Where are configuration and secrets stored?"},{"location":"faq/#how-do-i-run-tests-and-linters","text":"Use pytest for tests and ruff for formatting/linting. pytest -q ruff check . ruff format . Unit and integration tests are under: tests/ tests/core/ tests/chains/ Run selective tests for faster iteration.","title":"\ud83e\uddea How do I run tests and linters?"},{"location":"faq/#how-do-i-add-a-new-chain-prompt-or-model-integration","text":"","title":"\ud83d\udd27 How do I add a new chain, prompt, or model integration?"},{"location":"faq/#chains","text":"Add new chains to: src/regulatory/chains/ Include tests in: tests/chains/","title":"Chains"},{"location":"faq/#prompts","text":"Add or modify prompt templates under: src/regulatory/prompts/ src/regulatory/llm/prompts/","title":"Prompts"},{"location":"faq/#model-integrations","text":"Add new LLM or embedding provider adapters in: src/regulatory/services/ Wire new models through: src/regulatory/app/core/config.py For public API routes, register them under: src/regulatory/app/api/routes/","title":"Model Integrations"},{"location":"faq/#where-are-logs-and-how-is-observability-handled","text":"Logs are handled by helper utilities in: src/regulatory/utils/logger/ Docker Compose includes healthchecks, and FastAPI exposes readiness/liveness endpoints.","title":"\ud83d\udcc8 Where are logs and how is observability handled?"},{"location":"faq/#where-should-documentation-diagrams-or-design-notes-go","text":"Place all documentation under: src/regulatory/docs/ If the project uses MkDocs, you can update the site structure via: mkdocs.yml Examples include: ARCHITECTURE_FLOW.md API_REFERENCE.md DEV_NOTES.md","title":"\ud83d\udcda Where should documentation, diagrams, or design notes go?"},{"location":"faq/#who-do-i-contact-for-help-or-resource-access","text":"Open a GitHub issue or refer to maintainers listed in README.md . When contacting maintainers, include: Command used Logs Environment details Steps to reproduce This speeds up debugging.","title":"\ud83e\uddd1\u200d\ud83d\udcbc Who do I contact for help or resource access?"},{"location":"faq/#troubleshooting-common-issues","text":"","title":"\ud83d\udee0\ufe0f Troubleshooting \u2014 Common Issues"},{"location":"faq/#service-unhealthy-in-docker-compose","text":"Check logs: docker-compose -f docker-compose.dev.yaml logs <service> Sometimes increasing start_period helps.","title":"Service unhealthy in Docker Compose"},{"location":"faq/#missing-environment-variables","text":"Double-check .env.dev and required fields in: src/regulatory/app/core/config.py","title":"Missing environment variables"},{"location":"faq/#tests-failing-due-to-external-services","text":"Start dev stack before running integration tests. Use mocks for isolated testing. If the answer isn't here, open an issue or ask in the project chat with: Logs Commands executed System info Folder structure if relevant This ensures fast and effective support.","title":"Tests failing due to external services"},{"location":"getting-started/","text":"Regulatory AI \u2014 Architecture Overview This document presents an enhanced high-level overview of the Regulatory AI system architecture , describing the major components, their roles, and how they work together across development, runtime orchestration, and deployment environments. It is designed to give new contributors a clear mental model of the platform\u2019s structure and workflow. \ud83d\udd27 Core Components 1. API / Application Layer FastAPI backend located at src/regulatory/app/main.py . Exposes REST endpoints, health checks, and serves static assets under /static . Route registration occurs in regulatory.app.api.routes . Centralized configuration via regulatory.app.core.config . Acts as the entry point for all client interactions. 2. Chains & Agents (Business Logic Layer) Primary business workflows live under src/regulatory/chains and src/regulatory/core/agent . Chains orchestrate end-to-end tasks including: prompt construction memory access (read/write) vector/graph lookups LLM inference and output processing Agents encapsulate focused domain logic (e.g., FDA naming, GSPR table generation, risk classification). Enables modular, testable, multi-step orchestration. 3. LLM / Model Layer Model routing, inference helpers, and prompt templates in: src/regulatory/llm src/regulatory/prompts Supports pluggable model backends via service abstractions under: src/regulatory/services Allows runtime switching between OpenAI, local models, or custom providers. 4. Memory & Vector Databases Persistent memories, embeddings, and semantic search layers powered by: Milvus Redis Neo4j (for graph-based context) Configuration and environment bootstrapping in docker-compose.dev.yaml . Enables context-aware reasoning, historical continuity, and semantic clustering. 5. Graph / Knowledge Layer Graph building, nodes, and traversal utilities under: src/regulatory/graph src/regulatory/graph/nodes Supports hierarchical design reasoning, structured GSPR mapping, and dependent workflows. 6. GSPR Logic & Domain Modules Regulatory-specific rules, device logic, and GSPR generation modules in: src/regulatory/models src/regulatory/gspr Includes risk models, GSPR filters, table builders, and JSON mapping utilities. Central to regulatory-compliant documentation generation. 7. Services & Utilities Shared services for: file & PDF parsing structured logging component suggestions validation helpers Located in: src/regulatory/utils src/regulatory/services 8. Infrastructure & Deployment Multi-environment Docker Compose setups: docker-compose.dev.yaml (full local stack: Milvus, MinIO, Redis, Neo4j, MongoDB) docker-compose.stag.yaml for staging Nginx configuration templates at repo root ( nginx.*.conf ). CI-built images deployed behind secure reverse proxies. Logging and logstash helpers under /logs . \ud83d\udd04 Typical Request / Processing Flow Client \u2192 API : Request enters through Nginx or directly to FastAPI. Routing : FastAPI handler validates and forwards request to the appropriate chain or agent. Chain Execution : Build prompts Load memories Process inputs via regulatory logic Database/Graph Interaction : Embeddings search via Milvus Graph context lookup via Neo4j LLM Invocation : Selected backend processes instructions Outputs validated (guard middleware) and optionally persisted Response Assembly : Chain aggregates structured outputs (e.g., GSPR tables) Logs + metrics sent to logging stack Return to Client This multi-stage flow ensures reliability, regulatory consistency, and accurate model-driven outputs. \ud83d\ude80 Deployment Notes Development Use docker-compose.dev.yaml to initialize: Milvus Redis MinIO Neo4j MongoDB Backend service (FastAPI on port 8000) Ideal for full-stack local testing. Staging / Production Build with docker-compose.stag.yaml and Dockerfile.stag . Deploy behind Nginx using nginx.*.conf templates. Integrate CI-based image builds and environment-specific secrets. \ud83d\udcc8 Observability Logs : stored in logs/ with automated rotation in logs/rotated/ . Health Checks : FastAPI exposes /health endpoint. Docker containers include healthcheck definitions. Structured Outputs : GSPR artifacts, design data, and inference logs written to respective stores. \ud83e\udde9 Extending the System Add a New Chain Create a folder under src/regulatory/chains . Add prompts in src/regulatory/prompts . Register chain in API routers or the appropriate agent. Add a New Model Backend Implement service in src/regulatory/services . Register in src/regulatory/app/core/config.py . \ud83d\udcca High-Level Architecture Diagram Client \u2192 Nginx \u2192 FastAPI (Routes) \u2193 Chains / Agents \u2193 [Memory / Vector DB / Graph DB] \u2193 LLM \u2193 Response","title":"Getting Started"},{"location":"getting-started/#regulatory-ai-architecture-overview","text":"This document presents an enhanced high-level overview of the Regulatory AI system architecture , describing the major components, their roles, and how they work together across development, runtime orchestration, and deployment environments. It is designed to give new contributors a clear mental model of the platform\u2019s structure and workflow.","title":"Regulatory AI \u2014 Architecture Overview"},{"location":"getting-started/#core-components","text":"","title":"\ud83d\udd27 Core Components"},{"location":"getting-started/#1-api-application-layer","text":"FastAPI backend located at src/regulatory/app/main.py . Exposes REST endpoints, health checks, and serves static assets under /static . Route registration occurs in regulatory.app.api.routes . Centralized configuration via regulatory.app.core.config . Acts as the entry point for all client interactions.","title":"1. API / Application Layer"},{"location":"getting-started/#2-chains-agents-business-logic-layer","text":"Primary business workflows live under src/regulatory/chains and src/regulatory/core/agent . Chains orchestrate end-to-end tasks including: prompt construction memory access (read/write) vector/graph lookups LLM inference and output processing Agents encapsulate focused domain logic (e.g., FDA naming, GSPR table generation, risk classification). Enables modular, testable, multi-step orchestration.","title":"2. Chains &amp; Agents (Business Logic Layer)"},{"location":"getting-started/#3-llm-model-layer","text":"Model routing, inference helpers, and prompt templates in: src/regulatory/llm src/regulatory/prompts Supports pluggable model backends via service abstractions under: src/regulatory/services Allows runtime switching between OpenAI, local models, or custom providers.","title":"3. LLM / Model Layer"},{"location":"getting-started/#4-memory-vector-databases","text":"Persistent memories, embeddings, and semantic search layers powered by: Milvus Redis Neo4j (for graph-based context) Configuration and environment bootstrapping in docker-compose.dev.yaml . Enables context-aware reasoning, historical continuity, and semantic clustering.","title":"4. Memory &amp; Vector Databases"},{"location":"getting-started/#5-graph-knowledge-layer","text":"Graph building, nodes, and traversal utilities under: src/regulatory/graph src/regulatory/graph/nodes Supports hierarchical design reasoning, structured GSPR mapping, and dependent workflows.","title":"5. Graph / Knowledge Layer"},{"location":"getting-started/#6-gspr-logic-domain-modules","text":"Regulatory-specific rules, device logic, and GSPR generation modules in: src/regulatory/models src/regulatory/gspr Includes risk models, GSPR filters, table builders, and JSON mapping utilities. Central to regulatory-compliant documentation generation.","title":"6. GSPR Logic &amp; Domain Modules"},{"location":"getting-started/#7-services-utilities","text":"Shared services for: file & PDF parsing structured logging component suggestions validation helpers Located in: src/regulatory/utils src/regulatory/services","title":"7. Services &amp; Utilities"},{"location":"getting-started/#8-infrastructure-deployment","text":"Multi-environment Docker Compose setups: docker-compose.dev.yaml (full local stack: Milvus, MinIO, Redis, Neo4j, MongoDB) docker-compose.stag.yaml for staging Nginx configuration templates at repo root ( nginx.*.conf ). CI-built images deployed behind secure reverse proxies. Logging and logstash helpers under /logs .","title":"8. Infrastructure &amp; Deployment"},{"location":"getting-started/#typical-request-processing-flow","text":"Client \u2192 API : Request enters through Nginx or directly to FastAPI. Routing : FastAPI handler validates and forwards request to the appropriate chain or agent. Chain Execution : Build prompts Load memories Process inputs via regulatory logic Database/Graph Interaction : Embeddings search via Milvus Graph context lookup via Neo4j LLM Invocation : Selected backend processes instructions Outputs validated (guard middleware) and optionally persisted Response Assembly : Chain aggregates structured outputs (e.g., GSPR tables) Logs + metrics sent to logging stack Return to Client This multi-stage flow ensures reliability, regulatory consistency, and accurate model-driven outputs.","title":"\ud83d\udd04 Typical Request / Processing Flow"},{"location":"getting-started/#deployment-notes","text":"","title":"\ud83d\ude80 Deployment Notes"},{"location":"getting-started/#development","text":"Use docker-compose.dev.yaml to initialize: Milvus Redis MinIO Neo4j MongoDB Backend service (FastAPI on port 8000) Ideal for full-stack local testing.","title":"Development"},{"location":"getting-started/#staging-production","text":"Build with docker-compose.stag.yaml and Dockerfile.stag . Deploy behind Nginx using nginx.*.conf templates. Integrate CI-based image builds and environment-specific secrets.","title":"Staging / Production"},{"location":"getting-started/#observability","text":"Logs : stored in logs/ with automated rotation in logs/rotated/ . Health Checks : FastAPI exposes /health endpoint. Docker containers include healthcheck definitions. Structured Outputs : GSPR artifacts, design data, and inference logs written to respective stores.","title":"\ud83d\udcc8 Observability"},{"location":"getting-started/#extending-the-system","text":"","title":"\ud83e\udde9 Extending the System"},{"location":"getting-started/#add-a-new-chain","text":"Create a folder under src/regulatory/chains . Add prompts in src/regulatory/prompts . Register chain in API routers or the appropriate agent.","title":"Add a New Chain"},{"location":"getting-started/#add-a-new-model-backend","text":"Implement service in src/regulatory/services . Register in src/regulatory/app/core/config.py .","title":"Add a New Model Backend"},{"location":"getting-started/#high-level-architecture-diagram","text":"Client \u2192 Nginx \u2192 FastAPI (Routes) \u2193 Chains / Agents \u2193 [Memory / Vector DB / Graph DB] \u2193 LLM \u2193 Response","title":"\ud83d\udcca High-Level Architecture Diagram"},{"location":"ai_backend/agents/","text":"\ud83d\udda5\ufe0f Core Agents \u2014 Intelligent Regulatory Automation Modules \ud83c\udfe5 FDA Name Agent \u2014 Map Device Names to FDA Terminology Automatically interprets user-provided device names and maps them to official FDA-recognized nomenclature . Supports classification, regulatory lookup, and component selection with high accuracy \ud83e\udde0\ud83d\udcda. FDAAgent Initialize the FDAAgent for device name suggestions. The FDAAgent integrates with OpenAI embeddings and a Milvus vector store to provide device name suggestions based on similarity search and language model processing. Raises: Type Description ValueError If required environment variables (OPENAI_API_KEY, MILVUS_COLLECTION, Source code in core/agent/FDA_nameAgent.py 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 class FDAAgent : \"\"\" Initialize the FDAAgent for device name suggestions. The FDAAgent integrates with OpenAI embeddings and a Milvus vector store to provide device name suggestions based on similarity search and language model processing. Raises: ValueError: If required environment variables (OPENAI_API_KEY, MILVUS_COLLECTION, MILVUS_HOST/URI, MILVUS_PORT) are not set. \"\"\" def __init__ ( self ): self . embeddings = OpenAIEmbeddings ( api_key = SecretStr ( api_key ) if api_key is not None else None , ) collection_name = os . getenv ( \"MILVUS_COLLECTION\" ) if not collection_name : raise ValueError ( \"MILVUS_COLLECTION environment variable is not set.\" ) # Prefer full URI if explicitly provided milvus_uri = os . getenv ( \"MILVUS_URI\" ) if not milvus_uri : milvus_host = os . getenv ( \"MILVUS_HOST\" , \"localhost\" ) if not milvus_host : raise ValueError ( \"MILVUS_HOST environment variable is not set.\" ) milvus_port = os . getenv ( \"MILVUS_PORT\" , \"19530\" ) if not milvus_port : raise ValueError ( \"MILVUS_PORT environment variable is not set.\" ) milvus_uri = f \"http:// { milvus_host } : { milvus_port } \" self . vector_store = Milvus ( embedding_function = self . embeddings , collection_name = collection_name , connection_args = { \"uri\" : milvus_uri }, auto_id = True , # Set to True to match previous script behavior ) self . llm = ChatOpenAI ( temperature = 0 , model = \"gpt-4o-mini\" ) \"\"\" Retrieve device name suggestions based on input criteria. This method performs a similarity search in the Milvus vector store using the provided device name, then refines the results using a language model to generate structured suggestions. Args: device_name (str): The name of the device to search for. intended_purpose (str): The intended purpose of the device. Returns: dict: A dictionary containing a list of relevant device names. Example: agent = FDAAgent() suggestions = agent.get_suggestions(\"Pacemaker\", \"Heart rhythm management\") Response: { \"relevant_device_names\": [\"Cardiac Pacemaker\", \"Implantable Pacemaker\"] } \"\"\" def get_suggestions ( self , device_name : str , intended_purpose : str ) -> dict : results = self . vector_store . similarity_search ( device_name , k = 10 ) if not results : return { \"relevant_device_names\" : []} # Extract device names device_names = [] seen = set () for doc in results : name = doc . metadata . get ( \"device_name\" , doc . page_content ) if name and name not in seen : device_names . append ( name ) seen . add ( name ) # Pass both device_name & intended_purpose to LLM prompt = FDA_prompt . format ( device_name = device_name , intended_purpose = intended_purpose , device_names = device_names , ) structured_llm = self . llm . with_structured_output ( DeviceSuggestion ) response = structured_llm . invoke ( prompt ) return response \ud83d\udcca GSPR Table Agent \u2014 Build & Maintain Compliance Tables Generates structured GSPR compliance tables , aligning clauses with evidence, standards, and device parameters. Ensures traceability and MDR-ready documentation for audits and submissions \ud83d\udcc4\ud83d\udd0d. Project: Regulatory AI Backend Description: GSPRTableAgent orchestrates the GSPR generation workflow using LangTable. GSPRGraphRunner GSPRGraphRunner orchestrates the full GSPR generation workflow via GSPRGraph. It bridges FastAPI's background job system with the LLM-based regulatory reasoning pipeline defined under src/regulatory . Responsibilities: - Fetch context & state from Redis session - Execute LangGraph-based bulk generation for all sections - Publish real-time job progress via Redis Pub/Sub - Handle failures and provide comprehensive results Parameters: Name Type Description Default session_id str Unique identifier for the Redis session. required job_id str Unique identifier for the job. required component_name str Name of the component being processed. required requirement_sections dict Requirement sections to process. required concurrency_limit int Maximum number of concurrent tasks (default: 15). 15 Source code in core/agent/gspr_tableAgent.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 class GSPRGraphRunner : \"\"\" GSPRGraphRunner orchestrates the full GSPR generation workflow via GSPRGraph. It bridges FastAPI's background job system with the LLM-based regulatory reasoning pipeline defined under `src/regulatory`. Responsibilities: - Fetch context & state from Redis session - Execute LangGraph-based bulk generation for all sections - Publish real-time job progress via Redis Pub/Sub - Handle failures and provide comprehensive results Args: session_id (str): Unique identifier for the Redis session. job_id (str): Unique identifier for the job. component_name (str): Name of the component being processed. requirement_sections (dict): Requirement sections to process. concurrency_limit (int): Maximum number of concurrent tasks (default: 15). \"\"\" def __init__ ( self , session_id : str , job_id : str , component_name : str , requirement_sections : dict [ str , list [ dict [ str , Any ]]], concurrency_limit : int = 15 , ) -> None : self . session_id = session_id self . job_id = job_id self . job_manager = get_job_manager () self . session_manager = get_session_manager () self . concurrency_limit = concurrency_limit self . component_name = component_name self . requirement_sections = requirement_sections # ------------------------------------------------------------ # Bulk processing for all sections at once # ------------------------------------------------------------ async def run_all_sections ( self , sections : list [ dict [ str , Any ]], ) -> dict [ str , Any ]: \"\"\" Execute the LangGraph workflow for all sections. This method processes all sections through the GSPRGraph pipeline, updates job progress, and returns the results along with metadata such as processing duration and counts of completed, failed, and skipped sections. Args: sections (list): List of sections to process, each represented as a dictionary. Returns: dict: Contains the results of the workflow, including success status, total processed, counts of completed, failed, and skipped sections, and processing duration. Raises: RuntimeError: If the session is not found in Redis. Example: runner = GSPRGraphRunner(session_id=\"123\", job_id=\"job_456\", component_name=\"Sensor\", requirement_sections={}, concurrency_limit=10) results = await runner.run_all_sections(sections=[{\"section\": \"A\"}, {\"section\": \"B\"}]) Response: { \"success\": true, \"total_processed\": 2, \"completed\": 2, \"failed\": 0, \"skipped\": 0, \"duration\": 1.23 } \"\"\" logger . info ( f \"[GSPRGraphRunner] Getting session { self . session_id } from Redis...\" ) context = self . session_manager . get_session ( self . session_id ) if not context : raise RuntimeError ( f \"Session { self . session_id } not found in Redis.\" ) logger . info ( f \"[GSPRGraphRunner] Session found, creating GSPRGraph for job { self . job_id } ...\" ) # Create GSPRGraph execution environment graph = GSPRGraph ( chain = GSPRChain (), context = context , component_name = self . component_name , concurrency_limit = self . concurrency_limit , session_id = self . session_id , job_id = self . job_id , requirement_sections = self . requirement_sections , ) logger . info ( f \"[GSPRGraphRunner] GSPRGraph created, running workflow for { len ( sections ) } sections...\" ) start_time = time . perf_counter () try : # Run the full workflow: context -> grouping -> processing result = await graph . run ( sections = sections , session_id = self . session_id , ) duration = round ( time . perf_counter () - start_time , 2 ) logger . info ( f \"[GSPRGraphRunner] Workflow completed in { duration } s, processing results...\" ) # Extract results for job progress update group_results = result . get ( \"results\" , []) errors = result . get ( \"errors\" , []) logger . info ( f \"[GSPRGraphRunner] Raw result keys: { result . keys () } \" ) logger . info ( f \"[GSPRGraphRunner] Group results count: { len ( group_results ) } \" ) if group_results and len ( group_results ) > 0 : logger . info ( f \"[GSPRGraphRunner] Sample result: { group_results [ 0 ] } \" ) # Update job progress based on results # Note: GSPR chain returns status as \"success\" or \"skipped\", not \"completed\" completed_count = sum ( 1 for r in group_results if r . get ( \"status\" ) in [ \"success\" , \"completed\" ]) failed_count = sum ( 1 for r in group_results if r . get ( \"status\" ) == \"failed\" ) skipped_count = sum ( 1 for r in group_results if r . get ( \"status\" ) == \"skipped\" ) logger . info ( f \"[GSPRGraphRunner] Final counts - completed/success: { completed_count } , skipped: { skipped_count } , failed: { failed_count } \" ) # Determine if job was successful - no errors and some results processed job_success = len ( errors ) == 0 and len ( group_results ) > 0 # Don't double-count progress - the individual sections already updated # Just mark the job as completed and publish final event if job_success : self . job_manager . mark_completed ( self . job_id ) logger . info ( f \"[GSPRGraphRunner] Job { self . job_id } marked as completed\" ) else : self . job_manager . mark_completed ( self . job_id , failed = True ) logger . info ( f \"[GSPRGraphRunner] Job { self . job_id } marked as failed - Errors: { errors } \" ) # Return results with additional metadata return { ** result , \"success\" : job_success , \"total_processed\" : len ( group_results ), \"completed\" : completed_count , \"failed\" : failed_count , \"skipped\" : skipped_count , \"duration\" : duration , } except Exception as e : # Handle bulk processing failure logger . error ( f \"[GSPRGraphRunner] Bulk processing failed for job { self . job_id } : { e } \" ) self . job_manager . mark_completed ( self . job_id , failed = True ) return { \"success\" : False , \"error\" : str ( e ), \"total_processed\" : 0 , \"completed\" : 0 , \"failed\" : len ( sections ), \"duration\" : round ( time . perf_counter () - start_time , 2 ), } run_all_sections ( sections ) async Execute the LangGraph workflow for all sections. This method processes all sections through the GSPRGraph pipeline, updates job progress, and returns the results along with metadata such as processing duration and counts of completed, failed, and skipped sections. Parameters: Name Type Description Default sections list List of sections to process, each represented as a dictionary. required Returns: Name Type Description dict dict [ str , Any ] Contains the results of the workflow, including success status, total processed, dict [ str , Any ] counts of completed, failed, and skipped sections, and processing duration. Raises: Type Description RuntimeError If the session is not found in Redis. Example runner = GSPRGraphRunner(session_id=\"123\", job_id=\"job_456\", component_name=\"Sensor\", requirement_sections={}, concurrency_limit=10) results = await runner.run_all_sections(sections=[{\"section\": \"A\"}, {\"section\": \"B\"}]) Response: { \"success\": true, \"total_processed\": 2, \"completed\": 2, \"failed\": 0, \"skipped\": 0, \"duration\": 1.23 } Source code in core/agent/gspr_tableAgent.py 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 async def run_all_sections ( self , sections : list [ dict [ str , Any ]], ) -> dict [ str , Any ]: \"\"\" Execute the LangGraph workflow for all sections. This method processes all sections through the GSPRGraph pipeline, updates job progress, and returns the results along with metadata such as processing duration and counts of completed, failed, and skipped sections. Args: sections (list): List of sections to process, each represented as a dictionary. Returns: dict: Contains the results of the workflow, including success status, total processed, counts of completed, failed, and skipped sections, and processing duration. Raises: RuntimeError: If the session is not found in Redis. Example: runner = GSPRGraphRunner(session_id=\"123\", job_id=\"job_456\", component_name=\"Sensor\", requirement_sections={}, concurrency_limit=10) results = await runner.run_all_sections(sections=[{\"section\": \"A\"}, {\"section\": \"B\"}]) Response: { \"success\": true, \"total_processed\": 2, \"completed\": 2, \"failed\": 0, \"skipped\": 0, \"duration\": 1.23 } \"\"\" logger . info ( f \"[GSPRGraphRunner] Getting session { self . session_id } from Redis...\" ) context = self . session_manager . get_session ( self . session_id ) if not context : raise RuntimeError ( f \"Session { self . session_id } not found in Redis.\" ) logger . info ( f \"[GSPRGraphRunner] Session found, creating GSPRGraph for job { self . job_id } ...\" ) # Create GSPRGraph execution environment graph = GSPRGraph ( chain = GSPRChain (), context = context , component_name = self . component_name , concurrency_limit = self . concurrency_limit , session_id = self . session_id , job_id = self . job_id , requirement_sections = self . requirement_sections , ) logger . info ( f \"[GSPRGraphRunner] GSPRGraph created, running workflow for { len ( sections ) } sections...\" ) start_time = time . perf_counter () try : # Run the full workflow: context -> grouping -> processing result = await graph . run ( sections = sections , session_id = self . session_id , ) duration = round ( time . perf_counter () - start_time , 2 ) logger . info ( f \"[GSPRGraphRunner] Workflow completed in { duration } s, processing results...\" ) # Extract results for job progress update group_results = result . get ( \"results\" , []) errors = result . get ( \"errors\" , []) logger . info ( f \"[GSPRGraphRunner] Raw result keys: { result . keys () } \" ) logger . info ( f \"[GSPRGraphRunner] Group results count: { len ( group_results ) } \" ) if group_results and len ( group_results ) > 0 : logger . info ( f \"[GSPRGraphRunner] Sample result: { group_results [ 0 ] } \" ) # Update job progress based on results # Note: GSPR chain returns status as \"success\" or \"skipped\", not \"completed\" completed_count = sum ( 1 for r in group_results if r . get ( \"status\" ) in [ \"success\" , \"completed\" ]) failed_count = sum ( 1 for r in group_results if r . get ( \"status\" ) == \"failed\" ) skipped_count = sum ( 1 for r in group_results if r . get ( \"status\" ) == \"skipped\" ) logger . info ( f \"[GSPRGraphRunner] Final counts - completed/success: { completed_count } , skipped: { skipped_count } , failed: { failed_count } \" ) # Determine if job was successful - no errors and some results processed job_success = len ( errors ) == 0 and len ( group_results ) > 0 # Don't double-count progress - the individual sections already updated # Just mark the job as completed and publish final event if job_success : self . job_manager . mark_completed ( self . job_id ) logger . info ( f \"[GSPRGraphRunner] Job { self . job_id } marked as completed\" ) else : self . job_manager . mark_completed ( self . job_id , failed = True ) logger . info ( f \"[GSPRGraphRunner] Job { self . job_id } marked as failed - Errors: { errors } \" ) # Return results with additional metadata return { ** result , \"success\" : job_success , \"total_processed\" : len ( group_results ), \"completed\" : completed_count , \"failed\" : failed_count , \"skipped\" : skipped_count , \"duration\" : duration , } except Exception as e : # Handle bulk processing failure logger . error ( f \"[GSPRGraphRunner] Bulk processing failed for job { self . job_id } : { e } \" ) self . job_manager . mark_completed ( self . job_id , failed = True ) return { \"success\" : False , \"error\" : str ( e ), \"total_processed\" : 0 , \"completed\" : 0 , \"failed\" : len ( sections ), \"duration\" : round ( time . perf_counter () - start_time , 2 ), } \ud83d\udee1\ufe0f Regulatory Guard Agent \u2014 Rule-Based Safety & Compliance Validation Acts as a security and compliance layer across the pipeline. Enforces regulatory logic, validates inputs/outputs, and prevents inconsistent or unsafe data from propagating \u26a0\ufe0f\ud83d\udee1\ufe0f. system_instructions = 'You are a regulatory intelligence assistant. You analyze and generate compliance-related content only. Do not produce personal, political, or emotional commentary.' module-attribute Retrieve the regulatory guard agent instance. This function initializes and returns a regulatory guard agent configured with the current model, system prompt, and middleware. The agent is designed to analyze and generate compliance-related content while adhering to regulatory constraints. Returns: Name Type Description Agent A regulatory guard agent instance configured with the selected model, system prompt, and middleware. Example agent = get_regulatory_guard_agent() response = agent.run(\"Analyze compliance for medical device X.\") get_regulatory_guard_agent () Get regulatory guard agent with current model selection. Source code in core/agent/regulatory_guard_agent.py 32 33 34 35 36 37 38 def get_regulatory_guard_agent (): \"\"\"Get regulatory guard agent with current model selection.\"\"\" return create_agent ( model = get_vllm_llm (), system_prompt = GUARD_PROMPT or system_instructions , middleware = get_regulatory_middlewares (), )","title":"Workflows Overview"},{"location":"ai_backend/agents/#core-agents-intelligent-regulatory-automation-modules","text":"","title":"\ud83d\udda5\ufe0f Core Agents \u2014 Intelligent Regulatory Automation Modules"},{"location":"ai_backend/agents/#fda-name-agent-map-device-names-to-fda-terminology","text":"Automatically interprets user-provided device names and maps them to official FDA-recognized nomenclature . Supports classification, regulatory lookup, and component selection with high accuracy \ud83e\udde0\ud83d\udcda.","title":"\ud83c\udfe5 FDA Name Agent \u2014 Map Device Names to FDA Terminology"},{"location":"ai_backend/agents/#core.agent.FDA_nameAgent.FDAAgent","text":"Initialize the FDAAgent for device name suggestions. The FDAAgent integrates with OpenAI embeddings and a Milvus vector store to provide device name suggestions based on similarity search and language model processing. Raises: Type Description ValueError If required environment variables (OPENAI_API_KEY, MILVUS_COLLECTION, Source code in core/agent/FDA_nameAgent.py 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 class FDAAgent : \"\"\" Initialize the FDAAgent for device name suggestions. The FDAAgent integrates with OpenAI embeddings and a Milvus vector store to provide device name suggestions based on similarity search and language model processing. Raises: ValueError: If required environment variables (OPENAI_API_KEY, MILVUS_COLLECTION, MILVUS_HOST/URI, MILVUS_PORT) are not set. \"\"\" def __init__ ( self ): self . embeddings = OpenAIEmbeddings ( api_key = SecretStr ( api_key ) if api_key is not None else None , ) collection_name = os . getenv ( \"MILVUS_COLLECTION\" ) if not collection_name : raise ValueError ( \"MILVUS_COLLECTION environment variable is not set.\" ) # Prefer full URI if explicitly provided milvus_uri = os . getenv ( \"MILVUS_URI\" ) if not milvus_uri : milvus_host = os . getenv ( \"MILVUS_HOST\" , \"localhost\" ) if not milvus_host : raise ValueError ( \"MILVUS_HOST environment variable is not set.\" ) milvus_port = os . getenv ( \"MILVUS_PORT\" , \"19530\" ) if not milvus_port : raise ValueError ( \"MILVUS_PORT environment variable is not set.\" ) milvus_uri = f \"http:// { milvus_host } : { milvus_port } \" self . vector_store = Milvus ( embedding_function = self . embeddings , collection_name = collection_name , connection_args = { \"uri\" : milvus_uri }, auto_id = True , # Set to True to match previous script behavior ) self . llm = ChatOpenAI ( temperature = 0 , model = \"gpt-4o-mini\" ) \"\"\" Retrieve device name suggestions based on input criteria. This method performs a similarity search in the Milvus vector store using the provided device name, then refines the results using a language model to generate structured suggestions. Args: device_name (str): The name of the device to search for. intended_purpose (str): The intended purpose of the device. Returns: dict: A dictionary containing a list of relevant device names. Example: agent = FDAAgent() suggestions = agent.get_suggestions(\"Pacemaker\", \"Heart rhythm management\") Response: { \"relevant_device_names\": [\"Cardiac Pacemaker\", \"Implantable Pacemaker\"] } \"\"\" def get_suggestions ( self , device_name : str , intended_purpose : str ) -> dict : results = self . vector_store . similarity_search ( device_name , k = 10 ) if not results : return { \"relevant_device_names\" : []} # Extract device names device_names = [] seen = set () for doc in results : name = doc . metadata . get ( \"device_name\" , doc . page_content ) if name and name not in seen : device_names . append ( name ) seen . add ( name ) # Pass both device_name & intended_purpose to LLM prompt = FDA_prompt . format ( device_name = device_name , intended_purpose = intended_purpose , device_names = device_names , ) structured_llm = self . llm . with_structured_output ( DeviceSuggestion ) response = structured_llm . invoke ( prompt ) return response","title":"FDAAgent"},{"location":"ai_backend/agents/#gspr-table-agent-build-maintain-compliance-tables","text":"Generates structured GSPR compliance tables , aligning clauses with evidence, standards, and device parameters. Ensures traceability and MDR-ready documentation for audits and submissions \ud83d\udcc4\ud83d\udd0d.","title":"\ud83d\udcca GSPR Table Agent \u2014 Build &amp; Maintain Compliance Tables"},{"location":"ai_backend/agents/#core.agent.gspr_tableAgent--project-regulatory-ai-backend","text":"","title":"Project: Regulatory AI Backend"},{"location":"ai_backend/agents/#core.agent.gspr_tableAgent--description-gsprtableagent-orchestrates-the-gspr-generation-workflow-using-langtable","text":"","title":"Description: GSPRTableAgent orchestrates the GSPR generation workflow using LangTable."},{"location":"ai_backend/agents/#core.agent.gspr_tableAgent.GSPRGraphRunner","text":"GSPRGraphRunner orchestrates the full GSPR generation workflow via GSPRGraph. It bridges FastAPI's background job system with the LLM-based regulatory reasoning pipeline defined under src/regulatory . Responsibilities: - Fetch context & state from Redis session - Execute LangGraph-based bulk generation for all sections - Publish real-time job progress via Redis Pub/Sub - Handle failures and provide comprehensive results Parameters: Name Type Description Default session_id str Unique identifier for the Redis session. required job_id str Unique identifier for the job. required component_name str Name of the component being processed. required requirement_sections dict Requirement sections to process. required concurrency_limit int Maximum number of concurrent tasks (default: 15). 15 Source code in core/agent/gspr_tableAgent.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 class GSPRGraphRunner : \"\"\" GSPRGraphRunner orchestrates the full GSPR generation workflow via GSPRGraph. It bridges FastAPI's background job system with the LLM-based regulatory reasoning pipeline defined under `src/regulatory`. Responsibilities: - Fetch context & state from Redis session - Execute LangGraph-based bulk generation for all sections - Publish real-time job progress via Redis Pub/Sub - Handle failures and provide comprehensive results Args: session_id (str): Unique identifier for the Redis session. job_id (str): Unique identifier for the job. component_name (str): Name of the component being processed. requirement_sections (dict): Requirement sections to process. concurrency_limit (int): Maximum number of concurrent tasks (default: 15). \"\"\" def __init__ ( self , session_id : str , job_id : str , component_name : str , requirement_sections : dict [ str , list [ dict [ str , Any ]]], concurrency_limit : int = 15 , ) -> None : self . session_id = session_id self . job_id = job_id self . job_manager = get_job_manager () self . session_manager = get_session_manager () self . concurrency_limit = concurrency_limit self . component_name = component_name self . requirement_sections = requirement_sections # ------------------------------------------------------------ # Bulk processing for all sections at once # ------------------------------------------------------------ async def run_all_sections ( self , sections : list [ dict [ str , Any ]], ) -> dict [ str , Any ]: \"\"\" Execute the LangGraph workflow for all sections. This method processes all sections through the GSPRGraph pipeline, updates job progress, and returns the results along with metadata such as processing duration and counts of completed, failed, and skipped sections. Args: sections (list): List of sections to process, each represented as a dictionary. Returns: dict: Contains the results of the workflow, including success status, total processed, counts of completed, failed, and skipped sections, and processing duration. Raises: RuntimeError: If the session is not found in Redis. Example: runner = GSPRGraphRunner(session_id=\"123\", job_id=\"job_456\", component_name=\"Sensor\", requirement_sections={}, concurrency_limit=10) results = await runner.run_all_sections(sections=[{\"section\": \"A\"}, {\"section\": \"B\"}]) Response: { \"success\": true, \"total_processed\": 2, \"completed\": 2, \"failed\": 0, \"skipped\": 0, \"duration\": 1.23 } \"\"\" logger . info ( f \"[GSPRGraphRunner] Getting session { self . session_id } from Redis...\" ) context = self . session_manager . get_session ( self . session_id ) if not context : raise RuntimeError ( f \"Session { self . session_id } not found in Redis.\" ) logger . info ( f \"[GSPRGraphRunner] Session found, creating GSPRGraph for job { self . job_id } ...\" ) # Create GSPRGraph execution environment graph = GSPRGraph ( chain = GSPRChain (), context = context , component_name = self . component_name , concurrency_limit = self . concurrency_limit , session_id = self . session_id , job_id = self . job_id , requirement_sections = self . requirement_sections , ) logger . info ( f \"[GSPRGraphRunner] GSPRGraph created, running workflow for { len ( sections ) } sections...\" ) start_time = time . perf_counter () try : # Run the full workflow: context -> grouping -> processing result = await graph . run ( sections = sections , session_id = self . session_id , ) duration = round ( time . perf_counter () - start_time , 2 ) logger . info ( f \"[GSPRGraphRunner] Workflow completed in { duration } s, processing results...\" ) # Extract results for job progress update group_results = result . get ( \"results\" , []) errors = result . get ( \"errors\" , []) logger . info ( f \"[GSPRGraphRunner] Raw result keys: { result . keys () } \" ) logger . info ( f \"[GSPRGraphRunner] Group results count: { len ( group_results ) } \" ) if group_results and len ( group_results ) > 0 : logger . info ( f \"[GSPRGraphRunner] Sample result: { group_results [ 0 ] } \" ) # Update job progress based on results # Note: GSPR chain returns status as \"success\" or \"skipped\", not \"completed\" completed_count = sum ( 1 for r in group_results if r . get ( \"status\" ) in [ \"success\" , \"completed\" ]) failed_count = sum ( 1 for r in group_results if r . get ( \"status\" ) == \"failed\" ) skipped_count = sum ( 1 for r in group_results if r . get ( \"status\" ) == \"skipped\" ) logger . info ( f \"[GSPRGraphRunner] Final counts - completed/success: { completed_count } , skipped: { skipped_count } , failed: { failed_count } \" ) # Determine if job was successful - no errors and some results processed job_success = len ( errors ) == 0 and len ( group_results ) > 0 # Don't double-count progress - the individual sections already updated # Just mark the job as completed and publish final event if job_success : self . job_manager . mark_completed ( self . job_id ) logger . info ( f \"[GSPRGraphRunner] Job { self . job_id } marked as completed\" ) else : self . job_manager . mark_completed ( self . job_id , failed = True ) logger . info ( f \"[GSPRGraphRunner] Job { self . job_id } marked as failed - Errors: { errors } \" ) # Return results with additional metadata return { ** result , \"success\" : job_success , \"total_processed\" : len ( group_results ), \"completed\" : completed_count , \"failed\" : failed_count , \"skipped\" : skipped_count , \"duration\" : duration , } except Exception as e : # Handle bulk processing failure logger . error ( f \"[GSPRGraphRunner] Bulk processing failed for job { self . job_id } : { e } \" ) self . job_manager . mark_completed ( self . job_id , failed = True ) return { \"success\" : False , \"error\" : str ( e ), \"total_processed\" : 0 , \"completed\" : 0 , \"failed\" : len ( sections ), \"duration\" : round ( time . perf_counter () - start_time , 2 ), }","title":"GSPRGraphRunner"},{"location":"ai_backend/agents/#core.agent.gspr_tableAgent.GSPRGraphRunner.run_all_sections","text":"Execute the LangGraph workflow for all sections. This method processes all sections through the GSPRGraph pipeline, updates job progress, and returns the results along with metadata such as processing duration and counts of completed, failed, and skipped sections. Parameters: Name Type Description Default sections list List of sections to process, each represented as a dictionary. required Returns: Name Type Description dict dict [ str , Any ] Contains the results of the workflow, including success status, total processed, dict [ str , Any ] counts of completed, failed, and skipped sections, and processing duration. Raises: Type Description RuntimeError If the session is not found in Redis. Example runner = GSPRGraphRunner(session_id=\"123\", job_id=\"job_456\", component_name=\"Sensor\", requirement_sections={}, concurrency_limit=10) results = await runner.run_all_sections(sections=[{\"section\": \"A\"}, {\"section\": \"B\"}]) Response: { \"success\": true, \"total_processed\": 2, \"completed\": 2, \"failed\": 0, \"skipped\": 0, \"duration\": 1.23 } Source code in core/agent/gspr_tableAgent.py 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 async def run_all_sections ( self , sections : list [ dict [ str , Any ]], ) -> dict [ str , Any ]: \"\"\" Execute the LangGraph workflow for all sections. This method processes all sections through the GSPRGraph pipeline, updates job progress, and returns the results along with metadata such as processing duration and counts of completed, failed, and skipped sections. Args: sections (list): List of sections to process, each represented as a dictionary. Returns: dict: Contains the results of the workflow, including success status, total processed, counts of completed, failed, and skipped sections, and processing duration. Raises: RuntimeError: If the session is not found in Redis. Example: runner = GSPRGraphRunner(session_id=\"123\", job_id=\"job_456\", component_name=\"Sensor\", requirement_sections={}, concurrency_limit=10) results = await runner.run_all_sections(sections=[{\"section\": \"A\"}, {\"section\": \"B\"}]) Response: { \"success\": true, \"total_processed\": 2, \"completed\": 2, \"failed\": 0, \"skipped\": 0, \"duration\": 1.23 } \"\"\" logger . info ( f \"[GSPRGraphRunner] Getting session { self . session_id } from Redis...\" ) context = self . session_manager . get_session ( self . session_id ) if not context : raise RuntimeError ( f \"Session { self . session_id } not found in Redis.\" ) logger . info ( f \"[GSPRGraphRunner] Session found, creating GSPRGraph for job { self . job_id } ...\" ) # Create GSPRGraph execution environment graph = GSPRGraph ( chain = GSPRChain (), context = context , component_name = self . component_name , concurrency_limit = self . concurrency_limit , session_id = self . session_id , job_id = self . job_id , requirement_sections = self . requirement_sections , ) logger . info ( f \"[GSPRGraphRunner] GSPRGraph created, running workflow for { len ( sections ) } sections...\" ) start_time = time . perf_counter () try : # Run the full workflow: context -> grouping -> processing result = await graph . run ( sections = sections , session_id = self . session_id , ) duration = round ( time . perf_counter () - start_time , 2 ) logger . info ( f \"[GSPRGraphRunner] Workflow completed in { duration } s, processing results...\" ) # Extract results for job progress update group_results = result . get ( \"results\" , []) errors = result . get ( \"errors\" , []) logger . info ( f \"[GSPRGraphRunner] Raw result keys: { result . keys () } \" ) logger . info ( f \"[GSPRGraphRunner] Group results count: { len ( group_results ) } \" ) if group_results and len ( group_results ) > 0 : logger . info ( f \"[GSPRGraphRunner] Sample result: { group_results [ 0 ] } \" ) # Update job progress based on results # Note: GSPR chain returns status as \"success\" or \"skipped\", not \"completed\" completed_count = sum ( 1 for r in group_results if r . get ( \"status\" ) in [ \"success\" , \"completed\" ]) failed_count = sum ( 1 for r in group_results if r . get ( \"status\" ) == \"failed\" ) skipped_count = sum ( 1 for r in group_results if r . get ( \"status\" ) == \"skipped\" ) logger . info ( f \"[GSPRGraphRunner] Final counts - completed/success: { completed_count } , skipped: { skipped_count } , failed: { failed_count } \" ) # Determine if job was successful - no errors and some results processed job_success = len ( errors ) == 0 and len ( group_results ) > 0 # Don't double-count progress - the individual sections already updated # Just mark the job as completed and publish final event if job_success : self . job_manager . mark_completed ( self . job_id ) logger . info ( f \"[GSPRGraphRunner] Job { self . job_id } marked as completed\" ) else : self . job_manager . mark_completed ( self . job_id , failed = True ) logger . info ( f \"[GSPRGraphRunner] Job { self . job_id } marked as failed - Errors: { errors } \" ) # Return results with additional metadata return { ** result , \"success\" : job_success , \"total_processed\" : len ( group_results ), \"completed\" : completed_count , \"failed\" : failed_count , \"skipped\" : skipped_count , \"duration\" : duration , } except Exception as e : # Handle bulk processing failure logger . error ( f \"[GSPRGraphRunner] Bulk processing failed for job { self . job_id } : { e } \" ) self . job_manager . mark_completed ( self . job_id , failed = True ) return { \"success\" : False , \"error\" : str ( e ), \"total_processed\" : 0 , \"completed\" : 0 , \"failed\" : len ( sections ), \"duration\" : round ( time . perf_counter () - start_time , 2 ), }","title":"run_all_sections"},{"location":"ai_backend/agents/#regulatory-guard-agent-rule-based-safety-compliance-validation","text":"Acts as a security and compliance layer across the pipeline. Enforces regulatory logic, validates inputs/outputs, and prevents inconsistent or unsafe data from propagating \u26a0\ufe0f\ud83d\udee1\ufe0f.","title":"\ud83d\udee1\ufe0f Regulatory Guard Agent \u2014 Rule-Based Safety &amp; Compliance Validation"},{"location":"ai_backend/agents/#core.agent.regulatory_guard_agent.system_instructions","text":"Retrieve the regulatory guard agent instance. This function initializes and returns a regulatory guard agent configured with the current model, system prompt, and middleware. The agent is designed to analyze and generate compliance-related content while adhering to regulatory constraints. Returns: Name Type Description Agent A regulatory guard agent instance configured with the selected model, system prompt, and middleware. Example agent = get_regulatory_guard_agent() response = agent.run(\"Analyze compliance for medical device X.\")","title":"system_instructions"},{"location":"ai_backend/agents/#core.agent.regulatory_guard_agent.get_regulatory_guard_agent","text":"Get regulatory guard agent with current model selection. Source code in core/agent/regulatory_guard_agent.py 32 33 34 35 36 37 38 def get_regulatory_guard_agent (): \"\"\"Get regulatory guard agent with current model selection.\"\"\" return create_agent ( model = get_vllm_llm (), system_prompt = GUARD_PROMPT or system_instructions , middleware = get_regulatory_middlewares (), )","title":"get_regulatory_guard_agent"},{"location":"ai_backend/chains_overview/","text":"\u2699\ufe0f Core Processing Chains \u2014 Regulatory AI \ud83d\udd27 Component Recommender Chain - Smart Component Suggestions Analyzes device attributes and intelligently proposes optimal components required for regulatory and technical completeness. Ensures alignment between device structure and regulatory expectations. get_component_recommender_chain () Get component recommender chain with current model selection. Source code in core/chains/component_recommender_chain.py 61 62 63 64 65 66 67 def get_component_recommender_chain (): \"\"\"Get component recommender chain with current model selection.\"\"\" logger . info ( \"Creating component recommender chain with current model...\" ) component_recommender_llm = get_component_recommender_llm () chain = prompt | component_recommender_llm logger . info ( \"Component recommender chain created successfully.\" ) return chain get_component_recommender_llm () Get LLM instance with current model selection for runtime switching. Source code in core/chains/component_recommender_chain.py 30 31 32 33 34 35 36 37 38 39 40 def get_component_recommender_llm (): \"\"\"Get LLM instance with current model selection for runtime switching.\"\"\" logger . info ( \"Creating LLM instance with current model selection...\" ) try : llm = get_vllm_llm () # This will use the current selected model logger . info ( \"LLM initialized successfully.\" ) return llm . with_structured_output ( ComponentRecommenderModel ) except Exception as e : logger . exception ( \"Failed to initialize LLM: %s \" , e ) logger . info ( f \"LLM initialization exception message: { e } \" ) raise \ud83d\udcdd Design Input Chain \u2014 Structure & Validate Inputs Processes raw session data into structured design input specifications , ensuring clarity, consistency, and readiness for downstream modules. Acts as the foundation of compliant design documentation. driver = GraphDatabase . driver ( NEO4J_URI , auth = ( NEO4J_USER , NEO4J_PASSWORD )) module-attribute Fetch design input details for a specific GSPR clause. This function queries the Neo4j database for details related to a specific GSPR clause, including requirement types, standards, and justifications. It then uses a language model to generate structured design input data. Parameters: Name Type Description Default device_meta dict Metadata about the device, including type, purpose, users, and risks. required component str The name of the component being processed. required gspr_no str The GSPR clause number to query. required Returns: Name Type Description DesignInputModel A structured model containing the design input details, including component, requirement, GSPR text, and associated standards. Example device_meta = { \"device_type\": \"Sensor\", \"intended_purpose\": \"Monitoring\", \"intended_users\": [\"Doctors\", \"Nurses\"], \"risk_classification\": \"Class II\" } design_input = fetch_design_input(device_meta, \"Sensor\", \"5.1\") Response: DesignInputModel( component=\"Sensor\", requirement=\"Safety\", gspr_text=\"Ensure device safety under normal conditions.\", standards=[...] ) fetch_design_input ( device_meta , component , gspr_no ) Query Neo4j for a specific GSPRClause, fetch requirement type, standards, and run it through the LLM to generate structured output. Source code in core/chains/design_input_chain.py 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 def fetch_design_input ( device_meta : dict , component : str , gspr_no : str ) -> DesignInputModel : \"\"\" Query Neo4j for a specific GSPRClause, fetch requirement type, standards, and run it through the LLM to generate structured output. \"\"\" query = \"\"\" MATCH (g:GSPRClause {name: $gspr_no}) OPTIONAL MATCH (g)-[:HAS_TYPE]->(r:RequirementType) OPTIONAL MATCH (g)-[rel:ADDRESSED_BY]->(s:Standard) RETURN g.name AS gspr_no, g.text AS gspr_text, g.applicability AS applicability, r.name AS requirement, s.name AS standard, rel.justification AS justification \"\"\" standards_info = [] gspr_text = \"\" applicability = \"\" requirement = \"\" with driver . session ( database = NEO4J_DATABASE ) as session : results = session . run ( query , gspr_no = gspr_no ) for record in results : gspr_text = record [ \"gspr_text\" ] applicability = record [ \"applicability\" ] requirement = record [ \"requirement\" ] or \"\" if record [ \"standard\" ]: standards_info . append ({ \"standard\" : record [ \"standard\" ], \"justification\" : record [ \"justification\" ], \"gspr_text\" : gspr_text , \"applicability\" : applicability , \"requirement\" : requirement , }) if not standards_info : logger . warning ( f \"No standards found in KG for GSPR ' { gspr_no } '\" ) return DesignInputModel ( component = component , requirement = requirement , gspr_text = gspr_text , standards = []) # Build standards_context standards_context = \"\" for i , item in enumerate ( standards_info , start = 1 ): standards_context += f \"\"\" === Context for Standard { i } : { item [ 'standard' ] } === \u2022 Component: { component } \u2022 Requirement: { requirement } \u2022 GSPR Number: { gspr_no } \u2022 GSPR Clause Text: { item [ 'gspr_text' ] } \u2022 Applicability: { item [ 'applicability' ] } \u2022 Raw Justification (from KG): { item [ 'justification' ] } \"\"\" # Create prompt prompt = PromptTemplate ( template = DESIGN_INPUT_GENERATOR_PROMPT , input_variables = [ \"device_type\" , \"intended_purpose\" , \"intended_users\" , \"risk_classifications\" , \"component\" , \"requirement\" , \"gspr_no\" , \"gspr_text\" , \"standards_context\" , ], ) # Initialize LLM with structured output from regulatory.core.llm.llm_provider import get_vllm_llm llm = get_vllm_llm () design_input_llm = llm . with_structured_output ( DesignInputModel ) design_input_chain = prompt | design_input_llm chain_input = { \"device_type\" : device_meta . get ( \"device_type\" , \"\" ), \"intended_purpose\" : device_meta . get ( \"intended_purpose\" , \"\" ), \"intended_users\" : \", \" . join ( device_meta . get ( \"intended_users\" ) or []), \"risk_classifications\" : device_meta . get ( \"risk_classification\" , \"\" ), \"component\" : component , \"requirement\" : requirement , \"gspr_no\" : gspr_no , \"gspr_text\" : gspr_text , \"standards_context\" : standards_context , } logger . info ( f \"Fetching design input for component ' { component } ', GSPR ' { gspr_no } '\" ) response = design_input_chain . invoke ( chain_input ) return ( response if isinstance ( response , DesignInputModel ) else DesignInputModel ( ** response ) ) \ud83d\udce4 Design Output Chain \u2014 Transform Inputs \u2192 Regulatory Outputs Converts finalized, validated design inputs into formalized regulatory design documents . Handles formatting, integrity checks, and delivery of compliant output packages. run_design_output_chain ( design_input , component ) async Automatically generate a structured Design Output Report for a given medical device component. This function does not require user text or PDF references. Instead, it automatically utilizes the available design input data (device type, requirements, standards, and GSPR text) to produce a Design Output Report aligned with ISO/IEC standards. Parameters: Name Type Description Default design_input dict Dictionary containing design data, including: - device_type (str) - component (str) - requirement (str) - gspr_text (str) - standards (list[dict]) with 'name' and 'justification' fields required component str Name of the device component. required Returns: Name Type Description str Generated Design Output Report (formatted table with Clause, Category, Standard, and Output Statement). Source code in core/chains/design_output_chain.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 async def run_design_output_chain ( design_input : dict , component : str ): \"\"\" Automatically generate a structured Design Output Report for a given medical device component. This function does not require user text or PDF references. Instead, it automatically utilizes the available design input data (device type, requirements, standards, and GSPR text) to produce a Design Output Report aligned with ISO/IEC standards. Args: design_input (dict): Dictionary containing design data, including: - device_type (str) - component (str) - requirement (str) - gspr_text (str) - standards (list[dict]) with 'name' and 'justification' fields component (str): Name of the device component. Returns: str: Generated Design Output Report (formatted table with Clause, Category, Standard, and Output Statement). \"\"\" # Format standards context for LLM standards_context = \" \\n \" . join ( f \"=== Standard: { std . get ( 'name' , '' ) } === \\n Justification: { std . get ( 'justification' , '' ) } \" for std in design_input . get ( \"standards\" , []) ) # Prepare input payload for the LLM inputs = { \"device_type\" : design_input . get ( \"device_type\" , \"\" ), \"component\" : component , \"requirement\" : design_input . get ( \"requirement\" , \"\" ), \"gspr_text\" : design_input . get ( \"gspr_text\" , \"\" ), \"standards_context\" : standards_context , } logger . info ( f \"Running Design Output Chain for component: ' { component } ' (Auto ISO selection enabled)\" ) llm = get_vllm_llm () chain = prompt | llm # Execute asynchronously and return generated content result = await chain . ainvoke ( inputs ) return result . content \ud83d\udee1\ufe0f GSPR Chain \u2014 Analyze Compliance Against GSPR Evaluates device details against General Safety & Performance Requirements (GSPR) . Identifies relevant clauses, compliance gaps, and required evidence for MDR conformity. GSPRChain \u2014 Prompt & LLM Execution Layer (Async) Responsibilities: - Build prompts for GSPR reasoning steps - Use LLM clients (from regulatory.core.llm) - Return structured results for each reasoning phase GSPRChain Executes the core GSPR reasoning prompts using an async LLM client. This is a fully production implementation using the real GPT-4o model. Source code in core/chains/gspr_chain.py 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 class GSPRChain : \"\"\" Executes the core GSPR reasoning prompts using an async LLM client. This is a fully production implementation using the real GPT-4o model. \"\"\" def __init__ ( self , * , model_name : str = \"gpt-4o\" , small_model_name : str = \"gpt-4o-mini\" , temperature : float = 0.2 , component_name : str = \"unknown\" , ) -> None : self . model_name = model_name self . small_model_name = small_model_name self . temperature = temperature self . llm = get_vllm_llm ( model = model_name , temperature = temperature ) self . small_llm = get_vllm_llm ( model = small_model_name , temperature = 0.1 ) logger . info ( f \"GSPRChain initialized | main= { model_name } | small= { small_model_name } | temperature= { temperature } \" ) # ========================================================= # Internal Helper \u2014 Generic async LLM call (text or structured) # ========================================================= async def _llm_call ( self , prompt : str , * , temperature : Optional [ float ] = None , structured_schema : Optional [ type [ Any ]] = None , ) -> Any : \"\"\" Asynchronously call the configured LLM. Parameters ---------- prompt : str The formatted prompt text to send to the model. temperature : float, optional Override the default temperature for this specific call. structured_schema : pydantic.BaseModel | TypedDict | None If provided, returns structured output conforming to the schema using the model's `with_structured_output()` interface. Returns ------- Any - If `structured_schema` is None \u2192 str (LLM text output) - If `structured_schema` is provided \u2192 instance of schema \"\"\" try : # choose LLM instance if temperature and temperature != self . temperature : llm = get_vllm_llm ( model = self . model_name , temperature = temperature ) else : llm = self . llm # structured output mode if structured_schema is not None : llm_structured = llm . with_structured_output ( structured_schema , method = \"function_calling\" , ) result = await llm_structured . ainvoke ( prompt ) logger . debug ( f \"Structured LLM call executed using schema= { structured_schema . __name__ } \" ) return result # standard text generation mode response = await llm . ainvoke ( prompt ) logger . debug ( \"Text LLM call executed successfully.\" ) text = getattr ( response , \"content\" , str ( response )) return text . strip () except Exception as e : logger . exception ( f \"LLM call failed: { e } \" ) raise # ========================================================= # Context Builder # ========================================================= async def build_context ( self , * , base_context : Optional [ dict [ str , Any ]] = None , temperature : Optional [ float ] = None , ) -> dict [ str , Any ]: \"\"\" Builds or enriches session context using regulatory reasoning. \"\"\" context = dict ( base_context or {}) prompt = get_context_prompt () formatted_prompt = prompt . format ( context_json = context ) response = await self . _llm_call ( formatted_prompt , structured_schema = ContextSummaryModel , temperature = temperature or self . temperature , ) # If response is a Pydantic model instance, use its .model_dump() method context [ \"summary\" ] = response . model_dump () logger . info ( f \"Context successfully built via model { self . model_name } \" ) return context # ========================================================= # Section Grouper # ========================================================= async def group_sections ( self , sections : list [ dict [ str , Any ]], context : dict [ str , Any ], * , component_name : str | None = None , temperature : Optional [ float ] = 0.6 , # Higher temperature for more thoughtful analysis batch_size : int = 25 , # Smaller batches for deeper focus max_concurrency : int = 3 , # Reduced concurrency for more careful processing ) -> list [ dict [ str , Any ]]: \"\"\" Groups sections semantically using GPT structured output with DEEP ANALYSIS. Performs comprehensive regulatory analysis by: - Analyzing both titles AND full descriptions - Using higher temperature for thoughtful reasoning - Smaller batch sizes for focused analysis - Single best-fit group assignment per section - Detailed timing and assignment statistics Returns: [{\"group\": str, \"sections\": [...] }] with single assignment per section \"\"\" # ------------------------------------------------------------ # Split sections into manageable batches # ------------------------------------------------------------ logger . info ( \">>>>>>>>>>>>>>>>>\" ) total_sections = len ( sections ) batches = [ sections [ i : i + batch_size ] for i in range ( 0 , total_sections , batch_size )] logger . info ( f \"Processing { total_sections } sections in { len ( batches ) } batches (batch size= { batch_size } , max_concurrency= { max_concurrency } ).\" ) # ------------------------------------------------------------ # Prepare title index for mapping back # ------------------------------------------------------------ title_index = { s [ \"title\" ]: s for s in sections } merged_groups : dict [ str , list [ dict [ str , Any ]]] = {} semaphore = asyncio . Semaphore ( max_concurrency ) # ------------------------------------------------------------ # Helper to process a single batch # ------------------------------------------------------------ async def _process_batch ( batch : list [ dict [ str , Any ]], batch_num : int , component_name : str ) -> GroupingModel : async with semaphore : # Create detailed sections with titles AND descriptions for analysis sections_with_descriptions = [] for i , section in enumerate ( batch , 1 ): title = section . get ( \"title\" , \"Untitled Section\" ) description = section . get ( \"description\" , \"No description available\" ) # Truncate very long descriptions to avoid token limits if len ( description ) > 500 : description = description [: 497 ] + \"...\" sections_with_descriptions . append ( f \" { i } . TITLE: { title } \\n DESCRIPTION: { description } \\n \" ) sections_text = \" \\n \" . join ( sections_with_descriptions ) logger . debug ( f \"[Batch { batch_num } ] Deep analysis of { len ( batch ) } sectizons with full descriptions.\" ) prompt = get_grouping_prompt () formatted_prompt = prompt . format ( context_summary = context . get ( \"summary\" , \"N/A\" ), sections_with_descriptions = sections_text , component_name = component_name , ) # Structured JSON call per batch with timing import time start_time = time . perf_counter () response : GroupingModel = await self . _llm_call ( formatted_prompt , structured_schema = GroupingModel , temperature = temperature , ) processing_time = round ( time . perf_counter () - start_time , 2 ) # Calculate assignment statistics for this batch total_assignments = sum ( len ( group . sections ) for group in response . groups ) batch_sections = len ( batch ) logger . info ( f \"[Batch { batch_num } ] Deep analysis completed in { processing_time } s\" ) logger . info ( f \"[Batch { batch_num } ] Single assignments: { total_assignments } / { batch_sections } sections assigned\" ) return response # ------------------------------------------------------------ # 4\ufe0f\u20e3 Run all batches in parallel # ------------------------------------------------------------ tasks = [ asyncio . create_task ( _process_batch ( batch , i + 1 , component_name or \"unknown\" )) for i , batch in enumerate ( batches )] responses = await asyncio . gather ( * tasks ) logger . info ( f \"All { len ( responses ) } batches completed.\" ) # ------------------------------------------------------------ # 5\ufe0f\u20e3 Merge grouped results from all batches (SINGLE ASSIGNMENT ONLY) # ------------------------------------------------------------ for batch_idx , response in enumerate ( responses , start = 1 ): batch_mapped_count = 0 for group in response . groups : mapped_sections = [ title_index [ t ] for t in group . sections if t in title_index ] if group . name not in merged_groups : merged_groups [ group . name ] = [] merged_groups [ group . name ] . extend ( mapped_sections ) batch_mapped_count += len ( mapped_sections ) logger . info ( f \"[Batch { batch_idx } ] Added { len ( response . groups ) } groups with { batch_mapped_count } sections.\" ) # ------------------------------------------------------------ # 6\ufe0f\u20e3 Handle any missing titles (fallback for single assignments) # ------------------------------------------------------------ all_mapped_titles = { s [ \"title\" ] for g in merged_groups . values () for s in g } missing_sections = [ s for s in sections if s [ \"title\" ] not in all_mapped_titles ] if missing_sections : logger . warning ( f \" { len ( missing_sections ) } sections were unassigned \u2014 adding to 'Miscellaneous'.\" ) merged_groups . setdefault ( \"Miscellaneous\" , []) . extend ( missing_sections ) # ------------------------------------------------------------ # 7\ufe0f\u20e3 Final structured result (single assignment per section) # ------------------------------------------------------------ grouped_sections = [{ \"group\" : name , \"sections\" : secs } for name , secs in merged_groups . items ()] # Calculate statistics for single assignments total_assigned = sum ( len ( secs ) for secs in merged_groups . values ()) total_sections = len ( sections ) logger . info ( f \"\u2705 Grouped { total_sections } sections into { len ( grouped_sections ) } groups.\" ) logger . info ( f \"\ud83d\udcca Assignment: { total_assigned } / { total_sections } sections assigned (single assignment per section).\" ) return grouped_sections # ========================================================= # Section Generator # ========================================================= async def generate_section ( self , session_id : str , section : dict [ str , Any ], context : dict [ str , Any ], component_name : str , group_name : str , * , temperature : Optional [ float ] = 0.4 , ) -> dict [ str , Any ]: \"\"\" Generates the reasoning or compliance mapping for a single section. Returns: structured dict with standard, applicability, and justification. \"\"\" title = section . get ( \"title\" , \"Unnamed Section\" ) body = section . get ( \"body\" , \"\" ) summary = context . get ( \"summary\" , \"\" ) prompt = ( f \"You are an expert in regulatory compliance. \\n \" f \"Section Title: { title } \\n \" f \"Group: { group_name } \\n \" f \"Component: { component_name } \\n\\n \" f \"Session Summary: \\n { summary } \\n\\n \" f \"Section Text: \\n { body } \\n\\n \" f \"CRITICAL: You MUST respond in the exact format below. Do not include explanations or additional text. \\n\\n \" f \"Tasks: \\n \" f \"1. Identify ONE most relevant regulatory standard (ISO/FDA/MDR) \\n \" f \"2. Decide if this requirement is applicable (yes/no) \\n \" f \"3. Provide a brief justification (maximum 8 words) \\n\\n \" f \"REQUIRED FORMAT (copy exactly): \\n \" f \"STANDARD: [standard name only] \\n \" f \"APPLICABLE: [yes or no] \\n \" f \"JUSTIFICATION: [brief reason] \\n\\n \" f \"Good Examples: \\n \" f \"STANDARD: ISO 13485 \\n \" f \"APPLICABLE: yes \\n \" f \"JUSTIFICATION: Supplier responsibility per QMS procedure \\n\\n \" f \"STANDARD: FDA 21 CFR 820 \\n \" f \"APPLICABLE: no \\n \" f \"JUSTIFICATION: Not relevant for device type \\n\\n \" f \"STANDARD: None \\n \" f \"APPLICABLE: no \\n \" f \"JUSTIFICATION: Outside regulatory scope \\n\\n \" f \"Respond ONLY in the required format above.\" ) response = await self . _llm_call ( prompt , temperature = temperature ) # Parse the structured response standard = \"None\" applicable = False justification = \"Not specified\" logger . debug ( f \"Raw LLM response for section { title } : { response } \" ) try : lines = response . strip () . split ( \" \\n \" ) for line in lines : line = line . strip () if line . startswith ( \"STANDARD:\" ): standard = line . replace ( \"STANDARD:\" , \"\" ) . strip () if not standard : standard = \"None\" elif line . startswith ( \"APPLICABLE:\" ): applicable = \"yes\" in line . lower () elif line . startswith ( \"JUSTIFICATION:\" ): justification = line . replace ( \"JUSTIFICATION:\" , \"\" ) . strip () if not justification : justification = \"Not specified\" # Validate parsing results if standard == \"None\" and justification == \"Not specified\" and not applicable : logger . warning ( f \"LLM response parsing may have failed for section { title } . Using fallback.\" ) # Fallback parsing for unstructured response if \"iso\" in response . lower (): standard = \"ISO Standard\" elif \"fda\" in response . lower (): standard = \"FDA Regulation\" elif \"mdr\" in response . lower (): standard = \"MDR Regulation\" applicable = \"yes\" in response . lower () or \"applicable\" in response . lower () justification = \"LLM response format not structured\" except Exception as e : logger . error ( f \"Failed to parse LLM response for section { title } : { e } \" ) logger . error ( f \"Raw response was: { response } \" ) # Fallback parsing applicable = \"yes\" in response . lower () justification = \"Response parsing failed\" standard = \"Unknown\" # Ensure we have valid values if not standard or standard . strip () == \"\" : standard = \"None\" if not justification or justification . strip () == \"\" : justification = \"Not specified\" logger . info ( f \"Section { title } - Standard: { standard } , Applicable: { applicable } , Justification: { justification } \" ) result = { \"standard\" : standard , \"is_applicable\" : applicable , \"requirement_type\" : section . get ( \"requirement_type\" , \"Unknown\" ), \"requirement_justification\" : justification , \"status\" : \"success\" if applicable else \"skipped\" , } # Add result to session manager if provided try : from regulatory.app.core.state import get_session_manager session_mgr = get_session_manager () if session_mgr and session_id : # Create section result payload section_result = { \"section_id\" : section . get ( \"id\" , f \"section_ { title . replace ( ' ' , '_' ) } \" ), \"section_title\" : title , \"group_name\" : group_name , \"component_name\" : component_name , \"result\" : result , \"timestamp\" : time . time (), } # Use proper nested dictionary structure (not dot notation) update_payload = { \"gspr_section_results\" : { section_result [ \"section_id\" ]: section_result }} success = session_mgr . update_nested ( session_id , update_payload ) if success : logger . debug ( f \"\u2705 Added GSPR result for section ' { title } ' to session { session_id } \" ) else : logger . warning ( f \"\u26a0\ufe0f Failed to add GSPR result for section ' { title } ' to session { session_id } \" ) except Exception as e : logger . warning ( f \"Failed to update session manager: { e } \" ) logger . debug ( f \"Generated reasoning for ' { title } ' \u2192 { result [ 'standard' ] } \" ) return result async def determine_temperature ( self , node_title : str , context : dict [ str , Any ]) -> float : \"\"\" Ask the LLM to self-select an appropriate temperature between 0.1\u20130.9. This helps the system decide how deterministic or creative to be. \"\"\" prompt = get_temperature_prompt () structured_llm = self . small_llm . with_structured_output ( TemperatureModel ) temperature_chain = prompt | structured_llm inputs = { \"context_summary\" : context . get ( \"summary\" , \"N/A\" ), \"node_title\" : node_title or \"Unnamed Node\" , } try : result : TemperatureModel = cast ( TemperatureModel , await temperature_chain . ainvoke ( inputs )) temp_value = float ( result . temperature ) temp_value = max ( 0.1 , min ( 0.9 , temp_value )) logger . info ( f \"Structured LLM chose adaptive temperature: { temp_value } \" ) return temp_value except Exception as e : logger . exception ( f \"Structured temperature selection failed: { e } \" ) return 0.3 build_context ( * , base_context = None , temperature = None ) async Builds or enriches session context using regulatory reasoning. Source code in core/chains/gspr_chain.py 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 async def build_context ( self , * , base_context : Optional [ dict [ str , Any ]] = None , temperature : Optional [ float ] = None , ) -> dict [ str , Any ]: \"\"\" Builds or enriches session context using regulatory reasoning. \"\"\" context = dict ( base_context or {}) prompt = get_context_prompt () formatted_prompt = prompt . format ( context_json = context ) response = await self . _llm_call ( formatted_prompt , structured_schema = ContextSummaryModel , temperature = temperature or self . temperature , ) # If response is a Pydantic model instance, use its .model_dump() method context [ \"summary\" ] = response . model_dump () logger . info ( f \"Context successfully built via model { self . model_name } \" ) return context determine_temperature ( node_title , context ) async Ask the LLM to self-select an appropriate temperature between 0.1\u20130.9. This helps the system decide how deterministic or creative to be. Source code in core/chains/gspr_chain.py 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 async def determine_temperature ( self , node_title : str , context : dict [ str , Any ]) -> float : \"\"\" Ask the LLM to self-select an appropriate temperature between 0.1\u20130.9. This helps the system decide how deterministic or creative to be. \"\"\" prompt = get_temperature_prompt () structured_llm = self . small_llm . with_structured_output ( TemperatureModel ) temperature_chain = prompt | structured_llm inputs = { \"context_summary\" : context . get ( \"summary\" , \"N/A\" ), \"node_title\" : node_title or \"Unnamed Node\" , } try : result : TemperatureModel = cast ( TemperatureModel , await temperature_chain . ainvoke ( inputs )) temp_value = float ( result . temperature ) temp_value = max ( 0.1 , min ( 0.9 , temp_value )) logger . info ( f \"Structured LLM chose adaptive temperature: { temp_value } \" ) return temp_value except Exception as e : logger . exception ( f \"Structured temperature selection failed: { e } \" ) return 0.3 generate_section ( session_id , section , context , component_name , group_name , * , temperature = 0.4 ) async Generates the reasoning or compliance mapping for a single section. Returns: structured dict with standard, applicability, and justification. Source code in core/chains/gspr_chain.py 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 async def generate_section ( self , session_id : str , section : dict [ str , Any ], context : dict [ str , Any ], component_name : str , group_name : str , * , temperature : Optional [ float ] = 0.4 , ) -> dict [ str , Any ]: \"\"\" Generates the reasoning or compliance mapping for a single section. Returns: structured dict with standard, applicability, and justification. \"\"\" title = section . get ( \"title\" , \"Unnamed Section\" ) body = section . get ( \"body\" , \"\" ) summary = context . get ( \"summary\" , \"\" ) prompt = ( f \"You are an expert in regulatory compliance. \\n \" f \"Section Title: { title } \\n \" f \"Group: { group_name } \\n \" f \"Component: { component_name } \\n\\n \" f \"Session Summary: \\n { summary } \\n\\n \" f \"Section Text: \\n { body } \\n\\n \" f \"CRITICAL: You MUST respond in the exact format below. Do not include explanations or additional text. \\n\\n \" f \"Tasks: \\n \" f \"1. Identify ONE most relevant regulatory standard (ISO/FDA/MDR) \\n \" f \"2. Decide if this requirement is applicable (yes/no) \\n \" f \"3. Provide a brief justification (maximum 8 words) \\n\\n \" f \"REQUIRED FORMAT (copy exactly): \\n \" f \"STANDARD: [standard name only] \\n \" f \"APPLICABLE: [yes or no] \\n \" f \"JUSTIFICATION: [brief reason] \\n\\n \" f \"Good Examples: \\n \" f \"STANDARD: ISO 13485 \\n \" f \"APPLICABLE: yes \\n \" f \"JUSTIFICATION: Supplier responsibility per QMS procedure \\n\\n \" f \"STANDARD: FDA 21 CFR 820 \\n \" f \"APPLICABLE: no \\n \" f \"JUSTIFICATION: Not relevant for device type \\n\\n \" f \"STANDARD: None \\n \" f \"APPLICABLE: no \\n \" f \"JUSTIFICATION: Outside regulatory scope \\n\\n \" f \"Respond ONLY in the required format above.\" ) response = await self . _llm_call ( prompt , temperature = temperature ) # Parse the structured response standard = \"None\" applicable = False justification = \"Not specified\" logger . debug ( f \"Raw LLM response for section { title } : { response } \" ) try : lines = response . strip () . split ( \" \\n \" ) for line in lines : line = line . strip () if line . startswith ( \"STANDARD:\" ): standard = line . replace ( \"STANDARD:\" , \"\" ) . strip () if not standard : standard = \"None\" elif line . startswith ( \"APPLICABLE:\" ): applicable = \"yes\" in line . lower () elif line . startswith ( \"JUSTIFICATION:\" ): justification = line . replace ( \"JUSTIFICATION:\" , \"\" ) . strip () if not justification : justification = \"Not specified\" # Validate parsing results if standard == \"None\" and justification == \"Not specified\" and not applicable : logger . warning ( f \"LLM response parsing may have failed for section { title } . Using fallback.\" ) # Fallback parsing for unstructured response if \"iso\" in response . lower (): standard = \"ISO Standard\" elif \"fda\" in response . lower (): standard = \"FDA Regulation\" elif \"mdr\" in response . lower (): standard = \"MDR Regulation\" applicable = \"yes\" in response . lower () or \"applicable\" in response . lower () justification = \"LLM response format not structured\" except Exception as e : logger . error ( f \"Failed to parse LLM response for section { title } : { e } \" ) logger . error ( f \"Raw response was: { response } \" ) # Fallback parsing applicable = \"yes\" in response . lower () justification = \"Response parsing failed\" standard = \"Unknown\" # Ensure we have valid values if not standard or standard . strip () == \"\" : standard = \"None\" if not justification or justification . strip () == \"\" : justification = \"Not specified\" logger . info ( f \"Section { title } - Standard: { standard } , Applicable: { applicable } , Justification: { justification } \" ) result = { \"standard\" : standard , \"is_applicable\" : applicable , \"requirement_type\" : section . get ( \"requirement_type\" , \"Unknown\" ), \"requirement_justification\" : justification , \"status\" : \"success\" if applicable else \"skipped\" , } # Add result to session manager if provided try : from regulatory.app.core.state import get_session_manager session_mgr = get_session_manager () if session_mgr and session_id : # Create section result payload section_result = { \"section_id\" : section . get ( \"id\" , f \"section_ { title . replace ( ' ' , '_' ) } \" ), \"section_title\" : title , \"group_name\" : group_name , \"component_name\" : component_name , \"result\" : result , \"timestamp\" : time . time (), } # Use proper nested dictionary structure (not dot notation) update_payload = { \"gspr_section_results\" : { section_result [ \"section_id\" ]: section_result }} success = session_mgr . update_nested ( session_id , update_payload ) if success : logger . debug ( f \"\u2705 Added GSPR result for section ' { title } ' to session { session_id } \" ) else : logger . warning ( f \"\u26a0\ufe0f Failed to add GSPR result for section ' { title } ' to session { session_id } \" ) except Exception as e : logger . warning ( f \"Failed to update session manager: { e } \" ) logger . debug ( f \"Generated reasoning for ' { title } ' \u2192 { result [ 'standard' ] } \" ) return result group_sections ( sections , context , * , component_name = None , temperature = 0.6 , batch_size = 25 , max_concurrency = 3 ) async Groups sections semantically using GPT structured output with DEEP ANALYSIS. Performs comprehensive regulatory analysis by: - Analyzing both titles AND full descriptions - Using higher temperature for thoughtful reasoning - Smaller batch sizes for focused analysis - Single best-fit group assignment per section - Detailed timing and assignment statistics Returns: [{\"group\": str, \"sections\": [...] }] with single assignment per section Source code in core/chains/gspr_chain.py 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 async def group_sections ( self , sections : list [ dict [ str , Any ]], context : dict [ str , Any ], * , component_name : str | None = None , temperature : Optional [ float ] = 0.6 , # Higher temperature for more thoughtful analysis batch_size : int = 25 , # Smaller batches for deeper focus max_concurrency : int = 3 , # Reduced concurrency for more careful processing ) -> list [ dict [ str , Any ]]: \"\"\" Groups sections semantically using GPT structured output with DEEP ANALYSIS. Performs comprehensive regulatory analysis by: - Analyzing both titles AND full descriptions - Using higher temperature for thoughtful reasoning - Smaller batch sizes for focused analysis - Single best-fit group assignment per section - Detailed timing and assignment statistics Returns: [{\"group\": str, \"sections\": [...] }] with single assignment per section \"\"\" # ------------------------------------------------------------ # Split sections into manageable batches # ------------------------------------------------------------ logger . info ( \">>>>>>>>>>>>>>>>>\" ) total_sections = len ( sections ) batches = [ sections [ i : i + batch_size ] for i in range ( 0 , total_sections , batch_size )] logger . info ( f \"Processing { total_sections } sections in { len ( batches ) } batches (batch size= { batch_size } , max_concurrency= { max_concurrency } ).\" ) # ------------------------------------------------------------ # Prepare title index for mapping back # ------------------------------------------------------------ title_index = { s [ \"title\" ]: s for s in sections } merged_groups : dict [ str , list [ dict [ str , Any ]]] = {} semaphore = asyncio . Semaphore ( max_concurrency ) # ------------------------------------------------------------ # Helper to process a single batch # ------------------------------------------------------------ async def _process_batch ( batch : list [ dict [ str , Any ]], batch_num : int , component_name : str ) -> GroupingModel : async with semaphore : # Create detailed sections with titles AND descriptions for analysis sections_with_descriptions = [] for i , section in enumerate ( batch , 1 ): title = section . get ( \"title\" , \"Untitled Section\" ) description = section . get ( \"description\" , \"No description available\" ) # Truncate very long descriptions to avoid token limits if len ( description ) > 500 : description = description [: 497 ] + \"...\" sections_with_descriptions . append ( f \" { i } . TITLE: { title } \\n DESCRIPTION: { description } \\n \" ) sections_text = \" \\n \" . join ( sections_with_descriptions ) logger . debug ( f \"[Batch { batch_num } ] Deep analysis of { len ( batch ) } sectizons with full descriptions.\" ) prompt = get_grouping_prompt () formatted_prompt = prompt . format ( context_summary = context . get ( \"summary\" , \"N/A\" ), sections_with_descriptions = sections_text , component_name = component_name , ) # Structured JSON call per batch with timing import time start_time = time . perf_counter () response : GroupingModel = await self . _llm_call ( formatted_prompt , structured_schema = GroupingModel , temperature = temperature , ) processing_time = round ( time . perf_counter () - start_time , 2 ) # Calculate assignment statistics for this batch total_assignments = sum ( len ( group . sections ) for group in response . groups ) batch_sections = len ( batch ) logger . info ( f \"[Batch { batch_num } ] Deep analysis completed in { processing_time } s\" ) logger . info ( f \"[Batch { batch_num } ] Single assignments: { total_assignments } / { batch_sections } sections assigned\" ) return response # ------------------------------------------------------------ # 4\ufe0f\u20e3 Run all batches in parallel # ------------------------------------------------------------ tasks = [ asyncio . create_task ( _process_batch ( batch , i + 1 , component_name or \"unknown\" )) for i , batch in enumerate ( batches )] responses = await asyncio . gather ( * tasks ) logger . info ( f \"All { len ( responses ) } batches completed.\" ) # ------------------------------------------------------------ # 5\ufe0f\u20e3 Merge grouped results from all batches (SINGLE ASSIGNMENT ONLY) # ------------------------------------------------------------ for batch_idx , response in enumerate ( responses , start = 1 ): batch_mapped_count = 0 for group in response . groups : mapped_sections = [ title_index [ t ] for t in group . sections if t in title_index ] if group . name not in merged_groups : merged_groups [ group . name ] = [] merged_groups [ group . name ] . extend ( mapped_sections ) batch_mapped_count += len ( mapped_sections ) logger . info ( f \"[Batch { batch_idx } ] Added { len ( response . groups ) } groups with { batch_mapped_count } sections.\" ) # ------------------------------------------------------------ # 6\ufe0f\u20e3 Handle any missing titles (fallback for single assignments) # ------------------------------------------------------------ all_mapped_titles = { s [ \"title\" ] for g in merged_groups . values () for s in g } missing_sections = [ s for s in sections if s [ \"title\" ] not in all_mapped_titles ] if missing_sections : logger . warning ( f \" { len ( missing_sections ) } sections were unassigned \u2014 adding to 'Miscellaneous'.\" ) merged_groups . setdefault ( \"Miscellaneous\" , []) . extend ( missing_sections ) # ------------------------------------------------------------ # 7\ufe0f\u20e3 Final structured result (single assignment per section) # ------------------------------------------------------------ grouped_sections = [{ \"group\" : name , \"sections\" : secs } for name , secs in merged_groups . items ()] # Calculate statistics for single assignments total_assigned = sum ( len ( secs ) for secs in merged_groups . values ()) total_sections = len ( sections ) logger . info ( f \"\u2705 Grouped { total_sections } sections into { len ( grouped_sections ) } groups.\" ) logger . info ( f \"\ud83d\udcca Assignment: { total_assigned } / { total_sections } sections assigned (single assignment per section).\" ) return grouped_sections \ud83c\udfd7\ufe0f GSPR Generator Chain \u2014 Build GSPR Documentation Automatically generates structured GSPR compliance documentation , mapping requirements to device characteristics. Ensures consistency, traceability, and audit-ready formatting. This module builds and initializes the GSPR (General Safety and Performance Requirements) generator chain. It prepares the PromptTemplate, loads the LLM backend, and wraps it with a structured output model to generate high-quality, schema-validated GSPR entries. Workflow: Create a PromptTemplate based on the GSPR generator prompt string. Load the configured vLLM model using the internal LLM provider. Wrap the model with structured output using GSPRGeneratorModel . Construct a runnable chain: prompt \u2192 LLM \u2192 structured output. This chain is used by the system to produce consistent, validated, and regulatory-aligned GSPR entries for varied medical devices. prompt = PromptTemplate ( template = GSPR_GENERATOR_PROMPT , input_variables = [ 'medical_device' , 'material_type' , 'device_type' , 'intended_purpose' , 'intended_users' , 'risk_classifications' , 'component' , 'gspr' ]) module-attribute PromptTemplate Defines the template used by the GSPR generator. It inserts dynamic fields such as the medical device type, intended purpose, component details, and specific GSPR requirements. This template ensures all contextual inputs are passed into the LLM in a structured format. get_gspr_generator_chain () Get GSPR generator chain with current model selection. Source code in core/chains/gspr_generator_chain.py 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 def get_gspr_generator_chain (): \"\"\"Get GSPR generator chain with current model selection.\"\"\" logger . info ( \"Creating GSPR generator chain with current model...\" ) gspr_generator_llm = get_gspr_generator_llm () chain = prompt | gspr_generator_llm \"\"\" GSPR Generator Chain: Creates the final chain by piping: PromptTemplate \u2192 LLM \u2192 Structured Output. This runnable chain is used throughout the application to generate GSPR-compliant entries with deterministic structure and high-quality regulatory reasoning. \"\"\" logger . info ( \"GSPR generator chain initialized.\" ) return chain get_gspr_generator_llm () Get LLM instance with current model selection for runtime switching. Source code in core/chains/gspr_generator_chain.py 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 def get_gspr_generator_llm (): \"\"\"Get LLM instance with current model selection for runtime switching.\"\"\" logger . info ( \"Creating GSPR generator LLM instance with current model selection...\" ) try : llm = get_vllm_llm () \"\"\" LLM Loader: Loads the vLLM backend configured for regulatory text generation. The model is optimized for structured compliance reasoning and supports high-volume inference. \"\"\" logger . info ( \"LLM initialized successfully.\" ) return llm . with_structured_output ( GSPRGeneratorModel ) except Exception as e : logger . exception ( f \"Failed to initialize LLM - { str ( e ) } \" ) raise \ud83d\udea8 Guard Chain \u2014 Apply Rule-Based Validations Implements safety, logic, and regulatory guards on user inputs and generated outputs. Prevents invalid data, enforces constraints, and ensures workflow integrity. get_guard_chain () Get guard chain with current model selection. Source code in core/chains/guard_chain.py 62 63 64 65 66 67 68 def get_guard_chain (): \"\"\"Get guard chain with current model selection.\"\"\" logger . info ( \"Creating guard chain with current model...\" ) llm = get_guard_llm () chain = prompt | llm logger . info ( \"Guard chain initialized successfully.\" ) return chain get_guard_llm () Get LLM instance with current model selection for runtime switching. Source code in core/chains/guard_chain.py 37 38 39 40 41 42 43 44 45 46 def get_guard_llm (): \"\"\"Get LLM instance with current model selection for runtime switching.\"\"\" logger . info ( \"Creating guard LLM instance with current model selection...\" ) try : llm = get_vllm_llm () logger . info ( \"LLM initialized successfully.\" ) return llm except Exception as e : logger . exception ( f \"Failed to initialize LLM - { str ( e ) } \" ) raise \ud83d\udc65 Intended User Chain \u2014 Identify Expected User Profiles Analyzes device context to determine intended users , such as clinicians, technicians, or patients. Ensures user-centric design alignment with regulatory assessment standards . prompt = PromptTemplate ( template = INTENDED_USER_PROMPT , input_variables = [ 'medical_device' , 'device_type' , 'intended_purpose' , 'material_type' , 'components' , 'risk_classification' ]) module-attribute Retrieve the intended user LLM instance. This function initializes and returns a language model (LLM) instance configured for the intended user chain. The LLM is structured to generate outputs based on device type, intended purpose, and other inputs. Returns: Name Type Description LLM A language model instance configured with the IntendedUserModel. Raises: Type Description Exception If the LLM initialization fails. Example llm = get_intended_user_llm() response = llm.invoke({\"device_type\": \"Sensor\", \"intended_purpose\": \"Monitoring\"}) get_intended_user_chain () Get intended user chain with current model selection. Source code in core/chains/intended_user_chain.py 71 72 73 74 75 76 77 def get_intended_user_chain (): \"\"\"Get intended user chain with current model selection.\"\"\" logger . info ( \"Creating intended user chain with current model...\" ) intended_user_llm = get_intended_user_llm () chain = prompt | intended_user_llm logger . info ( \"Intended user chain created successfully.\" ) return chain get_intended_user_llm () Get LLM instance with current model selection for runtime switching. Source code in core/chains/intended_user_chain.py 45 46 47 48 49 50 51 52 53 54 55 def get_intended_user_llm (): \"\"\"Get LLM instance with current model selection for runtime switching.\"\"\" logger . info ( \"Creating intended user LLM instance with current model selection...\" ) try : llm = get_vllm_llm () logger . info ( \"LLM initialized successfully.\" ) return llm . with_structured_output ( IntendedUserModel ) except Exception as e : logger . exception ( \"Failed to initialize LLM: %s \" , e ) logger . info ( f \"LLM initialization exception message: { e } \" ) raise \ud83e\uddea Risk Classification Chain \u2014 Determine Device Risk Class Evaluates device properties to assign the correct risk class under GSPR frameworks. Supports consistent classification logic required for regulatory pathways. get_llm_for_region ( region ) Return appropriate LLM based on region. Source code in core/chains/risk_classification_chain.py 33 34 35 36 37 38 39 40 def get_llm_for_region ( region : str ): \"\"\"Return appropriate LLM based on region.\"\"\" if region . lower () in [ \"eu\" , \"india\" ]: return get_chatmdr_llm () elif region . lower () == \"us\" : return get_chatfda_llm () else : return get_vllm_llm () get_risk_classification_chain ( region = 'usa' ) Get risk classification chain with current model selection. Source code in core/chains/risk_classification_chain.py 93 94 95 96 97 98 99 def get_risk_classification_chain ( region : str = \"usa\" ): \"\"\"Get risk classification chain with current model selection.\"\"\" logger . info ( \"Creating risk classification chain with current model...\" ) risk_classification_llm = get_risk_classification_llm ( region ) chain = prompt | risk_classification_llm logger . info ( \"Risk classification chain created successfully.\" ) return chain get_risk_classification_llm ( region = 'usa' ) Get LLM instance with current model selection for runtime switching. Source code in core/chains/risk_classification_chain.py 64 65 66 67 68 69 70 71 72 73 def get_risk_classification_llm ( region : str = \"usa\" ): \"\"\"Get LLM instance with current model selection for runtime switching.\"\"\" logger . info ( f \"Creating risk classification LLM instance with current model selection for region ' { region } '...\" ) try : llm = get_llm_for_region ( region ) logger . info ( f \"LLM for region ' { region } ' initialized successfully.\" ) return llm . with_structured_output ( RiskClassificationModel , method = \"json_mode\" ) except Exception : logger . exception ( \"Failed to initialize LLM\" ) raise","title":"Chains Overview"},{"location":"ai_backend/chains_overview/#core-processing-chains-regulatory-ai","text":"","title":"\u2699\ufe0f Core Processing Chains \u2014 Regulatory AI"},{"location":"ai_backend/chains_overview/#component-recommender-chain-smart-component-suggestions","text":"Analyzes device attributes and intelligently proposes optimal components required for regulatory and technical completeness. Ensures alignment between device structure and regulatory expectations.","title":"\ud83d\udd27 Component Recommender Chain - Smart Component Suggestions"},{"location":"ai_backend/chains_overview/#core.chains.component_recommender_chain.get_component_recommender_chain","text":"Get component recommender chain with current model selection. Source code in core/chains/component_recommender_chain.py 61 62 63 64 65 66 67 def get_component_recommender_chain (): \"\"\"Get component recommender chain with current model selection.\"\"\" logger . info ( \"Creating component recommender chain with current model...\" ) component_recommender_llm = get_component_recommender_llm () chain = prompt | component_recommender_llm logger . info ( \"Component recommender chain created successfully.\" ) return chain","title":"get_component_recommender_chain"},{"location":"ai_backend/chains_overview/#core.chains.component_recommender_chain.get_component_recommender_llm","text":"Get LLM instance with current model selection for runtime switching. Source code in core/chains/component_recommender_chain.py 30 31 32 33 34 35 36 37 38 39 40 def get_component_recommender_llm (): \"\"\"Get LLM instance with current model selection for runtime switching.\"\"\" logger . info ( \"Creating LLM instance with current model selection...\" ) try : llm = get_vllm_llm () # This will use the current selected model logger . info ( \"LLM initialized successfully.\" ) return llm . with_structured_output ( ComponentRecommenderModel ) except Exception as e : logger . exception ( \"Failed to initialize LLM: %s \" , e ) logger . info ( f \"LLM initialization exception message: { e } \" ) raise","title":"get_component_recommender_llm"},{"location":"ai_backend/chains_overview/#design-input-chain-structure-validate-inputs","text":"Processes raw session data into structured design input specifications , ensuring clarity, consistency, and readiness for downstream modules. Acts as the foundation of compliant design documentation.","title":"\ud83d\udcdd Design Input Chain \u2014 Structure &amp; Validate Inputs"},{"location":"ai_backend/chains_overview/#core.chains.design_input_chain.driver","text":"Fetch design input details for a specific GSPR clause. This function queries the Neo4j database for details related to a specific GSPR clause, including requirement types, standards, and justifications. It then uses a language model to generate structured design input data. Parameters: Name Type Description Default device_meta dict Metadata about the device, including type, purpose, users, and risks. required component str The name of the component being processed. required gspr_no str The GSPR clause number to query. required Returns: Name Type Description DesignInputModel A structured model containing the design input details, including component, requirement, GSPR text, and associated standards. Example device_meta = { \"device_type\": \"Sensor\", \"intended_purpose\": \"Monitoring\", \"intended_users\": [\"Doctors\", \"Nurses\"], \"risk_classification\": \"Class II\" } design_input = fetch_design_input(device_meta, \"Sensor\", \"5.1\") Response: DesignInputModel( component=\"Sensor\", requirement=\"Safety\", gspr_text=\"Ensure device safety under normal conditions.\", standards=[...] )","title":"driver"},{"location":"ai_backend/chains_overview/#core.chains.design_input_chain.fetch_design_input","text":"Query Neo4j for a specific GSPRClause, fetch requirement type, standards, and run it through the LLM to generate structured output. Source code in core/chains/design_input_chain.py 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 def fetch_design_input ( device_meta : dict , component : str , gspr_no : str ) -> DesignInputModel : \"\"\" Query Neo4j for a specific GSPRClause, fetch requirement type, standards, and run it through the LLM to generate structured output. \"\"\" query = \"\"\" MATCH (g:GSPRClause {name: $gspr_no}) OPTIONAL MATCH (g)-[:HAS_TYPE]->(r:RequirementType) OPTIONAL MATCH (g)-[rel:ADDRESSED_BY]->(s:Standard) RETURN g.name AS gspr_no, g.text AS gspr_text, g.applicability AS applicability, r.name AS requirement, s.name AS standard, rel.justification AS justification \"\"\" standards_info = [] gspr_text = \"\" applicability = \"\" requirement = \"\" with driver . session ( database = NEO4J_DATABASE ) as session : results = session . run ( query , gspr_no = gspr_no ) for record in results : gspr_text = record [ \"gspr_text\" ] applicability = record [ \"applicability\" ] requirement = record [ \"requirement\" ] or \"\" if record [ \"standard\" ]: standards_info . append ({ \"standard\" : record [ \"standard\" ], \"justification\" : record [ \"justification\" ], \"gspr_text\" : gspr_text , \"applicability\" : applicability , \"requirement\" : requirement , }) if not standards_info : logger . warning ( f \"No standards found in KG for GSPR ' { gspr_no } '\" ) return DesignInputModel ( component = component , requirement = requirement , gspr_text = gspr_text , standards = []) # Build standards_context standards_context = \"\" for i , item in enumerate ( standards_info , start = 1 ): standards_context += f \"\"\" === Context for Standard { i } : { item [ 'standard' ] } === \u2022 Component: { component } \u2022 Requirement: { requirement } \u2022 GSPR Number: { gspr_no } \u2022 GSPR Clause Text: { item [ 'gspr_text' ] } \u2022 Applicability: { item [ 'applicability' ] } \u2022 Raw Justification (from KG): { item [ 'justification' ] } \"\"\" # Create prompt prompt = PromptTemplate ( template = DESIGN_INPUT_GENERATOR_PROMPT , input_variables = [ \"device_type\" , \"intended_purpose\" , \"intended_users\" , \"risk_classifications\" , \"component\" , \"requirement\" , \"gspr_no\" , \"gspr_text\" , \"standards_context\" , ], ) # Initialize LLM with structured output from regulatory.core.llm.llm_provider import get_vllm_llm llm = get_vllm_llm () design_input_llm = llm . with_structured_output ( DesignInputModel ) design_input_chain = prompt | design_input_llm chain_input = { \"device_type\" : device_meta . get ( \"device_type\" , \"\" ), \"intended_purpose\" : device_meta . get ( \"intended_purpose\" , \"\" ), \"intended_users\" : \", \" . join ( device_meta . get ( \"intended_users\" ) or []), \"risk_classifications\" : device_meta . get ( \"risk_classification\" , \"\" ), \"component\" : component , \"requirement\" : requirement , \"gspr_no\" : gspr_no , \"gspr_text\" : gspr_text , \"standards_context\" : standards_context , } logger . info ( f \"Fetching design input for component ' { component } ', GSPR ' { gspr_no } '\" ) response = design_input_chain . invoke ( chain_input ) return ( response if isinstance ( response , DesignInputModel ) else DesignInputModel ( ** response ) )","title":"fetch_design_input"},{"location":"ai_backend/chains_overview/#design-output-chain-transform-inputs-regulatory-outputs","text":"Converts finalized, validated design inputs into formalized regulatory design documents . Handles formatting, integrity checks, and delivery of compliant output packages.","title":"\ud83d\udce4 Design Output Chain \u2014 Transform Inputs \u2192 Regulatory Outputs"},{"location":"ai_backend/chains_overview/#core.chains.design_output_chain.run_design_output_chain","text":"Automatically generate a structured Design Output Report for a given medical device component. This function does not require user text or PDF references. Instead, it automatically utilizes the available design input data (device type, requirements, standards, and GSPR text) to produce a Design Output Report aligned with ISO/IEC standards. Parameters: Name Type Description Default design_input dict Dictionary containing design data, including: - device_type (str) - component (str) - requirement (str) - gspr_text (str) - standards (list[dict]) with 'name' and 'justification' fields required component str Name of the device component. required Returns: Name Type Description str Generated Design Output Report (formatted table with Clause, Category, Standard, and Output Statement). Source code in core/chains/design_output_chain.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 async def run_design_output_chain ( design_input : dict , component : str ): \"\"\" Automatically generate a structured Design Output Report for a given medical device component. This function does not require user text or PDF references. Instead, it automatically utilizes the available design input data (device type, requirements, standards, and GSPR text) to produce a Design Output Report aligned with ISO/IEC standards. Args: design_input (dict): Dictionary containing design data, including: - device_type (str) - component (str) - requirement (str) - gspr_text (str) - standards (list[dict]) with 'name' and 'justification' fields component (str): Name of the device component. Returns: str: Generated Design Output Report (formatted table with Clause, Category, Standard, and Output Statement). \"\"\" # Format standards context for LLM standards_context = \" \\n \" . join ( f \"=== Standard: { std . get ( 'name' , '' ) } === \\n Justification: { std . get ( 'justification' , '' ) } \" for std in design_input . get ( \"standards\" , []) ) # Prepare input payload for the LLM inputs = { \"device_type\" : design_input . get ( \"device_type\" , \"\" ), \"component\" : component , \"requirement\" : design_input . get ( \"requirement\" , \"\" ), \"gspr_text\" : design_input . get ( \"gspr_text\" , \"\" ), \"standards_context\" : standards_context , } logger . info ( f \"Running Design Output Chain for component: ' { component } ' (Auto ISO selection enabled)\" ) llm = get_vllm_llm () chain = prompt | llm # Execute asynchronously and return generated content result = await chain . ainvoke ( inputs ) return result . content","title":"run_design_output_chain"},{"location":"ai_backend/chains_overview/#gspr-chain-analyze-compliance-against-gspr","text":"Evaluates device details against General Safety & Performance Requirements (GSPR) . Identifies relevant clauses, compliance gaps, and required evidence for MDR conformity. GSPRChain \u2014 Prompt & LLM Execution Layer (Async) Responsibilities: - Build prompts for GSPR reasoning steps - Use LLM clients (from regulatory.core.llm) - Return structured results for each reasoning phase","title":"\ud83d\udee1\ufe0f GSPR Chain \u2014 Analyze Compliance Against GSPR"},{"location":"ai_backend/chains_overview/#core.chains.gspr_chain.GSPRChain","text":"Executes the core GSPR reasoning prompts using an async LLM client. This is a fully production implementation using the real GPT-4o model. Source code in core/chains/gspr_chain.py 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 class GSPRChain : \"\"\" Executes the core GSPR reasoning prompts using an async LLM client. This is a fully production implementation using the real GPT-4o model. \"\"\" def __init__ ( self , * , model_name : str = \"gpt-4o\" , small_model_name : str = \"gpt-4o-mini\" , temperature : float = 0.2 , component_name : str = \"unknown\" , ) -> None : self . model_name = model_name self . small_model_name = small_model_name self . temperature = temperature self . llm = get_vllm_llm ( model = model_name , temperature = temperature ) self . small_llm = get_vllm_llm ( model = small_model_name , temperature = 0.1 ) logger . info ( f \"GSPRChain initialized | main= { model_name } | small= { small_model_name } | temperature= { temperature } \" ) # ========================================================= # Internal Helper \u2014 Generic async LLM call (text or structured) # ========================================================= async def _llm_call ( self , prompt : str , * , temperature : Optional [ float ] = None , structured_schema : Optional [ type [ Any ]] = None , ) -> Any : \"\"\" Asynchronously call the configured LLM. Parameters ---------- prompt : str The formatted prompt text to send to the model. temperature : float, optional Override the default temperature for this specific call. structured_schema : pydantic.BaseModel | TypedDict | None If provided, returns structured output conforming to the schema using the model's `with_structured_output()` interface. Returns ------- Any - If `structured_schema` is None \u2192 str (LLM text output) - If `structured_schema` is provided \u2192 instance of schema \"\"\" try : # choose LLM instance if temperature and temperature != self . temperature : llm = get_vllm_llm ( model = self . model_name , temperature = temperature ) else : llm = self . llm # structured output mode if structured_schema is not None : llm_structured = llm . with_structured_output ( structured_schema , method = \"function_calling\" , ) result = await llm_structured . ainvoke ( prompt ) logger . debug ( f \"Structured LLM call executed using schema= { structured_schema . __name__ } \" ) return result # standard text generation mode response = await llm . ainvoke ( prompt ) logger . debug ( \"Text LLM call executed successfully.\" ) text = getattr ( response , \"content\" , str ( response )) return text . strip () except Exception as e : logger . exception ( f \"LLM call failed: { e } \" ) raise # ========================================================= # Context Builder # ========================================================= async def build_context ( self , * , base_context : Optional [ dict [ str , Any ]] = None , temperature : Optional [ float ] = None , ) -> dict [ str , Any ]: \"\"\" Builds or enriches session context using regulatory reasoning. \"\"\" context = dict ( base_context or {}) prompt = get_context_prompt () formatted_prompt = prompt . format ( context_json = context ) response = await self . _llm_call ( formatted_prompt , structured_schema = ContextSummaryModel , temperature = temperature or self . temperature , ) # If response is a Pydantic model instance, use its .model_dump() method context [ \"summary\" ] = response . model_dump () logger . info ( f \"Context successfully built via model { self . model_name } \" ) return context # ========================================================= # Section Grouper # ========================================================= async def group_sections ( self , sections : list [ dict [ str , Any ]], context : dict [ str , Any ], * , component_name : str | None = None , temperature : Optional [ float ] = 0.6 , # Higher temperature for more thoughtful analysis batch_size : int = 25 , # Smaller batches for deeper focus max_concurrency : int = 3 , # Reduced concurrency for more careful processing ) -> list [ dict [ str , Any ]]: \"\"\" Groups sections semantically using GPT structured output with DEEP ANALYSIS. Performs comprehensive regulatory analysis by: - Analyzing both titles AND full descriptions - Using higher temperature for thoughtful reasoning - Smaller batch sizes for focused analysis - Single best-fit group assignment per section - Detailed timing and assignment statistics Returns: [{\"group\": str, \"sections\": [...] }] with single assignment per section \"\"\" # ------------------------------------------------------------ # Split sections into manageable batches # ------------------------------------------------------------ logger . info ( \">>>>>>>>>>>>>>>>>\" ) total_sections = len ( sections ) batches = [ sections [ i : i + batch_size ] for i in range ( 0 , total_sections , batch_size )] logger . info ( f \"Processing { total_sections } sections in { len ( batches ) } batches (batch size= { batch_size } , max_concurrency= { max_concurrency } ).\" ) # ------------------------------------------------------------ # Prepare title index for mapping back # ------------------------------------------------------------ title_index = { s [ \"title\" ]: s for s in sections } merged_groups : dict [ str , list [ dict [ str , Any ]]] = {} semaphore = asyncio . Semaphore ( max_concurrency ) # ------------------------------------------------------------ # Helper to process a single batch # ------------------------------------------------------------ async def _process_batch ( batch : list [ dict [ str , Any ]], batch_num : int , component_name : str ) -> GroupingModel : async with semaphore : # Create detailed sections with titles AND descriptions for analysis sections_with_descriptions = [] for i , section in enumerate ( batch , 1 ): title = section . get ( \"title\" , \"Untitled Section\" ) description = section . get ( \"description\" , \"No description available\" ) # Truncate very long descriptions to avoid token limits if len ( description ) > 500 : description = description [: 497 ] + \"...\" sections_with_descriptions . append ( f \" { i } . TITLE: { title } \\n DESCRIPTION: { description } \\n \" ) sections_text = \" \\n \" . join ( sections_with_descriptions ) logger . debug ( f \"[Batch { batch_num } ] Deep analysis of { len ( batch ) } sectizons with full descriptions.\" ) prompt = get_grouping_prompt () formatted_prompt = prompt . format ( context_summary = context . get ( \"summary\" , \"N/A\" ), sections_with_descriptions = sections_text , component_name = component_name , ) # Structured JSON call per batch with timing import time start_time = time . perf_counter () response : GroupingModel = await self . _llm_call ( formatted_prompt , structured_schema = GroupingModel , temperature = temperature , ) processing_time = round ( time . perf_counter () - start_time , 2 ) # Calculate assignment statistics for this batch total_assignments = sum ( len ( group . sections ) for group in response . groups ) batch_sections = len ( batch ) logger . info ( f \"[Batch { batch_num } ] Deep analysis completed in { processing_time } s\" ) logger . info ( f \"[Batch { batch_num } ] Single assignments: { total_assignments } / { batch_sections } sections assigned\" ) return response # ------------------------------------------------------------ # 4\ufe0f\u20e3 Run all batches in parallel # ------------------------------------------------------------ tasks = [ asyncio . create_task ( _process_batch ( batch , i + 1 , component_name or \"unknown\" )) for i , batch in enumerate ( batches )] responses = await asyncio . gather ( * tasks ) logger . info ( f \"All { len ( responses ) } batches completed.\" ) # ------------------------------------------------------------ # 5\ufe0f\u20e3 Merge grouped results from all batches (SINGLE ASSIGNMENT ONLY) # ------------------------------------------------------------ for batch_idx , response in enumerate ( responses , start = 1 ): batch_mapped_count = 0 for group in response . groups : mapped_sections = [ title_index [ t ] for t in group . sections if t in title_index ] if group . name not in merged_groups : merged_groups [ group . name ] = [] merged_groups [ group . name ] . extend ( mapped_sections ) batch_mapped_count += len ( mapped_sections ) logger . info ( f \"[Batch { batch_idx } ] Added { len ( response . groups ) } groups with { batch_mapped_count } sections.\" ) # ------------------------------------------------------------ # 6\ufe0f\u20e3 Handle any missing titles (fallback for single assignments) # ------------------------------------------------------------ all_mapped_titles = { s [ \"title\" ] for g in merged_groups . values () for s in g } missing_sections = [ s for s in sections if s [ \"title\" ] not in all_mapped_titles ] if missing_sections : logger . warning ( f \" { len ( missing_sections ) } sections were unassigned \u2014 adding to 'Miscellaneous'.\" ) merged_groups . setdefault ( \"Miscellaneous\" , []) . extend ( missing_sections ) # ------------------------------------------------------------ # 7\ufe0f\u20e3 Final structured result (single assignment per section) # ------------------------------------------------------------ grouped_sections = [{ \"group\" : name , \"sections\" : secs } for name , secs in merged_groups . items ()] # Calculate statistics for single assignments total_assigned = sum ( len ( secs ) for secs in merged_groups . values ()) total_sections = len ( sections ) logger . info ( f \"\u2705 Grouped { total_sections } sections into { len ( grouped_sections ) } groups.\" ) logger . info ( f \"\ud83d\udcca Assignment: { total_assigned } / { total_sections } sections assigned (single assignment per section).\" ) return grouped_sections # ========================================================= # Section Generator # ========================================================= async def generate_section ( self , session_id : str , section : dict [ str , Any ], context : dict [ str , Any ], component_name : str , group_name : str , * , temperature : Optional [ float ] = 0.4 , ) -> dict [ str , Any ]: \"\"\" Generates the reasoning or compliance mapping for a single section. Returns: structured dict with standard, applicability, and justification. \"\"\" title = section . get ( \"title\" , \"Unnamed Section\" ) body = section . get ( \"body\" , \"\" ) summary = context . get ( \"summary\" , \"\" ) prompt = ( f \"You are an expert in regulatory compliance. \\n \" f \"Section Title: { title } \\n \" f \"Group: { group_name } \\n \" f \"Component: { component_name } \\n\\n \" f \"Session Summary: \\n { summary } \\n\\n \" f \"Section Text: \\n { body } \\n\\n \" f \"CRITICAL: You MUST respond in the exact format below. Do not include explanations or additional text. \\n\\n \" f \"Tasks: \\n \" f \"1. Identify ONE most relevant regulatory standard (ISO/FDA/MDR) \\n \" f \"2. Decide if this requirement is applicable (yes/no) \\n \" f \"3. Provide a brief justification (maximum 8 words) \\n\\n \" f \"REQUIRED FORMAT (copy exactly): \\n \" f \"STANDARD: [standard name only] \\n \" f \"APPLICABLE: [yes or no] \\n \" f \"JUSTIFICATION: [brief reason] \\n\\n \" f \"Good Examples: \\n \" f \"STANDARD: ISO 13485 \\n \" f \"APPLICABLE: yes \\n \" f \"JUSTIFICATION: Supplier responsibility per QMS procedure \\n\\n \" f \"STANDARD: FDA 21 CFR 820 \\n \" f \"APPLICABLE: no \\n \" f \"JUSTIFICATION: Not relevant for device type \\n\\n \" f \"STANDARD: None \\n \" f \"APPLICABLE: no \\n \" f \"JUSTIFICATION: Outside regulatory scope \\n\\n \" f \"Respond ONLY in the required format above.\" ) response = await self . _llm_call ( prompt , temperature = temperature ) # Parse the structured response standard = \"None\" applicable = False justification = \"Not specified\" logger . debug ( f \"Raw LLM response for section { title } : { response } \" ) try : lines = response . strip () . split ( \" \\n \" ) for line in lines : line = line . strip () if line . startswith ( \"STANDARD:\" ): standard = line . replace ( \"STANDARD:\" , \"\" ) . strip () if not standard : standard = \"None\" elif line . startswith ( \"APPLICABLE:\" ): applicable = \"yes\" in line . lower () elif line . startswith ( \"JUSTIFICATION:\" ): justification = line . replace ( \"JUSTIFICATION:\" , \"\" ) . strip () if not justification : justification = \"Not specified\" # Validate parsing results if standard == \"None\" and justification == \"Not specified\" and not applicable : logger . warning ( f \"LLM response parsing may have failed for section { title } . Using fallback.\" ) # Fallback parsing for unstructured response if \"iso\" in response . lower (): standard = \"ISO Standard\" elif \"fda\" in response . lower (): standard = \"FDA Regulation\" elif \"mdr\" in response . lower (): standard = \"MDR Regulation\" applicable = \"yes\" in response . lower () or \"applicable\" in response . lower () justification = \"LLM response format not structured\" except Exception as e : logger . error ( f \"Failed to parse LLM response for section { title } : { e } \" ) logger . error ( f \"Raw response was: { response } \" ) # Fallback parsing applicable = \"yes\" in response . lower () justification = \"Response parsing failed\" standard = \"Unknown\" # Ensure we have valid values if not standard or standard . strip () == \"\" : standard = \"None\" if not justification or justification . strip () == \"\" : justification = \"Not specified\" logger . info ( f \"Section { title } - Standard: { standard } , Applicable: { applicable } , Justification: { justification } \" ) result = { \"standard\" : standard , \"is_applicable\" : applicable , \"requirement_type\" : section . get ( \"requirement_type\" , \"Unknown\" ), \"requirement_justification\" : justification , \"status\" : \"success\" if applicable else \"skipped\" , } # Add result to session manager if provided try : from regulatory.app.core.state import get_session_manager session_mgr = get_session_manager () if session_mgr and session_id : # Create section result payload section_result = { \"section_id\" : section . get ( \"id\" , f \"section_ { title . replace ( ' ' , '_' ) } \" ), \"section_title\" : title , \"group_name\" : group_name , \"component_name\" : component_name , \"result\" : result , \"timestamp\" : time . time (), } # Use proper nested dictionary structure (not dot notation) update_payload = { \"gspr_section_results\" : { section_result [ \"section_id\" ]: section_result }} success = session_mgr . update_nested ( session_id , update_payload ) if success : logger . debug ( f \"\u2705 Added GSPR result for section ' { title } ' to session { session_id } \" ) else : logger . warning ( f \"\u26a0\ufe0f Failed to add GSPR result for section ' { title } ' to session { session_id } \" ) except Exception as e : logger . warning ( f \"Failed to update session manager: { e } \" ) logger . debug ( f \"Generated reasoning for ' { title } ' \u2192 { result [ 'standard' ] } \" ) return result async def determine_temperature ( self , node_title : str , context : dict [ str , Any ]) -> float : \"\"\" Ask the LLM to self-select an appropriate temperature between 0.1\u20130.9. This helps the system decide how deterministic or creative to be. \"\"\" prompt = get_temperature_prompt () structured_llm = self . small_llm . with_structured_output ( TemperatureModel ) temperature_chain = prompt | structured_llm inputs = { \"context_summary\" : context . get ( \"summary\" , \"N/A\" ), \"node_title\" : node_title or \"Unnamed Node\" , } try : result : TemperatureModel = cast ( TemperatureModel , await temperature_chain . ainvoke ( inputs )) temp_value = float ( result . temperature ) temp_value = max ( 0.1 , min ( 0.9 , temp_value )) logger . info ( f \"Structured LLM chose adaptive temperature: { temp_value } \" ) return temp_value except Exception as e : logger . exception ( f \"Structured temperature selection failed: { e } \" ) return 0.3","title":"GSPRChain"},{"location":"ai_backend/chains_overview/#core.chains.gspr_chain.GSPRChain.build_context","text":"Builds or enriches session context using regulatory reasoning. Source code in core/chains/gspr_chain.py 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 async def build_context ( self , * , base_context : Optional [ dict [ str , Any ]] = None , temperature : Optional [ float ] = None , ) -> dict [ str , Any ]: \"\"\" Builds or enriches session context using regulatory reasoning. \"\"\" context = dict ( base_context or {}) prompt = get_context_prompt () formatted_prompt = prompt . format ( context_json = context ) response = await self . _llm_call ( formatted_prompt , structured_schema = ContextSummaryModel , temperature = temperature or self . temperature , ) # If response is a Pydantic model instance, use its .model_dump() method context [ \"summary\" ] = response . model_dump () logger . info ( f \"Context successfully built via model { self . model_name } \" ) return context","title":"build_context"},{"location":"ai_backend/chains_overview/#core.chains.gspr_chain.GSPRChain.determine_temperature","text":"Ask the LLM to self-select an appropriate temperature between 0.1\u20130.9. This helps the system decide how deterministic or creative to be. Source code in core/chains/gspr_chain.py 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 async def determine_temperature ( self , node_title : str , context : dict [ str , Any ]) -> float : \"\"\" Ask the LLM to self-select an appropriate temperature between 0.1\u20130.9. This helps the system decide how deterministic or creative to be. \"\"\" prompt = get_temperature_prompt () structured_llm = self . small_llm . with_structured_output ( TemperatureModel ) temperature_chain = prompt | structured_llm inputs = { \"context_summary\" : context . get ( \"summary\" , \"N/A\" ), \"node_title\" : node_title or \"Unnamed Node\" , } try : result : TemperatureModel = cast ( TemperatureModel , await temperature_chain . ainvoke ( inputs )) temp_value = float ( result . temperature ) temp_value = max ( 0.1 , min ( 0.9 , temp_value )) logger . info ( f \"Structured LLM chose adaptive temperature: { temp_value } \" ) return temp_value except Exception as e : logger . exception ( f \"Structured temperature selection failed: { e } \" ) return 0.3","title":"determine_temperature"},{"location":"ai_backend/chains_overview/#core.chains.gspr_chain.GSPRChain.generate_section","text":"Generates the reasoning or compliance mapping for a single section. Returns: structured dict with standard, applicability, and justification. Source code in core/chains/gspr_chain.py 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 async def generate_section ( self , session_id : str , section : dict [ str , Any ], context : dict [ str , Any ], component_name : str , group_name : str , * , temperature : Optional [ float ] = 0.4 , ) -> dict [ str , Any ]: \"\"\" Generates the reasoning or compliance mapping for a single section. Returns: structured dict with standard, applicability, and justification. \"\"\" title = section . get ( \"title\" , \"Unnamed Section\" ) body = section . get ( \"body\" , \"\" ) summary = context . get ( \"summary\" , \"\" ) prompt = ( f \"You are an expert in regulatory compliance. \\n \" f \"Section Title: { title } \\n \" f \"Group: { group_name } \\n \" f \"Component: { component_name } \\n\\n \" f \"Session Summary: \\n { summary } \\n\\n \" f \"Section Text: \\n { body } \\n\\n \" f \"CRITICAL: You MUST respond in the exact format below. Do not include explanations or additional text. \\n\\n \" f \"Tasks: \\n \" f \"1. Identify ONE most relevant regulatory standard (ISO/FDA/MDR) \\n \" f \"2. Decide if this requirement is applicable (yes/no) \\n \" f \"3. Provide a brief justification (maximum 8 words) \\n\\n \" f \"REQUIRED FORMAT (copy exactly): \\n \" f \"STANDARD: [standard name only] \\n \" f \"APPLICABLE: [yes or no] \\n \" f \"JUSTIFICATION: [brief reason] \\n\\n \" f \"Good Examples: \\n \" f \"STANDARD: ISO 13485 \\n \" f \"APPLICABLE: yes \\n \" f \"JUSTIFICATION: Supplier responsibility per QMS procedure \\n\\n \" f \"STANDARD: FDA 21 CFR 820 \\n \" f \"APPLICABLE: no \\n \" f \"JUSTIFICATION: Not relevant for device type \\n\\n \" f \"STANDARD: None \\n \" f \"APPLICABLE: no \\n \" f \"JUSTIFICATION: Outside regulatory scope \\n\\n \" f \"Respond ONLY in the required format above.\" ) response = await self . _llm_call ( prompt , temperature = temperature ) # Parse the structured response standard = \"None\" applicable = False justification = \"Not specified\" logger . debug ( f \"Raw LLM response for section { title } : { response } \" ) try : lines = response . strip () . split ( \" \\n \" ) for line in lines : line = line . strip () if line . startswith ( \"STANDARD:\" ): standard = line . replace ( \"STANDARD:\" , \"\" ) . strip () if not standard : standard = \"None\" elif line . startswith ( \"APPLICABLE:\" ): applicable = \"yes\" in line . lower () elif line . startswith ( \"JUSTIFICATION:\" ): justification = line . replace ( \"JUSTIFICATION:\" , \"\" ) . strip () if not justification : justification = \"Not specified\" # Validate parsing results if standard == \"None\" and justification == \"Not specified\" and not applicable : logger . warning ( f \"LLM response parsing may have failed for section { title } . Using fallback.\" ) # Fallback parsing for unstructured response if \"iso\" in response . lower (): standard = \"ISO Standard\" elif \"fda\" in response . lower (): standard = \"FDA Regulation\" elif \"mdr\" in response . lower (): standard = \"MDR Regulation\" applicable = \"yes\" in response . lower () or \"applicable\" in response . lower () justification = \"LLM response format not structured\" except Exception as e : logger . error ( f \"Failed to parse LLM response for section { title } : { e } \" ) logger . error ( f \"Raw response was: { response } \" ) # Fallback parsing applicable = \"yes\" in response . lower () justification = \"Response parsing failed\" standard = \"Unknown\" # Ensure we have valid values if not standard or standard . strip () == \"\" : standard = \"None\" if not justification or justification . strip () == \"\" : justification = \"Not specified\" logger . info ( f \"Section { title } - Standard: { standard } , Applicable: { applicable } , Justification: { justification } \" ) result = { \"standard\" : standard , \"is_applicable\" : applicable , \"requirement_type\" : section . get ( \"requirement_type\" , \"Unknown\" ), \"requirement_justification\" : justification , \"status\" : \"success\" if applicable else \"skipped\" , } # Add result to session manager if provided try : from regulatory.app.core.state import get_session_manager session_mgr = get_session_manager () if session_mgr and session_id : # Create section result payload section_result = { \"section_id\" : section . get ( \"id\" , f \"section_ { title . replace ( ' ' , '_' ) } \" ), \"section_title\" : title , \"group_name\" : group_name , \"component_name\" : component_name , \"result\" : result , \"timestamp\" : time . time (), } # Use proper nested dictionary structure (not dot notation) update_payload = { \"gspr_section_results\" : { section_result [ \"section_id\" ]: section_result }} success = session_mgr . update_nested ( session_id , update_payload ) if success : logger . debug ( f \"\u2705 Added GSPR result for section ' { title } ' to session { session_id } \" ) else : logger . warning ( f \"\u26a0\ufe0f Failed to add GSPR result for section ' { title } ' to session { session_id } \" ) except Exception as e : logger . warning ( f \"Failed to update session manager: { e } \" ) logger . debug ( f \"Generated reasoning for ' { title } ' \u2192 { result [ 'standard' ] } \" ) return result","title":"generate_section"},{"location":"ai_backend/chains_overview/#core.chains.gspr_chain.GSPRChain.group_sections","text":"Groups sections semantically using GPT structured output with DEEP ANALYSIS. Performs comprehensive regulatory analysis by: - Analyzing both titles AND full descriptions - Using higher temperature for thoughtful reasoning - Smaller batch sizes for focused analysis - Single best-fit group assignment per section - Detailed timing and assignment statistics Returns: [{\"group\": str, \"sections\": [...] }] with single assignment per section Source code in core/chains/gspr_chain.py 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 async def group_sections ( self , sections : list [ dict [ str , Any ]], context : dict [ str , Any ], * , component_name : str | None = None , temperature : Optional [ float ] = 0.6 , # Higher temperature for more thoughtful analysis batch_size : int = 25 , # Smaller batches for deeper focus max_concurrency : int = 3 , # Reduced concurrency for more careful processing ) -> list [ dict [ str , Any ]]: \"\"\" Groups sections semantically using GPT structured output with DEEP ANALYSIS. Performs comprehensive regulatory analysis by: - Analyzing both titles AND full descriptions - Using higher temperature for thoughtful reasoning - Smaller batch sizes for focused analysis - Single best-fit group assignment per section - Detailed timing and assignment statistics Returns: [{\"group\": str, \"sections\": [...] }] with single assignment per section \"\"\" # ------------------------------------------------------------ # Split sections into manageable batches # ------------------------------------------------------------ logger . info ( \">>>>>>>>>>>>>>>>>\" ) total_sections = len ( sections ) batches = [ sections [ i : i + batch_size ] for i in range ( 0 , total_sections , batch_size )] logger . info ( f \"Processing { total_sections } sections in { len ( batches ) } batches (batch size= { batch_size } , max_concurrency= { max_concurrency } ).\" ) # ------------------------------------------------------------ # Prepare title index for mapping back # ------------------------------------------------------------ title_index = { s [ \"title\" ]: s for s in sections } merged_groups : dict [ str , list [ dict [ str , Any ]]] = {} semaphore = asyncio . Semaphore ( max_concurrency ) # ------------------------------------------------------------ # Helper to process a single batch # ------------------------------------------------------------ async def _process_batch ( batch : list [ dict [ str , Any ]], batch_num : int , component_name : str ) -> GroupingModel : async with semaphore : # Create detailed sections with titles AND descriptions for analysis sections_with_descriptions = [] for i , section in enumerate ( batch , 1 ): title = section . get ( \"title\" , \"Untitled Section\" ) description = section . get ( \"description\" , \"No description available\" ) # Truncate very long descriptions to avoid token limits if len ( description ) > 500 : description = description [: 497 ] + \"...\" sections_with_descriptions . append ( f \" { i } . TITLE: { title } \\n DESCRIPTION: { description } \\n \" ) sections_text = \" \\n \" . join ( sections_with_descriptions ) logger . debug ( f \"[Batch { batch_num } ] Deep analysis of { len ( batch ) } sectizons with full descriptions.\" ) prompt = get_grouping_prompt () formatted_prompt = prompt . format ( context_summary = context . get ( \"summary\" , \"N/A\" ), sections_with_descriptions = sections_text , component_name = component_name , ) # Structured JSON call per batch with timing import time start_time = time . perf_counter () response : GroupingModel = await self . _llm_call ( formatted_prompt , structured_schema = GroupingModel , temperature = temperature , ) processing_time = round ( time . perf_counter () - start_time , 2 ) # Calculate assignment statistics for this batch total_assignments = sum ( len ( group . sections ) for group in response . groups ) batch_sections = len ( batch ) logger . info ( f \"[Batch { batch_num } ] Deep analysis completed in { processing_time } s\" ) logger . info ( f \"[Batch { batch_num } ] Single assignments: { total_assignments } / { batch_sections } sections assigned\" ) return response # ------------------------------------------------------------ # 4\ufe0f\u20e3 Run all batches in parallel # ------------------------------------------------------------ tasks = [ asyncio . create_task ( _process_batch ( batch , i + 1 , component_name or \"unknown\" )) for i , batch in enumerate ( batches )] responses = await asyncio . gather ( * tasks ) logger . info ( f \"All { len ( responses ) } batches completed.\" ) # ------------------------------------------------------------ # 5\ufe0f\u20e3 Merge grouped results from all batches (SINGLE ASSIGNMENT ONLY) # ------------------------------------------------------------ for batch_idx , response in enumerate ( responses , start = 1 ): batch_mapped_count = 0 for group in response . groups : mapped_sections = [ title_index [ t ] for t in group . sections if t in title_index ] if group . name not in merged_groups : merged_groups [ group . name ] = [] merged_groups [ group . name ] . extend ( mapped_sections ) batch_mapped_count += len ( mapped_sections ) logger . info ( f \"[Batch { batch_idx } ] Added { len ( response . groups ) } groups with { batch_mapped_count } sections.\" ) # ------------------------------------------------------------ # 6\ufe0f\u20e3 Handle any missing titles (fallback for single assignments) # ------------------------------------------------------------ all_mapped_titles = { s [ \"title\" ] for g in merged_groups . values () for s in g } missing_sections = [ s for s in sections if s [ \"title\" ] not in all_mapped_titles ] if missing_sections : logger . warning ( f \" { len ( missing_sections ) } sections were unassigned \u2014 adding to 'Miscellaneous'.\" ) merged_groups . setdefault ( \"Miscellaneous\" , []) . extend ( missing_sections ) # ------------------------------------------------------------ # 7\ufe0f\u20e3 Final structured result (single assignment per section) # ------------------------------------------------------------ grouped_sections = [{ \"group\" : name , \"sections\" : secs } for name , secs in merged_groups . items ()] # Calculate statistics for single assignments total_assigned = sum ( len ( secs ) for secs in merged_groups . values ()) total_sections = len ( sections ) logger . info ( f \"\u2705 Grouped { total_sections } sections into { len ( grouped_sections ) } groups.\" ) logger . info ( f \"\ud83d\udcca Assignment: { total_assigned } / { total_sections } sections assigned (single assignment per section).\" ) return grouped_sections","title":"group_sections"},{"location":"ai_backend/chains_overview/#gspr-generator-chain-build-gspr-documentation","text":"Automatically generates structured GSPR compliance documentation , mapping requirements to device characteristics. Ensures consistency, traceability, and audit-ready formatting. This module builds and initializes the GSPR (General Safety and Performance Requirements) generator chain. It prepares the PromptTemplate, loads the LLM backend, and wraps it with a structured output model to generate high-quality, schema-validated GSPR entries.","title":"\ud83c\udfd7\ufe0f GSPR Generator Chain \u2014 Build GSPR Documentation"},{"location":"ai_backend/chains_overview/#core.chains.gspr_generator_chain--workflow","text":"Create a PromptTemplate based on the GSPR generator prompt string. Load the configured vLLM model using the internal LLM provider. Wrap the model with structured output using GSPRGeneratorModel . Construct a runnable chain: prompt \u2192 LLM \u2192 structured output. This chain is used by the system to produce consistent, validated, and regulatory-aligned GSPR entries for varied medical devices.","title":"Workflow:"},{"location":"ai_backend/chains_overview/#core.chains.gspr_generator_chain.prompt","text":"PromptTemplate Defines the template used by the GSPR generator. It inserts dynamic fields such as the medical device type, intended purpose, component details, and specific GSPR requirements. This template ensures all contextual inputs are passed into the LLM in a structured format.","title":"prompt"},{"location":"ai_backend/chains_overview/#core.chains.gspr_generator_chain.get_gspr_generator_chain","text":"Get GSPR generator chain with current model selection. Source code in core/chains/gspr_generator_chain.py 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 def get_gspr_generator_chain (): \"\"\"Get GSPR generator chain with current model selection.\"\"\" logger . info ( \"Creating GSPR generator chain with current model...\" ) gspr_generator_llm = get_gspr_generator_llm () chain = prompt | gspr_generator_llm \"\"\" GSPR Generator Chain: Creates the final chain by piping: PromptTemplate \u2192 LLM \u2192 Structured Output. This runnable chain is used throughout the application to generate GSPR-compliant entries with deterministic structure and high-quality regulatory reasoning. \"\"\" logger . info ( \"GSPR generator chain initialized.\" ) return chain","title":"get_gspr_generator_chain"},{"location":"ai_backend/chains_overview/#core.chains.gspr_generator_chain.get_gspr_generator_llm","text":"Get LLM instance with current model selection for runtime switching. Source code in core/chains/gspr_generator_chain.py 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 def get_gspr_generator_llm (): \"\"\"Get LLM instance with current model selection for runtime switching.\"\"\" logger . info ( \"Creating GSPR generator LLM instance with current model selection...\" ) try : llm = get_vllm_llm () \"\"\" LLM Loader: Loads the vLLM backend configured for regulatory text generation. The model is optimized for structured compliance reasoning and supports high-volume inference. \"\"\" logger . info ( \"LLM initialized successfully.\" ) return llm . with_structured_output ( GSPRGeneratorModel ) except Exception as e : logger . exception ( f \"Failed to initialize LLM - { str ( e ) } \" ) raise","title":"get_gspr_generator_llm"},{"location":"ai_backend/chains_overview/#guard-chain-apply-rule-based-validations","text":"Implements safety, logic, and regulatory guards on user inputs and generated outputs. Prevents invalid data, enforces constraints, and ensures workflow integrity.","title":"\ud83d\udea8 Guard Chain \u2014 Apply Rule-Based Validations"},{"location":"ai_backend/chains_overview/#core.chains.guard_chain.get_guard_chain","text":"Get guard chain with current model selection. Source code in core/chains/guard_chain.py 62 63 64 65 66 67 68 def get_guard_chain (): \"\"\"Get guard chain with current model selection.\"\"\" logger . info ( \"Creating guard chain with current model...\" ) llm = get_guard_llm () chain = prompt | llm logger . info ( \"Guard chain initialized successfully.\" ) return chain","title":"get_guard_chain"},{"location":"ai_backend/chains_overview/#core.chains.guard_chain.get_guard_llm","text":"Get LLM instance with current model selection for runtime switching. Source code in core/chains/guard_chain.py 37 38 39 40 41 42 43 44 45 46 def get_guard_llm (): \"\"\"Get LLM instance with current model selection for runtime switching.\"\"\" logger . info ( \"Creating guard LLM instance with current model selection...\" ) try : llm = get_vllm_llm () logger . info ( \"LLM initialized successfully.\" ) return llm except Exception as e : logger . exception ( f \"Failed to initialize LLM - { str ( e ) } \" ) raise","title":"get_guard_llm"},{"location":"ai_backend/chains_overview/#intended-user-chain-identify-expected-user-profiles","text":"Analyzes device context to determine intended users , such as clinicians, technicians, or patients. Ensures user-centric design alignment with regulatory assessment standards .","title":"\ud83d\udc65 Intended User Chain \u2014 Identify Expected User Profiles"},{"location":"ai_backend/chains_overview/#core.chains.intended_user_chain.prompt","text":"Retrieve the intended user LLM instance. This function initializes and returns a language model (LLM) instance configured for the intended user chain. The LLM is structured to generate outputs based on device type, intended purpose, and other inputs. Returns: Name Type Description LLM A language model instance configured with the IntendedUserModel. Raises: Type Description Exception If the LLM initialization fails. Example llm = get_intended_user_llm() response = llm.invoke({\"device_type\": \"Sensor\", \"intended_purpose\": \"Monitoring\"})","title":"prompt"},{"location":"ai_backend/chains_overview/#core.chains.intended_user_chain.get_intended_user_chain","text":"Get intended user chain with current model selection. Source code in core/chains/intended_user_chain.py 71 72 73 74 75 76 77 def get_intended_user_chain (): \"\"\"Get intended user chain with current model selection.\"\"\" logger . info ( \"Creating intended user chain with current model...\" ) intended_user_llm = get_intended_user_llm () chain = prompt | intended_user_llm logger . info ( \"Intended user chain created successfully.\" ) return chain","title":"get_intended_user_chain"},{"location":"ai_backend/chains_overview/#core.chains.intended_user_chain.get_intended_user_llm","text":"Get LLM instance with current model selection for runtime switching. Source code in core/chains/intended_user_chain.py 45 46 47 48 49 50 51 52 53 54 55 def get_intended_user_llm (): \"\"\"Get LLM instance with current model selection for runtime switching.\"\"\" logger . info ( \"Creating intended user LLM instance with current model selection...\" ) try : llm = get_vllm_llm () logger . info ( \"LLM initialized successfully.\" ) return llm . with_structured_output ( IntendedUserModel ) except Exception as e : logger . exception ( \"Failed to initialize LLM: %s \" , e ) logger . info ( f \"LLM initialization exception message: { e } \" ) raise","title":"get_intended_user_llm"},{"location":"ai_backend/chains_overview/#risk-classification-chain-determine-device-risk-class","text":"Evaluates device properties to assign the correct risk class under GSPR frameworks. Supports consistent classification logic required for regulatory pathways.","title":"\ud83e\uddea Risk Classification Chain \u2014 Determine Device Risk Class"},{"location":"ai_backend/chains_overview/#core.chains.risk_classification_chain.get_llm_for_region","text":"Return appropriate LLM based on region. Source code in core/chains/risk_classification_chain.py 33 34 35 36 37 38 39 40 def get_llm_for_region ( region : str ): \"\"\"Return appropriate LLM based on region.\"\"\" if region . lower () in [ \"eu\" , \"india\" ]: return get_chatmdr_llm () elif region . lower () == \"us\" : return get_chatfda_llm () else : return get_vllm_llm ()","title":"get_llm_for_region"},{"location":"ai_backend/chains_overview/#core.chains.risk_classification_chain.get_risk_classification_chain","text":"Get risk classification chain with current model selection. Source code in core/chains/risk_classification_chain.py 93 94 95 96 97 98 99 def get_risk_classification_chain ( region : str = \"usa\" ): \"\"\"Get risk classification chain with current model selection.\"\"\" logger . info ( \"Creating risk classification chain with current model...\" ) risk_classification_llm = get_risk_classification_llm ( region ) chain = prompt | risk_classification_llm logger . info ( \"Risk classification chain created successfully.\" ) return chain","title":"get_risk_classification_chain"},{"location":"ai_backend/chains_overview/#core.chains.risk_classification_chain.get_risk_classification_llm","text":"Get LLM instance with current model selection for runtime switching. Source code in core/chains/risk_classification_chain.py 64 65 66 67 68 69 70 71 72 73 def get_risk_classification_llm ( region : str = \"usa\" ): \"\"\"Get LLM instance with current model selection for runtime switching.\"\"\" logger . info ( f \"Creating risk classification LLM instance with current model selection for region ' { region } '...\" ) try : llm = get_llm_for_region ( region ) logger . info ( f \"LLM for region ' { region } ' initialized successfully.\" ) return llm . with_structured_output ( RiskClassificationModel , method = \"json_mode\" ) except Exception : logger . exception ( \"Failed to initialize LLM\" ) raise","title":"get_risk_classification_llm"},{"location":"ai_backend/graphs/","text":"\ud83d\udda5\ufe0f Intelligent Regulatory Automation Nodes \u2014 Core System Modules \ud83c\udfd7\ufe0f Component Recommender Node \u2014 Suggest Device Subsystems Recommends appropriate components and subsystems for the device based on intended function and materials. Optimizes design completeness and modular traceability. component_recommender_node ( state ) Executes the component recommender chain, updates the state with system-generated component suggestions under design_data.system_generated. Parameters: Name Type Description Default state dict The current state of the system, containing device input and design data. required Returns: Name Type Description dict dict The updated state with recommended components added to system-generated design data. Source code in core/graph/nodes/component_recommender_node.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 def component_recommender_node ( state : dict ) -> dict : \"\"\" Executes the component recommender chain, updates the state with system-generated component suggestions under design_data.system_generated. Args: state (dict): The current state of the system, containing device input and design data. Returns: dict: The updated state with recommended components added to system-generated design data. \"\"\" device_input = state [ \"device_input\" ] chain_input = { \"medical_device\" : device_input [ \"medical_device\" ], \"intended_purpose\" : device_input [ \"intended_purpose\" ], \"device_type\" : device_input [ \"device_type\" ], \"material_type\" : device_input [ \"material_type\" ], } logger . info ( \"Input to component recommender chain: \\n %s \" , json . dumps ( chain_input , indent = 2 )) config : RunnableConfig = { \"run_name\" : \"ComponentRecommender\" , \"tags\" : [ \"LLM_APP\" , \"Component_Recommender\" , \"v1.0\" ], \"metadata\" : { \"model\" : \"gpt-4o\" , # or whichever LLM you\u2019re using \"parser\" : \"PydanticOutputParser\" , \"temperature\" : 0.3 , \"max_tokens\" : 1500 , }, } # Get fresh chain instance with current model selection component_recommender_chain = get_component_recommender_chain () response = component_recommender_chain . invoke ( chain_input , config = config ) logger . debug ( \"Raw LLM response: %s \" , response ) if isinstance ( response , BaseModel ): response = response . model_dump () else : raise TypeError ( \"Response must be a dict or Pydantic object with .dict() method.\" ) model = ComponentRecommenderModel ( ** response ) logger . info ( \"Recommended Components: %s \" , model . components_list ) # Update state with recommended components (ensuring uniqueness) current_components = state [ \"design_data\" ][ \"system_generated\" ][ \"components\" ] updated_components = list ( set ( current_components + model . components_list )) state [ \"design_data\" ][ \"system_generated\" ][ \"components\" ] = updated_components logger . info ( \"Updated system_generated components: %s \" , updated_components ) return state \ud83d\udcdd Design Input Node \u2014 Generate Detailed Design Requirements Translates high-level specifications into detailed, regulatory-aligned design inputs for all subsystems. Supports parallel processing for material, performance, and human factor requirements. design_input_node ( state , component_name , gspr_no ) Generates and updates the design input for a specific component and GSPR (General Safety and Performance Requirements). Parameters: Name Type Description Default state dict The current state of the system, containing user input and design data. required component_name str The name of the component for which design input is generated. required gspr_no str The GSPR number associated with the design input. required Returns: Name Type Description dict dict The updated state with the generated design input added under the specified component and GSPR. Source code in core/graph/nodes/design_input_node.py 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 def design_input_node ( state : dict , component_name : str , gspr_no : str ) -> dict : \"\"\" Generates and updates the design input for a specific component and GSPR (General Safety and Performance Requirements). Args: state (dict): The current state of the system, containing user input and design data. component_name (str): The name of the component for which design input is generated. gspr_no (str): The GSPR number associated with the design input. Returns: dict: The updated state with the generated design input added under the specified component and GSPR. \"\"\" user_input = state . get ( \"user_input\" , {}) device_meta = { \"device_type\" : user_input . get ( \"device_type\" , \"\" ), \"intended_purpose\" : user_input . get ( \"intended_purpose\" , \"\" ), \"intended_users\" : user_input . get ( \"intended_users\" , []), \"risk_classification\" : user_input . get ( \"risk_classification\" , \"\" ), } logger . info ( f \"Generating design input for component ' { component_name } ' and GSPR ' { gspr_no } '\" ) item : DesignInputModel = fetch_design_input ( device_meta , component_name , gspr_no ) # Ensure top-level design_input exists if \"design_input\" not in state : state [ \"design_input\" ] = {} # Ensure component dict exists if component_name not in state [ \"design_input\" ]: state [ \"design_input\" ][ component_name ] = {} # Save GSPR entry under component state [ \"design_input\" ][ component_name ][ gspr_no ] = { \"component\" : item . component , \"requirement\" : item . requirement , \"gspr_text\" : item . gspr_text , \"standards\" : [ std . model_dump () if hasattr ( std , \"model_dump\" ) else std for std in item . standards ], } return state \ud83d\udcd0 Design Output Node \u2014 Compile Technical Specifications Aggregates all design outputs including schematics, technical specifications, and implementation instructions. Ensures each output maps back to input requirements for traceability. design_output_node ( state ) async Generate structured Design Output Reports for all components in the design_input section of the state. This node automatically processes each component's design input using the design output generation chain, which aligns with ISO/IEC standards and GSPR requirements. No user input or PDF references are required \u2014 all context is derived from the internal design input data. Parameters: Name Type Description Default state Dict [ str , Any ] State dictionary containing design input data. Expected structure: { \"design_input\": { \"ComponentName\": { \"device_type\": \"...\", \"component\": \"...\", \"requirement\": \"...\", \"gspr_text\": \"...\", \"standards\": [ ... ] }, ... } } required Returns: Type Description Dict [ str , Any ] Dict[str, Any]: Updated state dictionary including generated design outputs. Example: { \"design_output\": { \"ComponentName\": \" \" } } Source code in core/graph/nodes/design_output_node.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 async def design_output_node ( state : Dict [ str , Any ]) -> Dict [ str , Any ]: \"\"\" Generate structured Design Output Reports for all components in the design_input section of the state. This node automatically processes each component's design input using the design output generation chain, which aligns with ISO/IEC standards and GSPR requirements. No user input or PDF references are required \u2014 all context is derived from the internal design input data. Args: state (Dict[str, Any]): State dictionary containing design input data. Expected structure: { \"design_input\": { \"ComponentName\": { \"device_type\": \"...\", \"component\": \"...\", \"requirement\": \"...\", \"gspr_text\": \"...\", \"standards\": [ ... ] }, ... } } Returns: Dict[str, Any]: Updated state dictionary including generated design outputs. Example: { \"design_output\": { \"ComponentName\": \"<Generated Report Text>\" } } \"\"\" design_inputs = state . get ( \"design_input\" , {}) if not design_inputs : logger . error ( \"No design input found in state.\" ) return state # Initialize design_output container state . setdefault ( \"design_output\" , {}) for component , component_input in design_inputs . items (): logger . info ( f \"Generating Design Output Report for component ' { component } '\" ) try : # Generate design output (auto ISO reference) output_data = await run_design_output_chain ( design_input = component_input , component = component , ) # Store in state state [ \"design_output\" ][ component ] = output_data logger . info ( f \"Design Output successfully generated for ' { component } '\" ) except Exception as e : logger . error ( f \"Error generating Design Output for ' { component } ': { e } \" ) return state \ud83d\udd04 GSPR Filter Node \u2014 Refine Safety & Performance Requirements Filters and prioritizes GSPR clauses relevant to the device type, materials, and user environment. Improves efficiency and reduces regulatory noise. gspr_filter_node ( state , component_name , gspr_number ) Runs the GSPR filter chain for a specific component and GSPR number, and updates the session state with the applicability and justification results. Parameters: Name Type Description Default state dict The current session state containing user input and generated data. required component_name str The name of the component being evaluated. required gspr_number str The GSPR number to filter and evaluate. required Returns: Name Type Description dict dict The updated session state with the GSPR filter results stored under state['gspr_generated'] . Source code in core/graph/nodes/gspr_filter_node.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 def gspr_filter_node ( state : dict , component_name : str , gspr_number : str ) -> dict : \"\"\" Runs the GSPR filter chain for a specific component and GSPR number, and updates the session state with the applicability and justification results. Args: state (dict): The current session state containing user input and generated data. component_name (str): The name of the component being evaluated. gspr_number (str): The GSPR number to filter and evaluate. Returns: dict: The updated session state with the GSPR filter results stored under `state['gspr_generated']`. \"\"\" user_input = state . get ( \"user_input\" ) if not user_input : raise ValueError ( \"Missing 'user_input' in state\" ) gspr_map = build_gspr_map () # Prepare input for the LLM chain chain_input = { \"medical_device\" : user_input . get ( \"medical_device\" ), \"material_type\" : user_input . get ( \"material_type\" ), \"device_type\" : user_input . get ( \"device_type\" ), \"component_name\" : component_name , \"intended_purpose\" : user_input . get ( \"intended_purpose\" ), \"intended_users\" : \", \" . join ( user_input . get ( \"intended_users\" ) or []), \"risk_classification\" : user_input . get ( \"risk_classification\" ), \"gspr_number\" : gspr_number , \"gspr_context\" : gspr_map . get ( gspr_number ) or \"<No GSPR found>\" , } logger . info ( f \"Running GSPR filter for component: { component_name } , GSPR { gspr_number } \" ) logger . debug ( \"Input to GSPR filter chain: \\n %s \" , json . dumps ( chain_input , indent = 2 )) config : RunnableConfig = { \"run_name\" : \"GSPR_Filter\" , \"tags\" : [ \"LLM_APP\" , \"GSPR_Filter\" , \"v1.0\" ], \"metadata\" : { \"model\" : \"gpt-4o\" , # replace with actual model \"parser\" : \"PydanticOutputParser\" , \"temperature\" : 0.2 , # keep low for deterministic applicability \"max_tokens\" : 1200 , }, } # ---------------- Run chain ---------------- response : GSPRFilterResponse = gspr_filter_chain . invoke ( chain_input , config = config ) logger . debug ( \"LLM structured response: %s \" , getattr ( response , \"json\" , lambda : str ( response ))()) # ---------------- Update state ---------------- gspr_generated = state . setdefault ( \"gspr_generated\" , {}) gspr_generated . setdefault ( component_name , {}) gspr_generated [ component_name ] . setdefault ( gspr_number , {}) # Only update the relevant fields under the nested structure. # Do not create separate top-level dicts. gspr_generated [ component_name ][ gspr_number ] . update ( { \"is_applicable\" : bool ( response . is_applicable ), \"justification\" : response . justification or \"\" , } ) logger . info ( f \"\u2705 Updated GSPR state for ' { component_name } ': { gspr_number } -> { response . is_applicable } \" ) return state \ud83d\uddc2\ufe0f GSPR Generator Node \u2014 Create Safety & Performance Tables Generates the initial GSPR table linking device features to regulatory clauses and compliance justifications. Supports both FDA and MDR alignment. gspr_generator_node ( state , component_name , main_gspr_number ) Runs the GSPR generator chain for a specific component and GSPR number, and updates the session state with the generated requirements and standards. Parameters: Name Type Description Default state dict The current session state containing user input and generated data. required component_name str The name of the component for which the GSPR is being generated. required main_gspr_number str The main GSPR number associated with the generation process. required Returns: Name Type Description dict dict The updated session state with the GSPR generator results merged under state['gspr_generated'] . Source code in core/graph/nodes/gspr_generator_node.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 def gspr_generator_node ( state : dict , component_name : str , main_gspr_number : str ) -> dict : \"\"\" Runs the GSPR generator chain for a specific component and GSPR number, and updates the session state with the generated requirements and standards. Args: state (dict): The current session state containing user input and generated data. component_name (str): The name of the component for which the GSPR is being generated. main_gspr_number (str): The main GSPR number associated with the generation process. Returns: dict: The updated session state with the GSPR generator results merged under `state['gspr_generated']`. \"\"\" user_input : dict = state . get ( \"user_input\" ) or {} chain_input : dict = { \"medical_device\" : user_input . get ( \"medical_device\" ), \"material_type\" : user_input . get ( \"material_type\" ), \"device_type\" : user_input . get ( \"device_type\" ), \"intended_purpose\" : user_input . get ( \"intended_purpose\" ), \"intended_users\" : \", \" . join ( user_input . get ( \"intended_users\" ) or []), \"risk_classifications\" : user_input . get ( \"risk_classification\" ), \"component\" : component_name , \"gspr\" : main_gspr_number , } logger . info ( f \"Generating GSPR for component: { component_name } , GSPR: { main_gspr_number } \" ) logger . debug ( \"Input to GSPR Generator Chain: %s \" , chain_input ) config : RunnableConfig = { \"run_name\" : \"GSPR_Generator\" , \"tags\" : [ \"LLM_APP\" , \"GSPR_Generator\" , \"v1.0\" ], \"metadata\" : { \"model\" : \"gpt-4o\" , # replace with actual model in use \"parser\" : \"PydanticOutputParser\" , \"temperature\" : 0.3 , # slightly higher than filter to allow some flexibility \"max_tokens\" : 1500 , }, } # Get fresh chain instance with current model selection gspr_generator_chain = get_gspr_generator_chain () response = gspr_generator_chain . invoke ( chain_input , config = config ) logger . debug ( \"\ud83d\udcdd Raw LLM response: %s \" , response ) # Normalize response if isinstance ( response , dict ): item = GSPRGeneratorModel ( ** response ) elif isinstance ( response , GSPRGeneratorModel ): item = response elif isinstance ( response , BaseModel ): item = GSPRGeneratorModel ( ** response . dict ()) else : raise TypeError ( f \"Expected dict or GSPRGeneratorModel, got { type ( response ) } \" ) requirements = item . requirement or \"\" standards = item . standard if isinstance ( item . standard , list ) else ([ item . standard ] if item . standard else []) logger . info ( f \"\u2705 GSPR generated for ' { component_name } ', GSPR { main_gspr_number } \" ) logger . debug ( \"Requirements: %s | Standards: %s \" , requirements , standards ) # ---------------- Update state ---------------- gspr_generated = state . setdefault ( \"gspr_generated\" , {}) gspr_generated . setdefault ( component_name , {}) gspr_generated [ component_name ] . setdefault ( main_gspr_number , {}) # Merge generator fields with whatever filter already stored. gspr_generated [ component_name ][ main_gspr_number ] . update ( { \"requirements\" : requirements , \"standards\" : standards , } ) return state \ud83d\udcca GSPR Table Generator Node \u2014 Structure Compliance Evidence Builds structured, audit-ready GSPR tables integrating standards, test evidence, and applicability notes. gspr_filter_node ( state , component_name , gspr_number ) Run the GSPR filter chain for a given component and GSPR number, then update the session state with applicability and justification. All results are stored exclusively under state['gspr_generated'] . Source code in core/graph/nodes/gspr_table_generator_node.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 def gspr_filter_node ( state : dict , component_name : str , gspr_number : str ) -> dict : \"\"\" Run the GSPR filter chain for a given component and GSPR number, then update the session state with applicability and justification. All results are stored exclusively under `state['gspr_generated']`. \"\"\" user_input = state . get ( \"user_input\" ) if not user_input : raise ValueError ( \"Missing 'user_input' in state\" ) gspr_map = build_gspr_map () # Prepare input for the LLM chain chain_input = { \"medical_device\" : user_input . get ( \"medical_device\" ), \"material_type\" : user_input . get ( \"material_type\" ), \"device_type\" : user_input . get ( \"device_type\" ), \"component_name\" : component_name , \"intended_purpose\" : user_input . get ( \"intended_purpose\" ), \"intended_users\" : \", \" . join ( user_input . get ( \"intended_users\" ) or []), \"risk_classification\" : user_input . get ( \"risk_classification\" ), \"gspr_number\" : gspr_number , \"gspr_context\" : gspr_map . get ( gspr_number ) or \"<No GSPR found>\" , } logger . info ( f \"Running GSPR filter for component: { component_name } , GSPR { gspr_number } \" ) logger . debug ( \"Input to GSPR filter chain: \\n %s \" , json . dumps ( chain_input , indent = 2 )) config : RunnableConfig = { \"run_name\" : \"GSPR_Filter\" , \"tags\" : [ \"LLM_APP\" , \"GSPR_Filter\" , \"v1.0\" ], \"metadata\" : { \"model\" : \"gpt-4o\" , # replace with actual model \"parser\" : \"PydanticOutputParser\" , \"temperature\" : 0.2 , # keep low for deterministic applicability \"max_tokens\" : 1200 , }, } # ---------------- Run chain ---------------- response : GSPRFilterResponse = gspr_filter_chain . invoke ( chain_input , config = config ) logger . debug ( \"LLM structured response: %s \" , getattr ( response , \"json\" , lambda : str ( response ))()) # ---------------- Update state ---------------- gspr_generated = state . setdefault ( \"gspr_generated\" , {}) gspr_generated . setdefault ( component_name , {}) gspr_generated [ component_name ] . setdefault ( gspr_number , {}) # Only update the relevant fields under the nested structure. # Do not create separate top-level dicts. gspr_generated [ component_name ][ gspr_number ] . update ( { \"is_applicable\" : bool ( response . is_applicable ), \"justification\" : response . justification or \"\" , } ) logger . info ( f \"\u2705 Updated GSPR state for ' { component_name } ': { gspr_number } -> { response . is_applicable } \" ) return state gspr_table_generator_node ( state , component_name ) Generates applicability and justifications for all 181 GSPR sections for a given component. Updates the session state with the results and returns a summarized table list. Parameters: Name Type Description Default state dict The current session state containing user input and generated data. required component_name str The name of the component for which the GSPR table is generated. required Returns: Type Description dict tuple[dict, list[dict]]: A tuple containing the updated session state and a list of dictionaries list [ dict ] summarizing the GSPR table data. Source code in core/graph/nodes/gspr_table_generator_node.py 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 def gspr_table_generator_node ( state : dict , component_name : str ) -> tuple [ dict , list [ dict ]]: \"\"\" Generates applicability and justifications for all 181 GSPR sections for a given component. Updates the session state with the results and returns a summarized table list. Args: state (dict): The current session state containing user input and generated data. component_name (str): The name of the component for which the GSPR table is generated. Returns: tuple[dict, list[dict]]: A tuple containing the updated session state and a list of dictionaries summarizing the GSPR table data. \"\"\" user_input = state . get ( \"user_input\" ) if not user_input : raise ValueError ( \"Missing 'user_input' in state\" ) gspr_map = build_gspr_map () gspr_generated = state . setdefault ( \"gspr_generated\" , {}) gspr_generated . setdefault ( component_name , {}) table_data = [] config : RunnableConfig = { \"run_name\" : \"GSPR_Table_Generation\" , \"tags\" : [ \"LLM_APP\" , \"GSPR_Table\" , \"v1.0\" ], \"metadata\" : { \"model\" : \"gpt-4o\" , # replace if needed \"parser\" : \"PydanticOutputParser\" , \"temperature\" : 0.2 , \"max_tokens\" : 1200 , }, } logger . info ( f \"\ud83d\udd04 Starting GSPR Table Generation for component: { component_name } \" ) # Iterate through all 181 GSPRs for gspr_no , gspr_context in gspr_map . items (): chain_input = { \"medical_device\" : user_input . get ( \"medical_device\" ), \"material_type\" : user_input . get ( \"material_type\" ), \"device_type\" : user_input . get ( \"device_type\" ), \"component_name\" : component_name , \"intended_purpose\" : user_input . get ( \"intended_purpose\" ), \"intended_users\" : \", \" . join ( user_input . get ( \"intended_users\" ) or []), \"risk_classification\" : user_input . get ( \"risk_classification\" ), \"gspr_number\" : gspr_no , \"gspr_context\" : gspr_context or \"<No GSPR found>\" , } logger . debug ( f \"Running GSPR { gspr_no } for component { component_name } \" ) response : GSPRFilterResponse = gspr_filter_chain . invoke ( chain_input , config = config ) # Save result in session state gspr_generated [ component_name ][ gspr_no ] = { \"is_applicable\" : bool ( response . is_applicable ), \"justification\" : response . justification or \"\" , } # Build response table entry table_data . append ( { \"section_number\" : gspr_no , \"section_name\" : gspr_context . get ( \"title\" ) if isinstance ( gspr_context , dict ) else \"<No title>\" , \"applicable\" : \"Y\" if response . is_applicable else \"N\" , \"justification\" : response . justification or \"No justification provided\" , } ) logger . info ( f \"\u2705 Completed GSPR table generation for { component_name } \" ) return state , table_data \ud83d\udee1\ufe0f Guard Node \u2014 Validate Compliance Logic Enforces regulatory rules across the workflow. Prevents unsafe or inconsistent data propagation and validates each node's output. guard_node ( text , cat ) Executes the regulatory guard agent to process the given text and category, returning the AI-generated response. Parameters: Name Type Description Default text str The input text to be processed by the regulatory guard agent. required cat str The category associated with the input text. required Returns: Name Type Description str str The content of the AI-generated response. Source code in core/graph/nodes/guard_node.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 def guard_node ( text : str , cat : str ) -> str : \"\"\" Executes the regulatory guard agent to process the given text and category, returning the AI-generated response. Args: text (str): The input text to be processed by the regulatory guard agent. cat (str): The category associated with the input text. Returns: str: The content of the AI-generated response. \"\"\" # Prepare messages in LangChain-native format messages = [ SystemMessage ( content = system_instructions ), HumanMessage ( content = f \"Category: { cat } \\n\\n { text } \" ) ] chain_input = { \"messages\" : messages } logger . info ( \"Input to regulatory_guard_agent_node:\" ) logger . debug ( chain_input ) config = { \"run_name\" : \"Regulatory_Guard_Agent_Node\" , \"tags\" : [ \"LLM_APP\" , \"Regulatory_Agent\" , \"v1.0\" ], \"metadata\" : { \"model\" : \"gpt-4o\" , \"purpose\" : \"regulatory_guard\" , \"temperature\" : 0.2 , \"max_tokens\" : 800 , \"category\" : cat }, } # Get fresh agent instance with current model selection regulatory_guard_agent = get_regulatory_guard_agent () # Execute agent result = regulatory_guard_agent . invoke ( chain_input , config = config ) logger . info ( \"Guard Node Result (raw):\" ) logger . debug ( result ) # --------------------------------------------- # Extract ONLY the AIMessage content # --------------------------------------------- if isinstance ( result , dict ) and \"messages\" in result : for msg in result [ \"messages\" ]: if isinstance ( msg , AIMessage ): print ( \"AIMessage content:\" , msg . content ) return msg . content # <-- return ONLY model output # Fallbacks if agent returns simpler structures if isinstance ( result , AIMessage ): return result . content if isinstance ( result , dict ) and \"content\" in result : return result [ \"content\" ] return str ( result ) \ud83d\udc64 Intended User Node \u2014 Contextual Requirement Mapping Incorporates user environment and use-case context into design inputs and risk analysis. intended_user_node ( state ) Executes the LLM-driven intended user identification chain and updates the state with the identified intended users under design_data.system_generated.intended_users . Parameters: Name Type Description Default state dict The current state of the system, containing device input and design data. required Returns: Name Type Description dict dict The updated state with the identified intended users added to the system-generated design data. Source code in core/graph/nodes/intended_user_node.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 def intended_user_node ( state : dict ) -> dict : \"\"\" Executes the LLM-driven intended user identification chain and updates the state with the identified intended users under `design_data.system_generated.intended_users`. Args: state (dict): The current state of the system, containing device input and design data. Returns: dict: The updated state with the identified intended users added to the system-generated design data. \"\"\" # -------------------------------- # Prepare input for the LLM chain # -------------------------------- device_input = state . get ( \"device_input\" , {}) design_data = state . get ( \"design_data\" , {}) system_generated = design_data . get ( \"system_generated\" , {}) chain_input = { \"medical_device\" : device_input . get ( \"medical_device\" , \"\" ), \"material_type\" : device_input . get ( \"material_type\" , []), \"device_type\" : device_input . get ( \"device_type\" , []), \"intended_purpose\" : device_input . get ( \"intended_purpose\" , \"\" ), \"components\" : system_generated . get ( \"components\" , []), \"risk_classification\" : system_generated . get ( \"risk_classification\" , {}), } logger . info ( \"Input to intended user chain:\" ) logger . debug ( json . dumps ( chain_input , indent = 2 )) # -------------------------------- # Configure and invoke the chain # -------------------------------- config : RunnableConfig = { \"run_name\" : \"IntendedUser\" , \"tags\" : [ \"LLM_APP\" , \"Intended_User\" , \"v1.0\" ], \"metadata\" : { \"model\" : \"gpt-4o\" , \"parser\" : \"PydanticOutputParser\" , \"temperature\" : 0.2 , \"max_tokens\" : 800 , }, } # Get fresh chain instance with current model selection intended_user_chain = get_intended_user_chain () response = intended_user_chain . invoke ( chain_input , config = config ) logger . debug ( \"Raw LLM response: %s \" , response ) # -------------------------------- # Normalize response # -------------------------------- if isinstance ( response , BaseModel ): response = response . model_dump () elif not isinstance ( response , dict ): raise TypeError ( \"Expected response to be a dict or BaseModel.\" ) intended_users = response . get ( \"intended_users\" , []) if not isinstance ( intended_users , list ): raise ValueError ( \"'intended_users' should be a list in the response.\" ) logger . info ( \"Identified Intended Users: %s \" , intended_users ) # -------------------------------- # Update system_generated intended users # -------------------------------- state [ \"design_data\" ][ \"system_generated\" ][ \"intended_users\" ] = list ( set ( intended_users )) logger . info ( \"\u2705 Updated system_generated with intended users:\" ) logger . debug ( json . dumps ( state [ \"design_data\" ][ \"system_generated\" ][ \"intended_users\" ], indent = 2 )) return state \u2696\ufe0f Risk Classification Node \u2014 Determine Device Risk Class Classifies device according to FDA and MDR risk frameworks. Directly informs GSPR applicability and design control measures. risk_classify_node ( state ) Executes the LLM-driven risk classification chain and updates the state with the generated risk classification under design_data.system_generated.risk_classification . Parameters: Name Type Description Default state dict The current state of the system, containing device input and design data. required Returns: Name Type Description dict dict The updated state with the generated risk classification added to the system-generated design data. Source code in core/graph/nodes/risk_classify_node.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 def risk_classify_node ( state : dict ) -> dict : \"\"\" Executes the LLM-driven risk classification chain and updates the state with the generated risk classification under `design_data.system_generated.risk_classification`. Args: state (dict): The current state of the system, containing device input and design data. Returns: dict: The updated state with the generated risk classification added to the system-generated design data. \"\"\" # -------------------------------- # Prepare chain input # -------------------------------- device_input = state . get ( \"device_input\" , {}) design_data = state . get ( \"design_data\" , {}) chain_input = { \"medical_device\" : device_input . get ( \"medical_device\" , \"\" ), \"material_type\" : device_input . get ( \"material_type\" , []), \"device_type\" : device_input . get ( \"device_type\" , []), \"intended_purpose\" : device_input . get ( \"intended_purpose\" , \"\" ), \"components\" : design_data . get ( \"system_generated\" , {}) . get ( \"components\" , []), } logger . info ( \"Input to risk classification chain:\" ) logger . debug ( json . dumps ( chain_input , indent = 2 )) # -------------------------------- # Configure chain execution # -------------------------------- config : RunnableConfig = { \"run_name\" : \"RiskClassification\" , \"tags\" : [ \"LLM_APP\" , \"Risk_Classification\" , \"v1.0\" ], \"metadata\" : { \"model\" : \"gpt-4o\" , \"parser\" : \"PydanticOutputParser\" , \"temperature\" : 0.2 , \"max_tokens\" : 800 , }, } # -------------------------------- # Run LLM chain # -------------------------------- # Get fresh chain instance with current model selection risk_classification_chain = get_risk_classification_chain () response = risk_classification_chain . invoke ( chain_input , config = config ) logger . debug ( \"Raw LLM response: %s \" , response ) if isinstance ( response , BaseModel ): response = response . model_dump () elif not isinstance ( response , dict ): raise TypeError ( \"Response must be a dict or a Pydantic object with .model_dump().\" ) risk_classification = response . get ( \"risk_classification\" ) if not risk_classification : raise ValueError ( \"Invalid or missing 'risk_classification' in response.\" ) # -------------------------------- # Update system_generated risk classification # -------------------------------- state [ \"design_data\" ][ \"system_generated\" ][ \"risk_classification\" ] = risk_classification logger . info ( \"Updated system_generated with risk classification:\" ) logger . debug ( json . dumps ( state [ \"design_data\" ][ \"system_generated\" ][ \"risk_classification\" ], indent = 2 )) return state \ud83e\udde9 Full GSPR Orchestration Graph \u2014 End-to-End Flow Visualizes the complete multi-agent workflow , showing input processing, template generation, and compliance outputs. GSPRGraph LangGraph-based workflow for GSPR generation. This class orchestrates the GSPR generation process using LangGraph nodes. Each node determines its own adaptive LLM temperature using the GSPRChain and performs specific tasks such as context building, section grouping, and group processing. Attributes: Name Type Description chain GSPRChain The chain instance used for GSPR generation. base_context dict The base context shared across nodes. concurrency_limit int The maximum number of concurrent tasks. memory InMemorySaver The in-memory saver for graph checkpoints. graph StateGraph The compiled LangGraph instance. component_name str The name of the component being processed. session_id str The session identifier for the current run. job_id str The job identifier for tracking progress. requirement_sections dict The requirement sections to process. Source code in core/graph/gspr_graph.py 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 class GSPRGraph : \"\"\" LangGraph-based workflow for GSPR generation. This class orchestrates the GSPR generation process using LangGraph nodes. Each node determines its own adaptive LLM temperature using the GSPRChain and performs specific tasks such as context building, section grouping, and group processing. Attributes: chain (GSPRChain): The chain instance used for GSPR generation. base_context (dict): The base context shared across nodes. concurrency_limit (int): The maximum number of concurrent tasks. memory (InMemorySaver): The in-memory saver for graph checkpoints. graph (StateGraph): The compiled LangGraph instance. component_name (str): The name of the component being processed. session_id (str): The session identifier for the current run. job_id (str): The job identifier for tracking progress. requirement_sections (dict): The requirement sections to process. \"\"\" def __init__ ( self , chain : GSPRChain , context : Optional [ dict [ str , Any ]] = None , * , concurrency_limit : int = 10 , component_name : str = \" unknown\" , session_id : str = \"\" , job_id : str = \"\" , requirement_sections : dict [ str , list [ dict [ str , Any ]]], ) -> None : self . chain = chain self . base_context = context or {} self . concurrency_limit = concurrency_limit self . memory = InMemorySaver () self . graph = self . _build_graph () self . component_name = component_name self . session_id = session_id self . job_id = job_id self . requirement_sections = requirement_sections logger . info ( f \"Initialized GSPRGraph for component: { self . component_name } , job_id: { self . job_id } \" ) # --------------------------------------------------------------------- # Public API # --------------------------------------------------------------------- async def run ( self , * , sections : list [ dict [ str , Any ]], session_id : str = \"\" , ) -> dict [ str , Any ]: \"\"\" Bulk processing entrypoint for GSPR generation. Args: sections (list[dict[str, Any]]): The list of sections to process. session_id (str, optional): The session identifier for the current run. Returns: dict[str, Any]: The results of the GSPR generation, including context, grouped sections, results, and any errors encountered. \"\"\" initial : GSPRState = { \"messages\" : [], \"context\" : self . base_context , \"component_name\" : self . component_name , \"all_sections\" : sections , \"errors\" : [], } logger . info ( f \"Starting GSPRGraph run for component: { self . component_name } with { len ( sections ) } sections.\" ) # Configure checkpointer with thread_id config = RunnableConfig ( configurable = { \"thread_id\" : f \"gspr- { self . component_name } \" }) final = cast ( GSPRState , await self . graph . ainvoke ( initial , config = config )) logger . info ( f \"GSPRGraph run complete for component: { self . component_name } . Errors: { final . get ( 'errors' , []) } \" ) return { \"context\" : final . get ( \"context\" , {}), \"grouped_sections\" : final . get ( \"grouped_sections\" , []), \"results\" : final . get ( \"group_results\" , []), \"errors\" : final . get ( \"errors\" , []), } # --------------------------------------------------------------------- # LangGraph: Build graph # --------------------------------------------------------------------- def _build_graph ( self ): \"\"\" Builds the LangGraph instance for the GSPR workflow. Returns: StateGraph: The compiled LangGraph instance with nodes and edges defined. \"\"\" builder = StateGraph ( GSPRState ) builder . add_node ( \"context_builder\" , self . _context_builder ) builder . add_node ( \"section_grouper\" , self . _section_grouper ) builder . add_node ( \"group_runner\" , self . _group_runner ) builder . add_conditional_edges ( \"context_builder\" , self . _route_from_context_builder ) builder . add_edge ( START , \"context_builder\" ) builder . add_edge ( \"section_grouper\" , \"group_runner\" ) builder . add_edge ( \"group_runner\" , END ) return builder . compile ( checkpointer = self . memory ) # --------------------------------------------------------------------- # Router # --------------------------------------------------------------------- def _route_from_context_builder ( self , state : GSPRState ) -> str : state [ \"component_name\" ] = self . component_name if state . get ( \"all_sections\" ): return \"section_grouper\" logger . warning ( \"GSPRGraph: No 'all_sections' provided; finishing.\" ) return END # type: ignore[return-value] # --------------------------------------------------------------------- # Node: Context Builder # --------------------------------------------------------------------- async def _context_builder ( self , state : GSPRState ) -> GSPRState : try : # Step 1 \u2014 determine adaptive temperature for this node temperature = await self . chain . determine_temperature ( node_title = \"Context Builder\" , context = { \"phase\" : \"initial_context_building\" }, ) # Step 2 \u2014 run context building with that temperature enriched = await self . chain . build_context ( base_context = state . get ( \"context\" , {}), temperature = temperature , ) return { \"context\" : enriched , \"temperature\" : temperature } except Exception as e : logger . exception ( \"Context builder failed: %s \" , e ) return { \"context\" : state . get ( \"context\" , {}), \"errors\" : [ str ( e )]} # --------------------------------------------------------------------- # Node: Section Grouper # --------------------------------------------------------------------- async def _section_grouper ( self , state : GSPRState ) -> GSPRState : logger . info ( \"section grouper called\" ) logger . info ( \"......................\" ) sections = state . get ( \"all_sections\" , []) logger . info ( f \"Number of sections: { len ( sections ) } \" ) logger . info ( \"#####################################\" ) if not sections : return { \"grouped_sections\" : []} try : # \ud83d\udd25 Adaptive temperature reasoning for this node temperature = await self . chain . determine_temperature ( node_title = \"Section Grouper\" , context = state . get ( \"context\" , {}), ) # Group sections semantically using LLM grouped = await self . chain . group_sections ( sections = sections , context = state . get ( \"context\" , {}), temperature = temperature , ) logger . info ( f \"Grouped sections: { grouped } \" ) logger . info ( \"#####################################\" ) logger . info ( \"section grouper ended\" ) return { \"grouped_sections\" : grouped , \"temperature\" : temperature } except Exception as e : logger . exception ( \"Section grouper failed: %s \" , e ) return { \"grouped_sections\" : [], \"errors\" : [ str ( e )]} # Node: Group Runner # --------------------------------------------------------------------- async def _group_runner ( self , state : GSPRState ) -> GSPRState : grouped = state . get ( \"grouped_sections\" , []) if not grouped : return { \"group_results\" : []} semaphore = asyncio . Semaphore ( self . concurrency_limit ) results : list [ dict [ str , Any ]] = [] async def _run_one ( group_name : str , section : dict [ str , Any ]) -> None : async with semaphore : try : # Publish section started event if self . job_id : from regulatory.app.core.state import get_job_manager job_mgr = get_job_manager () job_mgr . events . section_started ( self . job_id , section_no = len ( results ) + 1 , section_id = section . get ( \"id\" ), requirement_type = section . get ( \"requirement_type\" , \"Unknown\" ), title = section . get ( \"title\" , \"\" )) logger . info ( f \"Published section_started event for section { section . get ( 'id' ) } in job { self . job_id } \" ) # \ud83d\udd25 Temperature reasoning for this specific section temp_value = await self . chain . determine_temperature ( node_title = f \" { group_name } \u2014 { section . get ( 'title' , '' ) } \" , context = state . get ( \"context\" , {}), ) out = await self . chain . generate_section ( session_id = self . session_id , section = section , context = state . get ( \"context\" , {}), group_name = group_name , component_name = state . get ( \"component_name\" , \"unknown\" ), temperature = temp_value , ) section_result = { ** out , \"section_id\" : section . get ( \"id\" ), \"title\" : section . get ( \"title\" ), \"group\" : group_name , \"temperature_used\" : temp_value , } results . append ( section_result ) # Update job manager progress for real-time streaming if self . job_id : from regulatory.app.core.state import get_job_manager job_mgr = get_job_manager () # Check if section was successful - look for success status or applicable is_success = section_result . get ( \"status\" ) == \"success\" or section_result . get ( \"is_applicable\" , False ) if is_success : job_mgr . update_progress ( self . job_id , inc_completed = 1 ) # Publish section completed event with proper data job_mgr . events . section_completed ( self . job_id , section_no = len ( results ), title = section . get ( \"title\" , \"\" ), requirement_type = section . get ( \"requirement_type\" , \"Unknown\" ), section_id = section . get ( \"id\" ), applicable = out . get ( \"is_applicable\" , False ), requirement_justification = out . get ( \"requirement_justification\" , \"Not specified\" ), standard = out . get ( \"standard\" , \"None\" ), ) logger . info ( f \"Section { section . get ( 'id' ) } completed - Standard: { out . get ( 'standard' , 'None' ) } , Applicable: { out . get ( 'is_applicable' , False ) } \" ) else : job_mgr . update_progress ( self . job_id , inc_completed = 1 ) # Still count as completed even if not applicable # Publish section completed event for non-applicable sections job_mgr . events . section_completed ( self . job_id , section_no = len ( results ), title = section . get ( \"title\" , \"\" ), requirement_type = section . get ( \"requirement_type\" , \"Unknown\" ), section_id = section . get ( \"id\" ), applicable = False , requirement_justification = out . get ( \"requirement_justification\" , \"Not applicable\" ), standard = out . get ( \"standard\" , \"None\" ), ) logger . info ( f \"Section { section . get ( 'id' ) } completed as not applicable - Standard: { out . get ( 'standard' , 'None' ) } \" ) # Save results to session manager after every result try : session_mgr = get_session_manager () if session_mgr and self . session_id : session_mgr . update_nested ( self . session_id , { \"gspr_section_results\" : { str ( section . get ( \"id\" )): section_result }}) logger . debug ( f \"Updated session with result for section { section . get ( 'id' ) } \" ) except Exception as session_error : logger . warning ( f \"Failed to update session for section { section . get ( 'id' ) } : { session_error } \" ) except Exception as e : error_result = { \"section_id\" : section . get ( \"id\" ), \"title\" : section . get ( \"title\" ), \"group\" : group_name , \"error\" : str ( e ), \"status\" : \"failed\" , } results . append ( error_result ) # Update job manager for failed section if self . job_id : from regulatory.app.core.state import get_job_manager job_mgr = get_job_manager () job_mgr . update_progress ( self . job_id , inc_failed = 1 ) # Publish section failed event job_mgr . events . section_failed ( self . job_id , section_no = len ( results ), error = str ( e ), attempts = 1 ) logger . error ( f \"Section { section . get ( 'id' ) } failed with error: { e } , updated progress for job { self . job_id } \" ) try : session_mgr = get_session_manager () if session_mgr and self . session_id : session_mgr . update_nested ( self . session_id , { \"gspr_section_results\" : { str ( section . get ( \"id\" )): error_result }}) logger . debug ( f \"Updated session with error for section { section . get ( 'id' ) } \" ) except Exception as session_error : logger . warning ( f \"Failed to update session for failed section { section . get ( 'id' ) } : { session_error } \" ) # Append to state[\"group_results\"] if it exists if \"group_results\" in state and isinstance ( state [ \"group_results\" ], list ): state [ \"group_results\" ] . append ( results [ - 1 ]) tasks = [ asyncio . create_task ( _run_one ( g [ \"group\" ], s )) for g in grouped for s in g . get ( \"sections\" , [])] await asyncio . gather ( * tasks ) logger . info ( f \"\ud83c\udfaf All { len ( results ) } sections processed. Saving complete analysis results...\" ) return { \"group_results\" : results } run ( * , sections , session_id = '' ) async Bulk processing entrypoint for GSPR generation. Parameters: Name Type Description Default sections list [ dict [ str , Any ]] The list of sections to process. required session_id str The session identifier for the current run. '' Returns: Type Description dict [ str , Any ] dict[str, Any]: The results of the GSPR generation, including context, dict [ str , Any ] grouped sections, results, and any errors encountered. Source code in core/graph/gspr_graph.py 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 async def run ( self , * , sections : list [ dict [ str , Any ]], session_id : str = \"\" , ) -> dict [ str , Any ]: \"\"\" Bulk processing entrypoint for GSPR generation. Args: sections (list[dict[str, Any]]): The list of sections to process. session_id (str, optional): The session identifier for the current run. Returns: dict[str, Any]: The results of the GSPR generation, including context, grouped sections, results, and any errors encountered. \"\"\" initial : GSPRState = { \"messages\" : [], \"context\" : self . base_context , \"component_name\" : self . component_name , \"all_sections\" : sections , \"errors\" : [], } logger . info ( f \"Starting GSPRGraph run for component: { self . component_name } with { len ( sections ) } sections.\" ) # Configure checkpointer with thread_id config = RunnableConfig ( configurable = { \"thread_id\" : f \"gspr- { self . component_name } \" }) final = cast ( GSPRState , await self . graph . ainvoke ( initial , config = config )) logger . info ( f \"GSPRGraph run complete for component: { self . component_name } . Errors: { final . get ( 'errors' , []) } \" ) return { \"context\" : final . get ( \"context\" , {}), \"grouped_sections\" : final . get ( \"grouped_sections\" , []), \"results\" : final . get ( \"group_results\" , []), \"errors\" : final . get ( \"errors\" , []), } GSPRState Bases: TypedDict Shared state passed between LangGraph nodes. Source code in core/graph/gspr_graph.py 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 class GSPRState ( TypedDict , total = False ): \"\"\"Shared state passed between LangGraph nodes.\"\"\" messages : Annotated [ list , add_messages ] context : dict [ str , Any ] component_name : str all_sections : list [ dict [ str , Any ]] grouped_sections : list [ dict [ str , Any ]] result : dict [ str , Any ] group_results : list [ dict [ str , Any ]] errors : list [ str ] # Adaptive parameters temperature : float","title":"Graph Nodes"},{"location":"ai_backend/graphs/#intelligent-regulatory-automation-nodes-core-system-modules","text":"","title":"\ud83d\udda5\ufe0f Intelligent Regulatory Automation Nodes \u2014 Core System Modules"},{"location":"ai_backend/graphs/#component-recommender-node-suggest-device-subsystems","text":"Recommends appropriate components and subsystems for the device based on intended function and materials. Optimizes design completeness and modular traceability.","title":"\ud83c\udfd7\ufe0f Component Recommender Node \u2014 Suggest Device Subsystems"},{"location":"ai_backend/graphs/#core.graph.nodes.component_recommender_node.component_recommender_node","text":"Executes the component recommender chain, updates the state with system-generated component suggestions under design_data.system_generated. Parameters: Name Type Description Default state dict The current state of the system, containing device input and design data. required Returns: Name Type Description dict dict The updated state with recommended components added to system-generated design data. Source code in core/graph/nodes/component_recommender_node.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 def component_recommender_node ( state : dict ) -> dict : \"\"\" Executes the component recommender chain, updates the state with system-generated component suggestions under design_data.system_generated. Args: state (dict): The current state of the system, containing device input and design data. Returns: dict: The updated state with recommended components added to system-generated design data. \"\"\" device_input = state [ \"device_input\" ] chain_input = { \"medical_device\" : device_input [ \"medical_device\" ], \"intended_purpose\" : device_input [ \"intended_purpose\" ], \"device_type\" : device_input [ \"device_type\" ], \"material_type\" : device_input [ \"material_type\" ], } logger . info ( \"Input to component recommender chain: \\n %s \" , json . dumps ( chain_input , indent = 2 )) config : RunnableConfig = { \"run_name\" : \"ComponentRecommender\" , \"tags\" : [ \"LLM_APP\" , \"Component_Recommender\" , \"v1.0\" ], \"metadata\" : { \"model\" : \"gpt-4o\" , # or whichever LLM you\u2019re using \"parser\" : \"PydanticOutputParser\" , \"temperature\" : 0.3 , \"max_tokens\" : 1500 , }, } # Get fresh chain instance with current model selection component_recommender_chain = get_component_recommender_chain () response = component_recommender_chain . invoke ( chain_input , config = config ) logger . debug ( \"Raw LLM response: %s \" , response ) if isinstance ( response , BaseModel ): response = response . model_dump () else : raise TypeError ( \"Response must be a dict or Pydantic object with .dict() method.\" ) model = ComponentRecommenderModel ( ** response ) logger . info ( \"Recommended Components: %s \" , model . components_list ) # Update state with recommended components (ensuring uniqueness) current_components = state [ \"design_data\" ][ \"system_generated\" ][ \"components\" ] updated_components = list ( set ( current_components + model . components_list )) state [ \"design_data\" ][ \"system_generated\" ][ \"components\" ] = updated_components logger . info ( \"Updated system_generated components: %s \" , updated_components ) return state","title":"component_recommender_node"},{"location":"ai_backend/graphs/#design-input-node-generate-detailed-design-requirements","text":"Translates high-level specifications into detailed, regulatory-aligned design inputs for all subsystems. Supports parallel processing for material, performance, and human factor requirements.","title":"\ud83d\udcdd Design Input Node \u2014 Generate Detailed Design Requirements"},{"location":"ai_backend/graphs/#core.graph.nodes.design_input_node.design_input_node","text":"Generates and updates the design input for a specific component and GSPR (General Safety and Performance Requirements). Parameters: Name Type Description Default state dict The current state of the system, containing user input and design data. required component_name str The name of the component for which design input is generated. required gspr_no str The GSPR number associated with the design input. required Returns: Name Type Description dict dict The updated state with the generated design input added under the specified component and GSPR. Source code in core/graph/nodes/design_input_node.py 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 def design_input_node ( state : dict , component_name : str , gspr_no : str ) -> dict : \"\"\" Generates and updates the design input for a specific component and GSPR (General Safety and Performance Requirements). Args: state (dict): The current state of the system, containing user input and design data. component_name (str): The name of the component for which design input is generated. gspr_no (str): The GSPR number associated with the design input. Returns: dict: The updated state with the generated design input added under the specified component and GSPR. \"\"\" user_input = state . get ( \"user_input\" , {}) device_meta = { \"device_type\" : user_input . get ( \"device_type\" , \"\" ), \"intended_purpose\" : user_input . get ( \"intended_purpose\" , \"\" ), \"intended_users\" : user_input . get ( \"intended_users\" , []), \"risk_classification\" : user_input . get ( \"risk_classification\" , \"\" ), } logger . info ( f \"Generating design input for component ' { component_name } ' and GSPR ' { gspr_no } '\" ) item : DesignInputModel = fetch_design_input ( device_meta , component_name , gspr_no ) # Ensure top-level design_input exists if \"design_input\" not in state : state [ \"design_input\" ] = {} # Ensure component dict exists if component_name not in state [ \"design_input\" ]: state [ \"design_input\" ][ component_name ] = {} # Save GSPR entry under component state [ \"design_input\" ][ component_name ][ gspr_no ] = { \"component\" : item . component , \"requirement\" : item . requirement , \"gspr_text\" : item . gspr_text , \"standards\" : [ std . model_dump () if hasattr ( std , \"model_dump\" ) else std for std in item . standards ], } return state","title":"design_input_node"},{"location":"ai_backend/graphs/#design-output-node-compile-technical-specifications","text":"Aggregates all design outputs including schematics, technical specifications, and implementation instructions. Ensures each output maps back to input requirements for traceability.","title":"\ud83d\udcd0 Design Output Node \u2014 Compile Technical Specifications"},{"location":"ai_backend/graphs/#core.graph.nodes.design_output_node.design_output_node","text":"Generate structured Design Output Reports for all components in the design_input section of the state. This node automatically processes each component's design input using the design output generation chain, which aligns with ISO/IEC standards and GSPR requirements. No user input or PDF references are required \u2014 all context is derived from the internal design input data. Parameters: Name Type Description Default state Dict [ str , Any ] State dictionary containing design input data. Expected structure: { \"design_input\": { \"ComponentName\": { \"device_type\": \"...\", \"component\": \"...\", \"requirement\": \"...\", \"gspr_text\": \"...\", \"standards\": [ ... ] }, ... } } required Returns: Type Description Dict [ str , Any ] Dict[str, Any]: Updated state dictionary including generated design outputs. Example: { \"design_output\": { \"ComponentName\": \" \" } } Source code in core/graph/nodes/design_output_node.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 async def design_output_node ( state : Dict [ str , Any ]) -> Dict [ str , Any ]: \"\"\" Generate structured Design Output Reports for all components in the design_input section of the state. This node automatically processes each component's design input using the design output generation chain, which aligns with ISO/IEC standards and GSPR requirements. No user input or PDF references are required \u2014 all context is derived from the internal design input data. Args: state (Dict[str, Any]): State dictionary containing design input data. Expected structure: { \"design_input\": { \"ComponentName\": { \"device_type\": \"...\", \"component\": \"...\", \"requirement\": \"...\", \"gspr_text\": \"...\", \"standards\": [ ... ] }, ... } } Returns: Dict[str, Any]: Updated state dictionary including generated design outputs. Example: { \"design_output\": { \"ComponentName\": \"<Generated Report Text>\" } } \"\"\" design_inputs = state . get ( \"design_input\" , {}) if not design_inputs : logger . error ( \"No design input found in state.\" ) return state # Initialize design_output container state . setdefault ( \"design_output\" , {}) for component , component_input in design_inputs . items (): logger . info ( f \"Generating Design Output Report for component ' { component } '\" ) try : # Generate design output (auto ISO reference) output_data = await run_design_output_chain ( design_input = component_input , component = component , ) # Store in state state [ \"design_output\" ][ component ] = output_data logger . info ( f \"Design Output successfully generated for ' { component } '\" ) except Exception as e : logger . error ( f \"Error generating Design Output for ' { component } ': { e } \" ) return state","title":"design_output_node"},{"location":"ai_backend/graphs/#gspr-filter-node-refine-safety-performance-requirements","text":"Filters and prioritizes GSPR clauses relevant to the device type, materials, and user environment. Improves efficiency and reduces regulatory noise.","title":"\ud83d\udd04 GSPR Filter Node \u2014 Refine Safety &amp; Performance Requirements"},{"location":"ai_backend/graphs/#core.graph.nodes.gspr_filter_node.gspr_filter_node","text":"Runs the GSPR filter chain for a specific component and GSPR number, and updates the session state with the applicability and justification results. Parameters: Name Type Description Default state dict The current session state containing user input and generated data. required component_name str The name of the component being evaluated. required gspr_number str The GSPR number to filter and evaluate. required Returns: Name Type Description dict dict The updated session state with the GSPR filter results stored under state['gspr_generated'] . Source code in core/graph/nodes/gspr_filter_node.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 def gspr_filter_node ( state : dict , component_name : str , gspr_number : str ) -> dict : \"\"\" Runs the GSPR filter chain for a specific component and GSPR number, and updates the session state with the applicability and justification results. Args: state (dict): The current session state containing user input and generated data. component_name (str): The name of the component being evaluated. gspr_number (str): The GSPR number to filter and evaluate. Returns: dict: The updated session state with the GSPR filter results stored under `state['gspr_generated']`. \"\"\" user_input = state . get ( \"user_input\" ) if not user_input : raise ValueError ( \"Missing 'user_input' in state\" ) gspr_map = build_gspr_map () # Prepare input for the LLM chain chain_input = { \"medical_device\" : user_input . get ( \"medical_device\" ), \"material_type\" : user_input . get ( \"material_type\" ), \"device_type\" : user_input . get ( \"device_type\" ), \"component_name\" : component_name , \"intended_purpose\" : user_input . get ( \"intended_purpose\" ), \"intended_users\" : \", \" . join ( user_input . get ( \"intended_users\" ) or []), \"risk_classification\" : user_input . get ( \"risk_classification\" ), \"gspr_number\" : gspr_number , \"gspr_context\" : gspr_map . get ( gspr_number ) or \"<No GSPR found>\" , } logger . info ( f \"Running GSPR filter for component: { component_name } , GSPR { gspr_number } \" ) logger . debug ( \"Input to GSPR filter chain: \\n %s \" , json . dumps ( chain_input , indent = 2 )) config : RunnableConfig = { \"run_name\" : \"GSPR_Filter\" , \"tags\" : [ \"LLM_APP\" , \"GSPR_Filter\" , \"v1.0\" ], \"metadata\" : { \"model\" : \"gpt-4o\" , # replace with actual model \"parser\" : \"PydanticOutputParser\" , \"temperature\" : 0.2 , # keep low for deterministic applicability \"max_tokens\" : 1200 , }, } # ---------------- Run chain ---------------- response : GSPRFilterResponse = gspr_filter_chain . invoke ( chain_input , config = config ) logger . debug ( \"LLM structured response: %s \" , getattr ( response , \"json\" , lambda : str ( response ))()) # ---------------- Update state ---------------- gspr_generated = state . setdefault ( \"gspr_generated\" , {}) gspr_generated . setdefault ( component_name , {}) gspr_generated [ component_name ] . setdefault ( gspr_number , {}) # Only update the relevant fields under the nested structure. # Do not create separate top-level dicts. gspr_generated [ component_name ][ gspr_number ] . update ( { \"is_applicable\" : bool ( response . is_applicable ), \"justification\" : response . justification or \"\" , } ) logger . info ( f \"\u2705 Updated GSPR state for ' { component_name } ': { gspr_number } -> { response . is_applicable } \" ) return state","title":"gspr_filter_node"},{"location":"ai_backend/graphs/#gspr-generator-node-create-safety-performance-tables","text":"Generates the initial GSPR table linking device features to regulatory clauses and compliance justifications. Supports both FDA and MDR alignment.","title":"\ud83d\uddc2\ufe0f GSPR Generator Node \u2014 Create Safety &amp; Performance Tables"},{"location":"ai_backend/graphs/#core.graph.nodes.gspr_generator_node.gspr_generator_node","text":"Runs the GSPR generator chain for a specific component and GSPR number, and updates the session state with the generated requirements and standards. Parameters: Name Type Description Default state dict The current session state containing user input and generated data. required component_name str The name of the component for which the GSPR is being generated. required main_gspr_number str The main GSPR number associated with the generation process. required Returns: Name Type Description dict dict The updated session state with the GSPR generator results merged under state['gspr_generated'] . Source code in core/graph/nodes/gspr_generator_node.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 def gspr_generator_node ( state : dict , component_name : str , main_gspr_number : str ) -> dict : \"\"\" Runs the GSPR generator chain for a specific component and GSPR number, and updates the session state with the generated requirements and standards. Args: state (dict): The current session state containing user input and generated data. component_name (str): The name of the component for which the GSPR is being generated. main_gspr_number (str): The main GSPR number associated with the generation process. Returns: dict: The updated session state with the GSPR generator results merged under `state['gspr_generated']`. \"\"\" user_input : dict = state . get ( \"user_input\" ) or {} chain_input : dict = { \"medical_device\" : user_input . get ( \"medical_device\" ), \"material_type\" : user_input . get ( \"material_type\" ), \"device_type\" : user_input . get ( \"device_type\" ), \"intended_purpose\" : user_input . get ( \"intended_purpose\" ), \"intended_users\" : \", \" . join ( user_input . get ( \"intended_users\" ) or []), \"risk_classifications\" : user_input . get ( \"risk_classification\" ), \"component\" : component_name , \"gspr\" : main_gspr_number , } logger . info ( f \"Generating GSPR for component: { component_name } , GSPR: { main_gspr_number } \" ) logger . debug ( \"Input to GSPR Generator Chain: %s \" , chain_input ) config : RunnableConfig = { \"run_name\" : \"GSPR_Generator\" , \"tags\" : [ \"LLM_APP\" , \"GSPR_Generator\" , \"v1.0\" ], \"metadata\" : { \"model\" : \"gpt-4o\" , # replace with actual model in use \"parser\" : \"PydanticOutputParser\" , \"temperature\" : 0.3 , # slightly higher than filter to allow some flexibility \"max_tokens\" : 1500 , }, } # Get fresh chain instance with current model selection gspr_generator_chain = get_gspr_generator_chain () response = gspr_generator_chain . invoke ( chain_input , config = config ) logger . debug ( \"\ud83d\udcdd Raw LLM response: %s \" , response ) # Normalize response if isinstance ( response , dict ): item = GSPRGeneratorModel ( ** response ) elif isinstance ( response , GSPRGeneratorModel ): item = response elif isinstance ( response , BaseModel ): item = GSPRGeneratorModel ( ** response . dict ()) else : raise TypeError ( f \"Expected dict or GSPRGeneratorModel, got { type ( response ) } \" ) requirements = item . requirement or \"\" standards = item . standard if isinstance ( item . standard , list ) else ([ item . standard ] if item . standard else []) logger . info ( f \"\u2705 GSPR generated for ' { component_name } ', GSPR { main_gspr_number } \" ) logger . debug ( \"Requirements: %s | Standards: %s \" , requirements , standards ) # ---------------- Update state ---------------- gspr_generated = state . setdefault ( \"gspr_generated\" , {}) gspr_generated . setdefault ( component_name , {}) gspr_generated [ component_name ] . setdefault ( main_gspr_number , {}) # Merge generator fields with whatever filter already stored. gspr_generated [ component_name ][ main_gspr_number ] . update ( { \"requirements\" : requirements , \"standards\" : standards , } ) return state","title":"gspr_generator_node"},{"location":"ai_backend/graphs/#gspr-table-generator-node-structure-compliance-evidence","text":"Builds structured, audit-ready GSPR tables integrating standards, test evidence, and applicability notes.","title":"\ud83d\udcca GSPR Table Generator Node \u2014 Structure Compliance Evidence"},{"location":"ai_backend/graphs/#core.graph.nodes.gspr_table_generator_node.gspr_filter_node","text":"Run the GSPR filter chain for a given component and GSPR number, then update the session state with applicability and justification. All results are stored exclusively under state['gspr_generated'] . Source code in core/graph/nodes/gspr_table_generator_node.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 def gspr_filter_node ( state : dict , component_name : str , gspr_number : str ) -> dict : \"\"\" Run the GSPR filter chain for a given component and GSPR number, then update the session state with applicability and justification. All results are stored exclusively under `state['gspr_generated']`. \"\"\" user_input = state . get ( \"user_input\" ) if not user_input : raise ValueError ( \"Missing 'user_input' in state\" ) gspr_map = build_gspr_map () # Prepare input for the LLM chain chain_input = { \"medical_device\" : user_input . get ( \"medical_device\" ), \"material_type\" : user_input . get ( \"material_type\" ), \"device_type\" : user_input . get ( \"device_type\" ), \"component_name\" : component_name , \"intended_purpose\" : user_input . get ( \"intended_purpose\" ), \"intended_users\" : \", \" . join ( user_input . get ( \"intended_users\" ) or []), \"risk_classification\" : user_input . get ( \"risk_classification\" ), \"gspr_number\" : gspr_number , \"gspr_context\" : gspr_map . get ( gspr_number ) or \"<No GSPR found>\" , } logger . info ( f \"Running GSPR filter for component: { component_name } , GSPR { gspr_number } \" ) logger . debug ( \"Input to GSPR filter chain: \\n %s \" , json . dumps ( chain_input , indent = 2 )) config : RunnableConfig = { \"run_name\" : \"GSPR_Filter\" , \"tags\" : [ \"LLM_APP\" , \"GSPR_Filter\" , \"v1.0\" ], \"metadata\" : { \"model\" : \"gpt-4o\" , # replace with actual model \"parser\" : \"PydanticOutputParser\" , \"temperature\" : 0.2 , # keep low for deterministic applicability \"max_tokens\" : 1200 , }, } # ---------------- Run chain ---------------- response : GSPRFilterResponse = gspr_filter_chain . invoke ( chain_input , config = config ) logger . debug ( \"LLM structured response: %s \" , getattr ( response , \"json\" , lambda : str ( response ))()) # ---------------- Update state ---------------- gspr_generated = state . setdefault ( \"gspr_generated\" , {}) gspr_generated . setdefault ( component_name , {}) gspr_generated [ component_name ] . setdefault ( gspr_number , {}) # Only update the relevant fields under the nested structure. # Do not create separate top-level dicts. gspr_generated [ component_name ][ gspr_number ] . update ( { \"is_applicable\" : bool ( response . is_applicable ), \"justification\" : response . justification or \"\" , } ) logger . info ( f \"\u2705 Updated GSPR state for ' { component_name } ': { gspr_number } -> { response . is_applicable } \" ) return state","title":"gspr_filter_node"},{"location":"ai_backend/graphs/#core.graph.nodes.gspr_table_generator_node.gspr_table_generator_node","text":"Generates applicability and justifications for all 181 GSPR sections for a given component. Updates the session state with the results and returns a summarized table list. Parameters: Name Type Description Default state dict The current session state containing user input and generated data. required component_name str The name of the component for which the GSPR table is generated. required Returns: Type Description dict tuple[dict, list[dict]]: A tuple containing the updated session state and a list of dictionaries list [ dict ] summarizing the GSPR table data. Source code in core/graph/nodes/gspr_table_generator_node.py 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 def gspr_table_generator_node ( state : dict , component_name : str ) -> tuple [ dict , list [ dict ]]: \"\"\" Generates applicability and justifications for all 181 GSPR sections for a given component. Updates the session state with the results and returns a summarized table list. Args: state (dict): The current session state containing user input and generated data. component_name (str): The name of the component for which the GSPR table is generated. Returns: tuple[dict, list[dict]]: A tuple containing the updated session state and a list of dictionaries summarizing the GSPR table data. \"\"\" user_input = state . get ( \"user_input\" ) if not user_input : raise ValueError ( \"Missing 'user_input' in state\" ) gspr_map = build_gspr_map () gspr_generated = state . setdefault ( \"gspr_generated\" , {}) gspr_generated . setdefault ( component_name , {}) table_data = [] config : RunnableConfig = { \"run_name\" : \"GSPR_Table_Generation\" , \"tags\" : [ \"LLM_APP\" , \"GSPR_Table\" , \"v1.0\" ], \"metadata\" : { \"model\" : \"gpt-4o\" , # replace if needed \"parser\" : \"PydanticOutputParser\" , \"temperature\" : 0.2 , \"max_tokens\" : 1200 , }, } logger . info ( f \"\ud83d\udd04 Starting GSPR Table Generation for component: { component_name } \" ) # Iterate through all 181 GSPRs for gspr_no , gspr_context in gspr_map . items (): chain_input = { \"medical_device\" : user_input . get ( \"medical_device\" ), \"material_type\" : user_input . get ( \"material_type\" ), \"device_type\" : user_input . get ( \"device_type\" ), \"component_name\" : component_name , \"intended_purpose\" : user_input . get ( \"intended_purpose\" ), \"intended_users\" : \", \" . join ( user_input . get ( \"intended_users\" ) or []), \"risk_classification\" : user_input . get ( \"risk_classification\" ), \"gspr_number\" : gspr_no , \"gspr_context\" : gspr_context or \"<No GSPR found>\" , } logger . debug ( f \"Running GSPR { gspr_no } for component { component_name } \" ) response : GSPRFilterResponse = gspr_filter_chain . invoke ( chain_input , config = config ) # Save result in session state gspr_generated [ component_name ][ gspr_no ] = { \"is_applicable\" : bool ( response . is_applicable ), \"justification\" : response . justification or \"\" , } # Build response table entry table_data . append ( { \"section_number\" : gspr_no , \"section_name\" : gspr_context . get ( \"title\" ) if isinstance ( gspr_context , dict ) else \"<No title>\" , \"applicable\" : \"Y\" if response . is_applicable else \"N\" , \"justification\" : response . justification or \"No justification provided\" , } ) logger . info ( f \"\u2705 Completed GSPR table generation for { component_name } \" ) return state , table_data","title":"gspr_table_generator_node"},{"location":"ai_backend/graphs/#guard-node-validate-compliance-logic","text":"Enforces regulatory rules across the workflow. Prevents unsafe or inconsistent data propagation and validates each node's output.","title":"\ud83d\udee1\ufe0f Guard Node \u2014 Validate Compliance Logic"},{"location":"ai_backend/graphs/#core.graph.nodes.guard_node.guard_node","text":"Executes the regulatory guard agent to process the given text and category, returning the AI-generated response. Parameters: Name Type Description Default text str The input text to be processed by the regulatory guard agent. required cat str The category associated with the input text. required Returns: Name Type Description str str The content of the AI-generated response. Source code in core/graph/nodes/guard_node.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 def guard_node ( text : str , cat : str ) -> str : \"\"\" Executes the regulatory guard agent to process the given text and category, returning the AI-generated response. Args: text (str): The input text to be processed by the regulatory guard agent. cat (str): The category associated with the input text. Returns: str: The content of the AI-generated response. \"\"\" # Prepare messages in LangChain-native format messages = [ SystemMessage ( content = system_instructions ), HumanMessage ( content = f \"Category: { cat } \\n\\n { text } \" ) ] chain_input = { \"messages\" : messages } logger . info ( \"Input to regulatory_guard_agent_node:\" ) logger . debug ( chain_input ) config = { \"run_name\" : \"Regulatory_Guard_Agent_Node\" , \"tags\" : [ \"LLM_APP\" , \"Regulatory_Agent\" , \"v1.0\" ], \"metadata\" : { \"model\" : \"gpt-4o\" , \"purpose\" : \"regulatory_guard\" , \"temperature\" : 0.2 , \"max_tokens\" : 800 , \"category\" : cat }, } # Get fresh agent instance with current model selection regulatory_guard_agent = get_regulatory_guard_agent () # Execute agent result = regulatory_guard_agent . invoke ( chain_input , config = config ) logger . info ( \"Guard Node Result (raw):\" ) logger . debug ( result ) # --------------------------------------------- # Extract ONLY the AIMessage content # --------------------------------------------- if isinstance ( result , dict ) and \"messages\" in result : for msg in result [ \"messages\" ]: if isinstance ( msg , AIMessage ): print ( \"AIMessage content:\" , msg . content ) return msg . content # <-- return ONLY model output # Fallbacks if agent returns simpler structures if isinstance ( result , AIMessage ): return result . content if isinstance ( result , dict ) and \"content\" in result : return result [ \"content\" ] return str ( result )","title":"guard_node"},{"location":"ai_backend/graphs/#intended-user-node-contextual-requirement-mapping","text":"Incorporates user environment and use-case context into design inputs and risk analysis.","title":"\ud83d\udc64 Intended User Node \u2014 Contextual Requirement Mapping"},{"location":"ai_backend/graphs/#core.graph.nodes.intended_user_node.intended_user_node","text":"Executes the LLM-driven intended user identification chain and updates the state with the identified intended users under design_data.system_generated.intended_users . Parameters: Name Type Description Default state dict The current state of the system, containing device input and design data. required Returns: Name Type Description dict dict The updated state with the identified intended users added to the system-generated design data. Source code in core/graph/nodes/intended_user_node.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 def intended_user_node ( state : dict ) -> dict : \"\"\" Executes the LLM-driven intended user identification chain and updates the state with the identified intended users under `design_data.system_generated.intended_users`. Args: state (dict): The current state of the system, containing device input and design data. Returns: dict: The updated state with the identified intended users added to the system-generated design data. \"\"\" # -------------------------------- # Prepare input for the LLM chain # -------------------------------- device_input = state . get ( \"device_input\" , {}) design_data = state . get ( \"design_data\" , {}) system_generated = design_data . get ( \"system_generated\" , {}) chain_input = { \"medical_device\" : device_input . get ( \"medical_device\" , \"\" ), \"material_type\" : device_input . get ( \"material_type\" , []), \"device_type\" : device_input . get ( \"device_type\" , []), \"intended_purpose\" : device_input . get ( \"intended_purpose\" , \"\" ), \"components\" : system_generated . get ( \"components\" , []), \"risk_classification\" : system_generated . get ( \"risk_classification\" , {}), } logger . info ( \"Input to intended user chain:\" ) logger . debug ( json . dumps ( chain_input , indent = 2 )) # -------------------------------- # Configure and invoke the chain # -------------------------------- config : RunnableConfig = { \"run_name\" : \"IntendedUser\" , \"tags\" : [ \"LLM_APP\" , \"Intended_User\" , \"v1.0\" ], \"metadata\" : { \"model\" : \"gpt-4o\" , \"parser\" : \"PydanticOutputParser\" , \"temperature\" : 0.2 , \"max_tokens\" : 800 , }, } # Get fresh chain instance with current model selection intended_user_chain = get_intended_user_chain () response = intended_user_chain . invoke ( chain_input , config = config ) logger . debug ( \"Raw LLM response: %s \" , response ) # -------------------------------- # Normalize response # -------------------------------- if isinstance ( response , BaseModel ): response = response . model_dump () elif not isinstance ( response , dict ): raise TypeError ( \"Expected response to be a dict or BaseModel.\" ) intended_users = response . get ( \"intended_users\" , []) if not isinstance ( intended_users , list ): raise ValueError ( \"'intended_users' should be a list in the response.\" ) logger . info ( \"Identified Intended Users: %s \" , intended_users ) # -------------------------------- # Update system_generated intended users # -------------------------------- state [ \"design_data\" ][ \"system_generated\" ][ \"intended_users\" ] = list ( set ( intended_users )) logger . info ( \"\u2705 Updated system_generated with intended users:\" ) logger . debug ( json . dumps ( state [ \"design_data\" ][ \"system_generated\" ][ \"intended_users\" ], indent = 2 )) return state","title":"intended_user_node"},{"location":"ai_backend/graphs/#risk-classification-node-determine-device-risk-class","text":"Classifies device according to FDA and MDR risk frameworks. Directly informs GSPR applicability and design control measures.","title":"\u2696\ufe0f Risk Classification Node \u2014 Determine Device Risk Class"},{"location":"ai_backend/graphs/#core.graph.nodes.risk_classify_node.risk_classify_node","text":"Executes the LLM-driven risk classification chain and updates the state with the generated risk classification under design_data.system_generated.risk_classification . Parameters: Name Type Description Default state dict The current state of the system, containing device input and design data. required Returns: Name Type Description dict dict The updated state with the generated risk classification added to the system-generated design data. Source code in core/graph/nodes/risk_classify_node.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 def risk_classify_node ( state : dict ) -> dict : \"\"\" Executes the LLM-driven risk classification chain and updates the state with the generated risk classification under `design_data.system_generated.risk_classification`. Args: state (dict): The current state of the system, containing device input and design data. Returns: dict: The updated state with the generated risk classification added to the system-generated design data. \"\"\" # -------------------------------- # Prepare chain input # -------------------------------- device_input = state . get ( \"device_input\" , {}) design_data = state . get ( \"design_data\" , {}) chain_input = { \"medical_device\" : device_input . get ( \"medical_device\" , \"\" ), \"material_type\" : device_input . get ( \"material_type\" , []), \"device_type\" : device_input . get ( \"device_type\" , []), \"intended_purpose\" : device_input . get ( \"intended_purpose\" , \"\" ), \"components\" : design_data . get ( \"system_generated\" , {}) . get ( \"components\" , []), } logger . info ( \"Input to risk classification chain:\" ) logger . debug ( json . dumps ( chain_input , indent = 2 )) # -------------------------------- # Configure chain execution # -------------------------------- config : RunnableConfig = { \"run_name\" : \"RiskClassification\" , \"tags\" : [ \"LLM_APP\" , \"Risk_Classification\" , \"v1.0\" ], \"metadata\" : { \"model\" : \"gpt-4o\" , \"parser\" : \"PydanticOutputParser\" , \"temperature\" : 0.2 , \"max_tokens\" : 800 , }, } # -------------------------------- # Run LLM chain # -------------------------------- # Get fresh chain instance with current model selection risk_classification_chain = get_risk_classification_chain () response = risk_classification_chain . invoke ( chain_input , config = config ) logger . debug ( \"Raw LLM response: %s \" , response ) if isinstance ( response , BaseModel ): response = response . model_dump () elif not isinstance ( response , dict ): raise TypeError ( \"Response must be a dict or a Pydantic object with .model_dump().\" ) risk_classification = response . get ( \"risk_classification\" ) if not risk_classification : raise ValueError ( \"Invalid or missing 'risk_classification' in response.\" ) # -------------------------------- # Update system_generated risk classification # -------------------------------- state [ \"design_data\" ][ \"system_generated\" ][ \"risk_classification\" ] = risk_classification logger . info ( \"Updated system_generated with risk classification:\" ) logger . debug ( json . dumps ( state [ \"design_data\" ][ \"system_generated\" ][ \"risk_classification\" ], indent = 2 )) return state","title":"risk_classify_node"},{"location":"ai_backend/graphs/#full-gspr-orchestration-graph-end-to-end-flow","text":"Visualizes the complete multi-agent workflow , showing input processing, template generation, and compliance outputs.","title":"\ud83e\udde9 Full GSPR Orchestration Graph \u2014 End-to-End Flow"},{"location":"ai_backend/graphs/#core.graph.gspr_graph.GSPRGraph","text":"LangGraph-based workflow for GSPR generation. This class orchestrates the GSPR generation process using LangGraph nodes. Each node determines its own adaptive LLM temperature using the GSPRChain and performs specific tasks such as context building, section grouping, and group processing. Attributes: Name Type Description chain GSPRChain The chain instance used for GSPR generation. base_context dict The base context shared across nodes. concurrency_limit int The maximum number of concurrent tasks. memory InMemorySaver The in-memory saver for graph checkpoints. graph StateGraph The compiled LangGraph instance. component_name str The name of the component being processed. session_id str The session identifier for the current run. job_id str The job identifier for tracking progress. requirement_sections dict The requirement sections to process. Source code in core/graph/gspr_graph.py 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 class GSPRGraph : \"\"\" LangGraph-based workflow for GSPR generation. This class orchestrates the GSPR generation process using LangGraph nodes. Each node determines its own adaptive LLM temperature using the GSPRChain and performs specific tasks such as context building, section grouping, and group processing. Attributes: chain (GSPRChain): The chain instance used for GSPR generation. base_context (dict): The base context shared across nodes. concurrency_limit (int): The maximum number of concurrent tasks. memory (InMemorySaver): The in-memory saver for graph checkpoints. graph (StateGraph): The compiled LangGraph instance. component_name (str): The name of the component being processed. session_id (str): The session identifier for the current run. job_id (str): The job identifier for tracking progress. requirement_sections (dict): The requirement sections to process. \"\"\" def __init__ ( self , chain : GSPRChain , context : Optional [ dict [ str , Any ]] = None , * , concurrency_limit : int = 10 , component_name : str = \" unknown\" , session_id : str = \"\" , job_id : str = \"\" , requirement_sections : dict [ str , list [ dict [ str , Any ]]], ) -> None : self . chain = chain self . base_context = context or {} self . concurrency_limit = concurrency_limit self . memory = InMemorySaver () self . graph = self . _build_graph () self . component_name = component_name self . session_id = session_id self . job_id = job_id self . requirement_sections = requirement_sections logger . info ( f \"Initialized GSPRGraph for component: { self . component_name } , job_id: { self . job_id } \" ) # --------------------------------------------------------------------- # Public API # --------------------------------------------------------------------- async def run ( self , * , sections : list [ dict [ str , Any ]], session_id : str = \"\" , ) -> dict [ str , Any ]: \"\"\" Bulk processing entrypoint for GSPR generation. Args: sections (list[dict[str, Any]]): The list of sections to process. session_id (str, optional): The session identifier for the current run. Returns: dict[str, Any]: The results of the GSPR generation, including context, grouped sections, results, and any errors encountered. \"\"\" initial : GSPRState = { \"messages\" : [], \"context\" : self . base_context , \"component_name\" : self . component_name , \"all_sections\" : sections , \"errors\" : [], } logger . info ( f \"Starting GSPRGraph run for component: { self . component_name } with { len ( sections ) } sections.\" ) # Configure checkpointer with thread_id config = RunnableConfig ( configurable = { \"thread_id\" : f \"gspr- { self . component_name } \" }) final = cast ( GSPRState , await self . graph . ainvoke ( initial , config = config )) logger . info ( f \"GSPRGraph run complete for component: { self . component_name } . Errors: { final . get ( 'errors' , []) } \" ) return { \"context\" : final . get ( \"context\" , {}), \"grouped_sections\" : final . get ( \"grouped_sections\" , []), \"results\" : final . get ( \"group_results\" , []), \"errors\" : final . get ( \"errors\" , []), } # --------------------------------------------------------------------- # LangGraph: Build graph # --------------------------------------------------------------------- def _build_graph ( self ): \"\"\" Builds the LangGraph instance for the GSPR workflow. Returns: StateGraph: The compiled LangGraph instance with nodes and edges defined. \"\"\" builder = StateGraph ( GSPRState ) builder . add_node ( \"context_builder\" , self . _context_builder ) builder . add_node ( \"section_grouper\" , self . _section_grouper ) builder . add_node ( \"group_runner\" , self . _group_runner ) builder . add_conditional_edges ( \"context_builder\" , self . _route_from_context_builder ) builder . add_edge ( START , \"context_builder\" ) builder . add_edge ( \"section_grouper\" , \"group_runner\" ) builder . add_edge ( \"group_runner\" , END ) return builder . compile ( checkpointer = self . memory ) # --------------------------------------------------------------------- # Router # --------------------------------------------------------------------- def _route_from_context_builder ( self , state : GSPRState ) -> str : state [ \"component_name\" ] = self . component_name if state . get ( \"all_sections\" ): return \"section_grouper\" logger . warning ( \"GSPRGraph: No 'all_sections' provided; finishing.\" ) return END # type: ignore[return-value] # --------------------------------------------------------------------- # Node: Context Builder # --------------------------------------------------------------------- async def _context_builder ( self , state : GSPRState ) -> GSPRState : try : # Step 1 \u2014 determine adaptive temperature for this node temperature = await self . chain . determine_temperature ( node_title = \"Context Builder\" , context = { \"phase\" : \"initial_context_building\" }, ) # Step 2 \u2014 run context building with that temperature enriched = await self . chain . build_context ( base_context = state . get ( \"context\" , {}), temperature = temperature , ) return { \"context\" : enriched , \"temperature\" : temperature } except Exception as e : logger . exception ( \"Context builder failed: %s \" , e ) return { \"context\" : state . get ( \"context\" , {}), \"errors\" : [ str ( e )]} # --------------------------------------------------------------------- # Node: Section Grouper # --------------------------------------------------------------------- async def _section_grouper ( self , state : GSPRState ) -> GSPRState : logger . info ( \"section grouper called\" ) logger . info ( \"......................\" ) sections = state . get ( \"all_sections\" , []) logger . info ( f \"Number of sections: { len ( sections ) } \" ) logger . info ( \"#####################################\" ) if not sections : return { \"grouped_sections\" : []} try : # \ud83d\udd25 Adaptive temperature reasoning for this node temperature = await self . chain . determine_temperature ( node_title = \"Section Grouper\" , context = state . get ( \"context\" , {}), ) # Group sections semantically using LLM grouped = await self . chain . group_sections ( sections = sections , context = state . get ( \"context\" , {}), temperature = temperature , ) logger . info ( f \"Grouped sections: { grouped } \" ) logger . info ( \"#####################################\" ) logger . info ( \"section grouper ended\" ) return { \"grouped_sections\" : grouped , \"temperature\" : temperature } except Exception as e : logger . exception ( \"Section grouper failed: %s \" , e ) return { \"grouped_sections\" : [], \"errors\" : [ str ( e )]} # Node: Group Runner # --------------------------------------------------------------------- async def _group_runner ( self , state : GSPRState ) -> GSPRState : grouped = state . get ( \"grouped_sections\" , []) if not grouped : return { \"group_results\" : []} semaphore = asyncio . Semaphore ( self . concurrency_limit ) results : list [ dict [ str , Any ]] = [] async def _run_one ( group_name : str , section : dict [ str , Any ]) -> None : async with semaphore : try : # Publish section started event if self . job_id : from regulatory.app.core.state import get_job_manager job_mgr = get_job_manager () job_mgr . events . section_started ( self . job_id , section_no = len ( results ) + 1 , section_id = section . get ( \"id\" ), requirement_type = section . get ( \"requirement_type\" , \"Unknown\" ), title = section . get ( \"title\" , \"\" )) logger . info ( f \"Published section_started event for section { section . get ( 'id' ) } in job { self . job_id } \" ) # \ud83d\udd25 Temperature reasoning for this specific section temp_value = await self . chain . determine_temperature ( node_title = f \" { group_name } \u2014 { section . get ( 'title' , '' ) } \" , context = state . get ( \"context\" , {}), ) out = await self . chain . generate_section ( session_id = self . session_id , section = section , context = state . get ( \"context\" , {}), group_name = group_name , component_name = state . get ( \"component_name\" , \"unknown\" ), temperature = temp_value , ) section_result = { ** out , \"section_id\" : section . get ( \"id\" ), \"title\" : section . get ( \"title\" ), \"group\" : group_name , \"temperature_used\" : temp_value , } results . append ( section_result ) # Update job manager progress for real-time streaming if self . job_id : from regulatory.app.core.state import get_job_manager job_mgr = get_job_manager () # Check if section was successful - look for success status or applicable is_success = section_result . get ( \"status\" ) == \"success\" or section_result . get ( \"is_applicable\" , False ) if is_success : job_mgr . update_progress ( self . job_id , inc_completed = 1 ) # Publish section completed event with proper data job_mgr . events . section_completed ( self . job_id , section_no = len ( results ), title = section . get ( \"title\" , \"\" ), requirement_type = section . get ( \"requirement_type\" , \"Unknown\" ), section_id = section . get ( \"id\" ), applicable = out . get ( \"is_applicable\" , False ), requirement_justification = out . get ( \"requirement_justification\" , \"Not specified\" ), standard = out . get ( \"standard\" , \"None\" ), ) logger . info ( f \"Section { section . get ( 'id' ) } completed - Standard: { out . get ( 'standard' , 'None' ) } , Applicable: { out . get ( 'is_applicable' , False ) } \" ) else : job_mgr . update_progress ( self . job_id , inc_completed = 1 ) # Still count as completed even if not applicable # Publish section completed event for non-applicable sections job_mgr . events . section_completed ( self . job_id , section_no = len ( results ), title = section . get ( \"title\" , \"\" ), requirement_type = section . get ( \"requirement_type\" , \"Unknown\" ), section_id = section . get ( \"id\" ), applicable = False , requirement_justification = out . get ( \"requirement_justification\" , \"Not applicable\" ), standard = out . get ( \"standard\" , \"None\" ), ) logger . info ( f \"Section { section . get ( 'id' ) } completed as not applicable - Standard: { out . get ( 'standard' , 'None' ) } \" ) # Save results to session manager after every result try : session_mgr = get_session_manager () if session_mgr and self . session_id : session_mgr . update_nested ( self . session_id , { \"gspr_section_results\" : { str ( section . get ( \"id\" )): section_result }}) logger . debug ( f \"Updated session with result for section { section . get ( 'id' ) } \" ) except Exception as session_error : logger . warning ( f \"Failed to update session for section { section . get ( 'id' ) } : { session_error } \" ) except Exception as e : error_result = { \"section_id\" : section . get ( \"id\" ), \"title\" : section . get ( \"title\" ), \"group\" : group_name , \"error\" : str ( e ), \"status\" : \"failed\" , } results . append ( error_result ) # Update job manager for failed section if self . job_id : from regulatory.app.core.state import get_job_manager job_mgr = get_job_manager () job_mgr . update_progress ( self . job_id , inc_failed = 1 ) # Publish section failed event job_mgr . events . section_failed ( self . job_id , section_no = len ( results ), error = str ( e ), attempts = 1 ) logger . error ( f \"Section { section . get ( 'id' ) } failed with error: { e } , updated progress for job { self . job_id } \" ) try : session_mgr = get_session_manager () if session_mgr and self . session_id : session_mgr . update_nested ( self . session_id , { \"gspr_section_results\" : { str ( section . get ( \"id\" )): error_result }}) logger . debug ( f \"Updated session with error for section { section . get ( 'id' ) } \" ) except Exception as session_error : logger . warning ( f \"Failed to update session for failed section { section . get ( 'id' ) } : { session_error } \" ) # Append to state[\"group_results\"] if it exists if \"group_results\" in state and isinstance ( state [ \"group_results\" ], list ): state [ \"group_results\" ] . append ( results [ - 1 ]) tasks = [ asyncio . create_task ( _run_one ( g [ \"group\" ], s )) for g in grouped for s in g . get ( \"sections\" , [])] await asyncio . gather ( * tasks ) logger . info ( f \"\ud83c\udfaf All { len ( results ) } sections processed. Saving complete analysis results...\" ) return { \"group_results\" : results }","title":"GSPRGraph"},{"location":"ai_backend/graphs/#core.graph.gspr_graph.GSPRGraph.run","text":"Bulk processing entrypoint for GSPR generation. Parameters: Name Type Description Default sections list [ dict [ str , Any ]] The list of sections to process. required session_id str The session identifier for the current run. '' Returns: Type Description dict [ str , Any ] dict[str, Any]: The results of the GSPR generation, including context, dict [ str , Any ] grouped sections, results, and any errors encountered. Source code in core/graph/gspr_graph.py 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 async def run ( self , * , sections : list [ dict [ str , Any ]], session_id : str = \"\" , ) -> dict [ str , Any ]: \"\"\" Bulk processing entrypoint for GSPR generation. Args: sections (list[dict[str, Any]]): The list of sections to process. session_id (str, optional): The session identifier for the current run. Returns: dict[str, Any]: The results of the GSPR generation, including context, grouped sections, results, and any errors encountered. \"\"\" initial : GSPRState = { \"messages\" : [], \"context\" : self . base_context , \"component_name\" : self . component_name , \"all_sections\" : sections , \"errors\" : [], } logger . info ( f \"Starting GSPRGraph run for component: { self . component_name } with { len ( sections ) } sections.\" ) # Configure checkpointer with thread_id config = RunnableConfig ( configurable = { \"thread_id\" : f \"gspr- { self . component_name } \" }) final = cast ( GSPRState , await self . graph . ainvoke ( initial , config = config )) logger . info ( f \"GSPRGraph run complete for component: { self . component_name } . Errors: { final . get ( 'errors' , []) } \" ) return { \"context\" : final . get ( \"context\" , {}), \"grouped_sections\" : final . get ( \"grouped_sections\" , []), \"results\" : final . get ( \"group_results\" , []), \"errors\" : final . get ( \"errors\" , []), }","title":"run"},{"location":"ai_backend/graphs/#core.graph.gspr_graph.GSPRState","text":"Bases: TypedDict Shared state passed between LangGraph nodes. Source code in core/graph/gspr_graph.py 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 class GSPRState ( TypedDict , total = False ): \"\"\"Shared state passed between LangGraph nodes.\"\"\" messages : Annotated [ list , add_messages ] context : dict [ str , Any ] component_name : str all_sections : list [ dict [ str , Any ]] grouped_sections : list [ dict [ str , Any ]] result : dict [ str , Any ] group_results : list [ dict [ str , Any ]] errors : list [ str ] # Adaptive parameters temperature : float","title":"GSPRState"},{"location":"ai_backend/others/","text":"\ud83d\uddc2\ufe0f Other Core Modules \u2014 References \ud83e\udd16 LLM Provider \u2014 Unified Model Interface Manages access to the underlying LLMs used across all regulatory workflows. Ensures consistent configuration, temperature control, and model routing. get_available_models () Retrieves a list of all available models supported by the LLM provider. Returns: Type Description list [ str ] list[str]: A list of available model names. Source code in core/llm/llm_provider.py 53 54 55 56 57 58 59 60 def get_available_models () -> list [ str ]: \"\"\" Retrieves a list of all available models supported by the LLM provider. Returns: list[str]: A list of available model names. \"\"\" return [ \"gpt-4o\" , \"gemini-2.5-flash\" , \"mistral-large-latest\" , \"deepseek-chat\" , \"grok-4-1-fast-non-reasoning-latest\" , \"claude-sonnet-4-5-20250929\" ] get_chatfda_llm () Returns a ChatOpenAI instance configured for ChatFDA. Source code in core/llm/llm_provider.py 227 228 229 230 231 232 233 234 235 def get_chatfda_llm (): \"\"\"Returns a ChatOpenAI instance configured for ChatFDA.\"\"\" logger . info ( \"Using ChatFDA via Langchain ChatOpenAI\" ) api_key = os . getenv ( \"CHATFDA_API_KEY\" ) return ChatOpenAI ( model = \"chatfda-diamond\" , base_url = \"https://api.chatmdr.eu/v1/\" , api_key = SecretStr ( api_key ) if api_key is not None else None , ) get_chatmdr_llm () Returns a ChatOpenAI instance configured for ChatMDR. Source code in core/llm/llm_provider.py 216 217 218 219 220 221 222 223 224 def get_chatmdr_llm (): \"\"\"Returns a ChatOpenAI instance configured for ChatMDR.\"\"\" logger . info ( \"Using ChatMDR via Langchain ChatOpenAI\" ) api_key = os . getenv ( \"CHATMDR_API_KEY\" ) return ChatOpenAI ( model = \"chatmdr-smart\" , base_url = \"https://api.chatmdr.eu/v1/\" , api_key = SecretStr ( api_key ) if api_key is not None else None , ) get_claude_llm ( model = 'claude-sonnet-4-5-20250929' , temperature = 0.2 ) Returns a ChatAnthropic instance configured for Claude. Source code in core/llm/llm_provider.py 155 156 157 158 159 160 161 162 163 164 165 166 167 168 def get_claude_llm ( model : str = \"claude-sonnet-4-5-20250929\" , temperature : float = 0.2 ): \"\"\"Returns a ChatAnthropic instance configured for Claude.\"\"\" logger . info ( f \"Using Claude LLM with model { model } \" ) try : from langchain_anthropic import ChatAnthropic api_key = os . getenv ( \"ANTHROPIC_API_KEY\" ) return ChatAnthropic ( model = model , temperature = temperature , api_key = api_key , # Don't wrap in SecretStr for Anthropic ) except ImportError : logger . error ( \"langchain_anthropic not installed. Install with: pip install langchain-anthropic\" ) raise ImportError ( \"langchain_anthropic package required for Claude support\" ) get_deepseek_llm ( model = 'deepseek-chat' , temperature = 0.2 ) Returns a ChatOpenAI instance configured for DeepSeek API. Source code in core/llm/llm_provider.py 131 132 133 134 135 136 137 138 139 140 def get_deepseek_llm ( model : str = \"deepseek-chat\" , temperature : float = 0.2 ): \"\"\"Returns a ChatOpenAI instance configured for DeepSeek API.\"\"\" logger . info ( f \"Using DeepSeek LLM with model { model } \" ) api_key = os . getenv ( \"DEEPSEEK_API_KEY\" ) return ChatOpenAI ( model = model , temperature = temperature , base_url = \"https://api.deepseek.com/v1/\" , api_key = SecretStr ( api_key ) if api_key is not None else None , ) get_gemini_llm ( model = 'gemini-2.5-flash' , temperature = 0.3 ) Returns a ChatGoogleGenerativeAI instance configured for the Gemini Pro model. Parameters: Name Type Description Default model str The name of the Gemini model to use. Defaults to \"gemini-2.5-flash\". 'gemini-2.5-flash' temperature float The temperature setting for the model. Defaults to 0.3. 0.3 Returns: Name Type Description ChatGoogleGenerativeAI An instance of the Gemini LLM. Source code in core/llm/llm_provider.py 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 def get_gemini_llm ( model : str = \"gemini-2.5-flash\" , temperature : float = 0.3 ): \"\"\" Returns a ChatGoogleGenerativeAI instance configured for the Gemini Pro model. Args: model (str): The name of the Gemini model to use. Defaults to \"gemini-2.5-flash\". temperature (float): The temperature setting for the model. Defaults to 0.3. Returns: ChatGoogleGenerativeAI: An instance of the Gemini LLM. \"\"\" logger . info ( f \"Using Gemini LLM with model { model } \" ) api_key = os . getenv ( \"GEMINI_API_KEY\" ) return ChatGoogleGenerativeAI ( model = model , temperature = temperature , google_api_key = api_key , ) get_gpt_llm ( model = 'gpt-4o' , temperature = 0.2 ) Returns a ChatOpenAI instance configured for GPT models. Source code in core/llm/llm_provider.py 207 208 209 210 211 212 213 def get_gpt_llm ( model : str = \"gpt-4o\" , temperature : float = 0.2 ): \"\"\"Returns a ChatOpenAI instance configured for GPT models.\"\"\" logger . info ( f \"Using OpenAI ChatGPT with model { model } \" ) return ChatOpenAI ( model = model , temperature = temperature , ) get_grok_llm ( model = 'grok-4-1-fast-non-reasoning-latest' , temperature = 0.2 ) Returns a ChatOpenAI instance configured for Grok API. Source code in core/llm/llm_provider.py 143 144 145 146 147 148 149 150 151 152 def get_grok_llm ( model : str = \"grok-4-1-fast-non-reasoning-latest\" , temperature : float = 0.2 ): \"\"\"Returns a ChatOpenAI instance configured for Grok API.\"\"\" logger . info ( f \"Using Grok LLM with model { model } \" ) api_key = os . getenv ( \"GROK_API_KEY\" ) return ChatOpenAI ( model = model , temperature = temperature , base_url = \"https://api.x.ai/v1/\" , api_key = SecretStr ( api_key ) if api_key is not None else None , ) get_groq_llm () Returns a ChatGroq instance configured for the DeepSeek model. Source code in core/llm/llm_provider.py 123 124 125 126 127 128 def get_groq_llm (): \"\"\"Returns a ChatGroq instance configured for the DeepSeek model.\"\"\" return ChatGroq ( model = \"deepseek-r1-distill-llama-70b\" , temperature = 0.5 , # Optional: control randomness ) get_mistral_llm ( model = 'mistral-large-latest' , temperature = 0.3 ) Returns a ChatMistralAI instance configured for the Mistral Large model. Parameters: Name Type Description Default model str The name of the Mistral model to use. Defaults to \"mistral-large-latest\". 'mistral-large-latest' temperature float The temperature setting for the model. Defaults to 0.3. 0.3 Returns: Name Type Description ChatMistralAI An instance of the Mistral LLM. Source code in core/llm/llm_provider.py 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 def get_mistral_llm ( model : str = \"mistral-large-latest\" , temperature : float = 0.3 ): \"\"\" Returns a ChatMistralAI instance configured for the Mistral Large model. Args: model (str): The name of the Mistral model to use. Defaults to \"mistral-large-latest\". temperature (float): The temperature setting for the model. Defaults to 0.3. Returns: ChatMistralAI: An instance of the Mistral LLM. \"\"\" logger . info ( f \"Using Mistral LLM with model { model } \" ) api_key = os . getenv ( \"MISTRAL_API_KEY\" ) return ChatMistralAI ( model = model , temperature = temperature , api_key = SecretStr ( api_key ) if api_key else None , ) get_selected_model () Retrieves the currently selected model for the LLM provider. Returns: Name Type Description str str The name of the currently selected model. Defaults to _DEFAULT_MODEL if no model is set. Source code in core/llm/llm_provider.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 def get_selected_model () -> str : \"\"\" Retrieves the currently selected model for the LLM provider. Returns: str: The name of the currently selected model. Defaults to `_DEFAULT_MODEL` if no model is set. \"\"\" try : if _SELECTED_MODEL_FILE . exists (): return _SELECTED_MODEL_FILE . read_text () . strip () return _DEFAULT_MODEL except Exception as e : logger . warning ( f \"Failed to read selected model: { e } , using default\" ) return _DEFAULT_MODEL get_vllm_llm ( model = None , temperature = 0.2 ) Returns an LLM instance based on the selected model choice. Source code in core/llm/llm_provider.py 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 def get_vllm_llm ( model : str = None , temperature : float = 0.2 ): \"\"\"Returns an LLM instance based on the selected model choice.\"\"\" # Use selected model if no specific model is provided if model is None : model = get_selected_model () available_models = get_available_models () if model not in available_models : logger . warning ( f \"Model { model } not available, using default { _DEFAULT_MODEL } \" ) model = _DEFAULT_MODEL logger . info ( f \"Using model { model } \" ) # Return appropriate LLM instance based on model log_file = \"selected_model.log\" with open ( log_file , \"a\" ) as f : # \"a\" = append, creates file if not present f . write ( f \"Selected model before assignment: { model } \\n \" ) if model == \"gpt-4o\" : return get_gpt_llm ( \"gpt-4o\" , temperature ) elif model == \"gemini-2.5-flash\" : return get_gemini_llm ( \"gemini-2.5-flash\" , temperature ) elif model == \"mistral-large-latest\" : return get_mistral_llm ( \"mistral-large-latest\" , temperature ) elif model == \"deepseek-chat\" : return get_deepseek_llm ( \"deepseek-chat\" , temperature ) elif model == \"grok-4-1-fast-non-reasoning-latest\" : return get_grok_llm ( \"grok-4-1-fast-non-reasoning-latest\" , temperature ) elif model == \"claude-sonnet-4-5-20250929\" : return get_claude_llm ( \"claude-sonnet-4-5-20250929\" , temperature ) else : # Fallback to OpenAI GPT-4o return get_gpt_llm ( \"gpt-4o\" , temperature ) set_selected_model ( model ) Sets the selected model for the LLM provider. Parameters: Name Type Description Default model str The name of the model to set as the selected model. required Source code in core/llm/llm_provider.py 40 41 42 43 44 45 46 47 48 49 50 51 def set_selected_model ( model : str ) -> None : \"\"\" Sets the selected model for the LLM provider. Args: model (str): The name of the model to set as the selected model. \"\"\" try : _SELECTED_MODEL_FILE . write_text ( model ) logger . info ( f \"Selected model changed to: { model } \" ) except Exception as e : logger . error ( f \"Failed to set selected model: { e } \" ) switch_model ( model ) Switches to a new model if it is available. Parameters: Name Type Description Default model str The name of the model to switch to. required Returns: Name Type Description bool bool True if the model switch was successful, False otherwise. Source code in core/llm/llm_provider.py 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 def switch_model ( model : str ) -> bool : \"\"\" Switches to a new model if it is available. Args: model (str): The name of the model to switch to. Returns: bool: True if the model switch was successful, False otherwise. \"\"\" available_models = get_available_models () if model in available_models : set_selected_model ( model ) logger . info ( f \"Successfully switched to model: { model } \" ) return True else : logger . error ( f \"Model { model } not available. Available models: { available_models } \" ) return False \ud83d\udee1\ufe0f Input Guard Middleware \u2014 Validate Incoming Data Performs safety, format, and completeness checks on all incoming user inputs. Prevents malformed or unsafe data from entering the regulatory pipeline. RegulatoryInputGuardMiddleware Bases: AgentMiddleware Middleware to filter and block messages containing banned keywords before they are processed by the agent. Attributes: Name Type Description banned_keywords list [ str ] A list of keywords that are not allowed in user messages. Source code in core/middleware/input_guard_middleware.py 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 class RegulatoryInputGuardMiddleware ( AgentMiddleware ): \"\"\" Middleware to filter and block messages containing banned keywords before they are processed by the agent. Attributes: banned_keywords (list[str]): A list of keywords that are not allowed in user messages. \"\"\" def __init__ ( self , banned_keywords = None ): \"\"\" Initializes the middleware with a list of banned keywords. Args: banned_keywords (list[str], optional): A list of keywords to block. Defaults to a predefined list. \"\"\" super () . __init__ () self . banned_keywords = [ kw . lower () for kw in ( banned_keywords or [ \"politics\" , \"party\" , \"hate\" , \"religion\" , \"violence\" , \"personal\" ])] @hook_config ( can_jump_to = [ \"end\" ]) def before_agent ( self , state , runtime : Runtime ): \"\"\" Checks the user message for banned keywords and blocks the message if any are found. Args: state (dict): The current state of the agent, including user messages. runtime (Runtime): The runtime environment for the agent. Returns: dict or None: A response dict to block the message or None to allow processing to continue. \"\"\" if not state . get ( \"messages\" ): return None user_msg = state [ \"messages\" ][ 0 ] # normalize role role = getattr ( user_msg , \"type\" , None ) or getattr ( user_msg , \"role\" , None ) if role not in ( \"human\" , \"user\" ): return None # normalize content content = getattr ( user_msg , \"content\" , \"\" ) or user_msg . get ( \"content\" , \"\" ) content = content . lower () for keyword in self . banned_keywords : if keyword in content : return { \"messages\" : [{ \"role\" : \"assistant\" , \"content\" : ( \"This content appears to be outside the scope of regulatory analysis. \" \"Please focus on compliance, policy, or technical regulatory topics.\" ) }], \"jump_to\" : \"end\" } return None __init__ ( banned_keywords = None ) Initializes the middleware with a list of banned keywords. Parameters: Name Type Description Default banned_keywords list [ str ] A list of keywords to block. Defaults to a predefined list. None Source code in core/middleware/input_guard_middleware.py 13 14 15 16 17 18 19 20 21 22 23 def __init__ ( self , banned_keywords = None ): \"\"\" Initializes the middleware with a list of banned keywords. Args: banned_keywords (list[str], optional): A list of keywords to block. Defaults to a predefined list. \"\"\" super () . __init__ () self . banned_keywords = [ kw . lower () for kw in ( banned_keywords or [ \"politics\" , \"party\" , \"hate\" , \"religion\" , \"violence\" , \"personal\" ])] before_agent ( state , runtime ) Checks the user message for banned keywords and blocks the message if any are found. Parameters: Name Type Description Default state dict The current state of the agent, including user messages. required runtime Runtime The runtime environment for the agent. required Returns: Type Description dict or None: A response dict to block the message or None to allow processing to continue. Source code in core/middleware/input_guard_middleware.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 @hook_config ( can_jump_to = [ \"end\" ]) def before_agent ( self , state , runtime : Runtime ): \"\"\" Checks the user message for banned keywords and blocks the message if any are found. Args: state (dict): The current state of the agent, including user messages. runtime (Runtime): The runtime environment for the agent. Returns: dict or None: A response dict to block the message or None to allow processing to continue. \"\"\" if not state . get ( \"messages\" ): return None user_msg = state [ \"messages\" ][ 0 ] # normalize role role = getattr ( user_msg , \"type\" , None ) or getattr ( user_msg , \"role\" , None ) if role not in ( \"human\" , \"user\" ): return None # normalize content content = getattr ( user_msg , \"content\" , \"\" ) or user_msg . get ( \"content\" , \"\" ) content = content . lower () for keyword in self . banned_keywords : if keyword in content : return { \"messages\" : [{ \"role\" : \"assistant\" , \"content\" : ( \"This content appears to be outside the scope of regulatory analysis. \" \"Please focus on compliance, policy, or technical regulatory topics.\" ) }], \"jump_to\" : \"end\" } return None \ud83d\udd12 PII Middleware \u2014 Protect Sensitive Information Automatically detects and filters personally identifiable information. Ensures privacy compliance and prevents unintentional data exposure. get_pii_middleware () Returns a standard set of PII (Personally Identifiable Information) middleware layers. The middleware layers are configured to handle specific types of PII, such as email addresses and credit card numbers, by applying strategies like redaction or masking to the input data. Returns: Type Description list[PIIMiddleware]: A list of PII middleware layers with predefined strategies. Source code in core/middleware/pii_middleware.py 3 4 5 6 7 8 9 10 11 12 13 14 15 16 def get_pii_middleware (): \"\"\" Returns a standard set of PII (Personally Identifiable Information) middleware layers. The middleware layers are configured to handle specific types of PII, such as email addresses and credit card numbers, by applying strategies like redaction or masking to the input data. Returns: list[PIIMiddleware]: A list of PII middleware layers with predefined strategies. \"\"\" return [ PIIMiddleware ( \"email\" , strategy = \"redact\" , apply_to_input = True ), PIIMiddleware ( \"credit_card\" , strategy = \"mask\" , apply_to_input = True ), ] \ud83d\uddc3\ufe0f Middleware Registry \u2014 Centralized Pipeline Control Registers and manages middleware components for request preprocessing and validation. Provides structured execution flow across all middleware layers. get_regulatory_middlewares () Returns the full middleware stack for regulatory compliance. The middleware stack includes: - RegulatoryInputGuardMiddleware : Filters and blocks inappropriate or non-compliant input. - PII middleware layers: Handles Personally Identifiable Information (PII) by applying strategies like redaction or masking to sensitive data. Returns: Name Type Description list A list of middleware instances for regulatory compliance. Source code in core/middleware/registry.py 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 def get_regulatory_middlewares (): \"\"\" Returns the full middleware stack for regulatory compliance. The middleware stack includes: - `RegulatoryInputGuardMiddleware`: Filters and blocks inappropriate or non-compliant input. - PII middleware layers: Handles Personally Identifiable Information (PII) by applying strategies like redaction or masking to sensitive data. Returns: list: A list of middleware instances for regulatory compliance. \"\"\" return [ RegulatoryInputGuardMiddleware (), * get_pii_middleware (), ] \ud83d\uddfa\ufe0f GSPR Mapper \u2014 Map Device Features to GSPR Clauses Links device components, risks, and performance attributes directly to relevant GSPR sections. Acts as the logical bridge between design inputs and regulatory requirements. GSPRSection Source code in core/gspr/gspr_mapper.py 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 class GSPRSection : def __init__ ( self , section_id : str , data : dict , parent_id : Optional [ str ] = None ): self . section_id = section_id self . full_id = f \" { parent_id } . { section_id } \" if parent_id else section_id self . chapter_id = data . get ( \"chapter_id\" ) self . chapter_title = data . get ( \"chapter_tittle\" ) self . title = data . get ( \"title\" ) self . description = data . get ( \"description\" ) self . requirement_type = data . get ( \"requirement_type\" , None ) self . subsections = { key : GSPRSection ( key , value , self . full_id ) for key , value in data . get ( \"subsections\" , {}) . items ()} def get_titles_with_requirements ( self ) -> list [ Tuple [ str , str , str ]]: \"\"\" Recursively fetch (section_id, title, requirement_type) for all sections that have requirement_type. \"\"\" results = [] if self . requirement_type : # only include sections with requirement_type results . append (( self . full_id , self . title , self . requirement_type , self . description )) for sub in self . subsections . values (): results . extend ( sub . get_titles_with_requirements ()) return results def __repr__ ( self ): return f \"<GSPRSection { self . full_id } : { self . title } >\" get_titles_with_requirements () Recursively fetch (section_id, title, requirement_type) for all sections that have requirement_type. Source code in core/gspr/gspr_mapper.py 56 57 58 59 60 61 62 63 64 65 66 67 68 def get_titles_with_requirements ( self ) -> list [ Tuple [ str , str , str ]]: \"\"\" Recursively fetch (section_id, title, requirement_type) for all sections that have requirement_type. \"\"\" results = [] if self . requirement_type : # only include sections with requirement_type results . append (( self . full_id , self . title , self . requirement_type , self . description )) for sub in self . subsections . values (): results . extend ( sub . get_titles_with_requirements ()) return results build_gspr_map ( base_dir = None ) cached Build and cache a GSPR map from .py files in the structure_gspr directory. Parameters: Name Type Description Default base_dir Path | None Directory containing the GSPR .py files. Defaults to /gspr/structure_gspr. None Returns: OrderedDict: Mapping of file stem (without .py) -> file contents. Source code in core/gspr/gspr_mapper.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 @lru_cache ( maxsize = 5 ) def build_gspr_map ( base_dir : Path | None = None ) -> OrderedDict : \"\"\" Build and cache a GSPR map from .py files in the structure_gspr directory. Args: base_dir (Path | None): Directory containing the GSPR .py files. Defaults to <current_file>/gspr/structure_gspr. Returns: OrderedDict: Mapping of file stem (without .py) -> file contents. \"\"\" if base_dir is None : base_dir = Path ( __file__ ) . parent / \"gspr\" / \"structure_gspr\" gspr_map = OrderedDict () for file in sorted ( base_dir . glob ( \"*.py\" ), key = lambda f : natural_key ( f . name )): if file . name != \"__init__.py\" : gspr_map [ file . stem ] = file . read_text ( encoding = \"utf-8\" ) . strip () return gspr_map natural_key ( string ) Sort helper: ensures natural sorting (e.g. 2 < 10). Source code in core/gspr/gspr_mapper.py 16 17 18 19 20 def natural_key ( string : str ): \"\"\"Sort helper: ensures natural sorting (e.g. 2 < 10).\"\"\" import re return [ int ( s ) if s . isdigit () else s for s in re . split ( r \"(\\d+)\" , string )] \ud83d\udcbe Save JSON Mapping \u2014 Export Regulatory Mappings Saves generated GSPR and requirement mappings into structured JSON files. Supports traceability, audits, and integration with external tools.","title":"Other Modules"},{"location":"ai_backend/others/#other-core-modules-references","text":"","title":"\ud83d\uddc2\ufe0f Other Core Modules \u2014 References"},{"location":"ai_backend/others/#llm-provider-unified-model-interface","text":"Manages access to the underlying LLMs used across all regulatory workflows. Ensures consistent configuration, temperature control, and model routing.","title":"\ud83e\udd16 LLM Provider \u2014 Unified Model Interface"},{"location":"ai_backend/others/#core.llm.llm_provider.get_available_models","text":"Retrieves a list of all available models supported by the LLM provider. Returns: Type Description list [ str ] list[str]: A list of available model names. Source code in core/llm/llm_provider.py 53 54 55 56 57 58 59 60 def get_available_models () -> list [ str ]: \"\"\" Retrieves a list of all available models supported by the LLM provider. Returns: list[str]: A list of available model names. \"\"\" return [ \"gpt-4o\" , \"gemini-2.5-flash\" , \"mistral-large-latest\" , \"deepseek-chat\" , \"grok-4-1-fast-non-reasoning-latest\" , \"claude-sonnet-4-5-20250929\" ]","title":"get_available_models"},{"location":"ai_backend/others/#core.llm.llm_provider.get_chatfda_llm","text":"Returns a ChatOpenAI instance configured for ChatFDA. Source code in core/llm/llm_provider.py 227 228 229 230 231 232 233 234 235 def get_chatfda_llm (): \"\"\"Returns a ChatOpenAI instance configured for ChatFDA.\"\"\" logger . info ( \"Using ChatFDA via Langchain ChatOpenAI\" ) api_key = os . getenv ( \"CHATFDA_API_KEY\" ) return ChatOpenAI ( model = \"chatfda-diamond\" , base_url = \"https://api.chatmdr.eu/v1/\" , api_key = SecretStr ( api_key ) if api_key is not None else None , )","title":"get_chatfda_llm"},{"location":"ai_backend/others/#core.llm.llm_provider.get_chatmdr_llm","text":"Returns a ChatOpenAI instance configured for ChatMDR. Source code in core/llm/llm_provider.py 216 217 218 219 220 221 222 223 224 def get_chatmdr_llm (): \"\"\"Returns a ChatOpenAI instance configured for ChatMDR.\"\"\" logger . info ( \"Using ChatMDR via Langchain ChatOpenAI\" ) api_key = os . getenv ( \"CHATMDR_API_KEY\" ) return ChatOpenAI ( model = \"chatmdr-smart\" , base_url = \"https://api.chatmdr.eu/v1/\" , api_key = SecretStr ( api_key ) if api_key is not None else None , )","title":"get_chatmdr_llm"},{"location":"ai_backend/others/#core.llm.llm_provider.get_claude_llm","text":"Returns a ChatAnthropic instance configured for Claude. Source code in core/llm/llm_provider.py 155 156 157 158 159 160 161 162 163 164 165 166 167 168 def get_claude_llm ( model : str = \"claude-sonnet-4-5-20250929\" , temperature : float = 0.2 ): \"\"\"Returns a ChatAnthropic instance configured for Claude.\"\"\" logger . info ( f \"Using Claude LLM with model { model } \" ) try : from langchain_anthropic import ChatAnthropic api_key = os . getenv ( \"ANTHROPIC_API_KEY\" ) return ChatAnthropic ( model = model , temperature = temperature , api_key = api_key , # Don't wrap in SecretStr for Anthropic ) except ImportError : logger . error ( \"langchain_anthropic not installed. Install with: pip install langchain-anthropic\" ) raise ImportError ( \"langchain_anthropic package required for Claude support\" )","title":"get_claude_llm"},{"location":"ai_backend/others/#core.llm.llm_provider.get_deepseek_llm","text":"Returns a ChatOpenAI instance configured for DeepSeek API. Source code in core/llm/llm_provider.py 131 132 133 134 135 136 137 138 139 140 def get_deepseek_llm ( model : str = \"deepseek-chat\" , temperature : float = 0.2 ): \"\"\"Returns a ChatOpenAI instance configured for DeepSeek API.\"\"\" logger . info ( f \"Using DeepSeek LLM with model { model } \" ) api_key = os . getenv ( \"DEEPSEEK_API_KEY\" ) return ChatOpenAI ( model = model , temperature = temperature , base_url = \"https://api.deepseek.com/v1/\" , api_key = SecretStr ( api_key ) if api_key is not None else None , )","title":"get_deepseek_llm"},{"location":"ai_backend/others/#core.llm.llm_provider.get_gemini_llm","text":"Returns a ChatGoogleGenerativeAI instance configured for the Gemini Pro model. Parameters: Name Type Description Default model str The name of the Gemini model to use. Defaults to \"gemini-2.5-flash\". 'gemini-2.5-flash' temperature float The temperature setting for the model. Defaults to 0.3. 0.3 Returns: Name Type Description ChatGoogleGenerativeAI An instance of the Gemini LLM. Source code in core/llm/llm_provider.py 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 def get_gemini_llm ( model : str = \"gemini-2.5-flash\" , temperature : float = 0.3 ): \"\"\" Returns a ChatGoogleGenerativeAI instance configured for the Gemini Pro model. Args: model (str): The name of the Gemini model to use. Defaults to \"gemini-2.5-flash\". temperature (float): The temperature setting for the model. Defaults to 0.3. Returns: ChatGoogleGenerativeAI: An instance of the Gemini LLM. \"\"\" logger . info ( f \"Using Gemini LLM with model { model } \" ) api_key = os . getenv ( \"GEMINI_API_KEY\" ) return ChatGoogleGenerativeAI ( model = model , temperature = temperature , google_api_key = api_key , )","title":"get_gemini_llm"},{"location":"ai_backend/others/#core.llm.llm_provider.get_gpt_llm","text":"Returns a ChatOpenAI instance configured for GPT models. Source code in core/llm/llm_provider.py 207 208 209 210 211 212 213 def get_gpt_llm ( model : str = \"gpt-4o\" , temperature : float = 0.2 ): \"\"\"Returns a ChatOpenAI instance configured for GPT models.\"\"\" logger . info ( f \"Using OpenAI ChatGPT with model { model } \" ) return ChatOpenAI ( model = model , temperature = temperature , )","title":"get_gpt_llm"},{"location":"ai_backend/others/#core.llm.llm_provider.get_grok_llm","text":"Returns a ChatOpenAI instance configured for Grok API. Source code in core/llm/llm_provider.py 143 144 145 146 147 148 149 150 151 152 def get_grok_llm ( model : str = \"grok-4-1-fast-non-reasoning-latest\" , temperature : float = 0.2 ): \"\"\"Returns a ChatOpenAI instance configured for Grok API.\"\"\" logger . info ( f \"Using Grok LLM with model { model } \" ) api_key = os . getenv ( \"GROK_API_KEY\" ) return ChatOpenAI ( model = model , temperature = temperature , base_url = \"https://api.x.ai/v1/\" , api_key = SecretStr ( api_key ) if api_key is not None else None , )","title":"get_grok_llm"},{"location":"ai_backend/others/#core.llm.llm_provider.get_groq_llm","text":"Returns a ChatGroq instance configured for the DeepSeek model. Source code in core/llm/llm_provider.py 123 124 125 126 127 128 def get_groq_llm (): \"\"\"Returns a ChatGroq instance configured for the DeepSeek model.\"\"\" return ChatGroq ( model = \"deepseek-r1-distill-llama-70b\" , temperature = 0.5 , # Optional: control randomness )","title":"get_groq_llm"},{"location":"ai_backend/others/#core.llm.llm_provider.get_mistral_llm","text":"Returns a ChatMistralAI instance configured for the Mistral Large model. Parameters: Name Type Description Default model str The name of the Mistral model to use. Defaults to \"mistral-large-latest\". 'mistral-large-latest' temperature float The temperature setting for the model. Defaults to 0.3. 0.3 Returns: Name Type Description ChatMistralAI An instance of the Mistral LLM. Source code in core/llm/llm_provider.py 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 def get_mistral_llm ( model : str = \"mistral-large-latest\" , temperature : float = 0.3 ): \"\"\" Returns a ChatMistralAI instance configured for the Mistral Large model. Args: model (str): The name of the Mistral model to use. Defaults to \"mistral-large-latest\". temperature (float): The temperature setting for the model. Defaults to 0.3. Returns: ChatMistralAI: An instance of the Mistral LLM. \"\"\" logger . info ( f \"Using Mistral LLM with model { model } \" ) api_key = os . getenv ( \"MISTRAL_API_KEY\" ) return ChatMistralAI ( model = model , temperature = temperature , api_key = SecretStr ( api_key ) if api_key else None , )","title":"get_mistral_llm"},{"location":"ai_backend/others/#core.llm.llm_provider.get_selected_model","text":"Retrieves the currently selected model for the LLM provider. Returns: Name Type Description str str The name of the currently selected model. Defaults to _DEFAULT_MODEL if no model is set. Source code in core/llm/llm_provider.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 def get_selected_model () -> str : \"\"\" Retrieves the currently selected model for the LLM provider. Returns: str: The name of the currently selected model. Defaults to `_DEFAULT_MODEL` if no model is set. \"\"\" try : if _SELECTED_MODEL_FILE . exists (): return _SELECTED_MODEL_FILE . read_text () . strip () return _DEFAULT_MODEL except Exception as e : logger . warning ( f \"Failed to read selected model: { e } , using default\" ) return _DEFAULT_MODEL","title":"get_selected_model"},{"location":"ai_backend/others/#core.llm.llm_provider.get_vllm_llm","text":"Returns an LLM instance based on the selected model choice. Source code in core/llm/llm_provider.py 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 def get_vllm_llm ( model : str = None , temperature : float = 0.2 ): \"\"\"Returns an LLM instance based on the selected model choice.\"\"\" # Use selected model if no specific model is provided if model is None : model = get_selected_model () available_models = get_available_models () if model not in available_models : logger . warning ( f \"Model { model } not available, using default { _DEFAULT_MODEL } \" ) model = _DEFAULT_MODEL logger . info ( f \"Using model { model } \" ) # Return appropriate LLM instance based on model log_file = \"selected_model.log\" with open ( log_file , \"a\" ) as f : # \"a\" = append, creates file if not present f . write ( f \"Selected model before assignment: { model } \\n \" ) if model == \"gpt-4o\" : return get_gpt_llm ( \"gpt-4o\" , temperature ) elif model == \"gemini-2.5-flash\" : return get_gemini_llm ( \"gemini-2.5-flash\" , temperature ) elif model == \"mistral-large-latest\" : return get_mistral_llm ( \"mistral-large-latest\" , temperature ) elif model == \"deepseek-chat\" : return get_deepseek_llm ( \"deepseek-chat\" , temperature ) elif model == \"grok-4-1-fast-non-reasoning-latest\" : return get_grok_llm ( \"grok-4-1-fast-non-reasoning-latest\" , temperature ) elif model == \"claude-sonnet-4-5-20250929\" : return get_claude_llm ( \"claude-sonnet-4-5-20250929\" , temperature ) else : # Fallback to OpenAI GPT-4o return get_gpt_llm ( \"gpt-4o\" , temperature )","title":"get_vllm_llm"},{"location":"ai_backend/others/#core.llm.llm_provider.set_selected_model","text":"Sets the selected model for the LLM provider. Parameters: Name Type Description Default model str The name of the model to set as the selected model. required Source code in core/llm/llm_provider.py 40 41 42 43 44 45 46 47 48 49 50 51 def set_selected_model ( model : str ) -> None : \"\"\" Sets the selected model for the LLM provider. Args: model (str): The name of the model to set as the selected model. \"\"\" try : _SELECTED_MODEL_FILE . write_text ( model ) logger . info ( f \"Selected model changed to: { model } \" ) except Exception as e : logger . error ( f \"Failed to set selected model: { e } \" )","title":"set_selected_model"},{"location":"ai_backend/others/#core.llm.llm_provider.switch_model","text":"Switches to a new model if it is available. Parameters: Name Type Description Default model str The name of the model to switch to. required Returns: Name Type Description bool bool True if the model switch was successful, False otherwise. Source code in core/llm/llm_provider.py 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 def switch_model ( model : str ) -> bool : \"\"\" Switches to a new model if it is available. Args: model (str): The name of the model to switch to. Returns: bool: True if the model switch was successful, False otherwise. \"\"\" available_models = get_available_models () if model in available_models : set_selected_model ( model ) logger . info ( f \"Successfully switched to model: { model } \" ) return True else : logger . error ( f \"Model { model } not available. Available models: { available_models } \" ) return False","title":"switch_model"},{"location":"ai_backend/others/#input-guard-middleware-validate-incoming-data","text":"Performs safety, format, and completeness checks on all incoming user inputs. Prevents malformed or unsafe data from entering the regulatory pipeline.","title":"\ud83d\udee1\ufe0f Input Guard Middleware \u2014 Validate Incoming Data"},{"location":"ai_backend/others/#core.middleware.input_guard_middleware.RegulatoryInputGuardMiddleware","text":"Bases: AgentMiddleware Middleware to filter and block messages containing banned keywords before they are processed by the agent. Attributes: Name Type Description banned_keywords list [ str ] A list of keywords that are not allowed in user messages. Source code in core/middleware/input_guard_middleware.py 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 class RegulatoryInputGuardMiddleware ( AgentMiddleware ): \"\"\" Middleware to filter and block messages containing banned keywords before they are processed by the agent. Attributes: banned_keywords (list[str]): A list of keywords that are not allowed in user messages. \"\"\" def __init__ ( self , banned_keywords = None ): \"\"\" Initializes the middleware with a list of banned keywords. Args: banned_keywords (list[str], optional): A list of keywords to block. Defaults to a predefined list. \"\"\" super () . __init__ () self . banned_keywords = [ kw . lower () for kw in ( banned_keywords or [ \"politics\" , \"party\" , \"hate\" , \"religion\" , \"violence\" , \"personal\" ])] @hook_config ( can_jump_to = [ \"end\" ]) def before_agent ( self , state , runtime : Runtime ): \"\"\" Checks the user message for banned keywords and blocks the message if any are found. Args: state (dict): The current state of the agent, including user messages. runtime (Runtime): The runtime environment for the agent. Returns: dict or None: A response dict to block the message or None to allow processing to continue. \"\"\" if not state . get ( \"messages\" ): return None user_msg = state [ \"messages\" ][ 0 ] # normalize role role = getattr ( user_msg , \"type\" , None ) or getattr ( user_msg , \"role\" , None ) if role not in ( \"human\" , \"user\" ): return None # normalize content content = getattr ( user_msg , \"content\" , \"\" ) or user_msg . get ( \"content\" , \"\" ) content = content . lower () for keyword in self . banned_keywords : if keyword in content : return { \"messages\" : [{ \"role\" : \"assistant\" , \"content\" : ( \"This content appears to be outside the scope of regulatory analysis. \" \"Please focus on compliance, policy, or technical regulatory topics.\" ) }], \"jump_to\" : \"end\" } return None","title":"RegulatoryInputGuardMiddleware"},{"location":"ai_backend/others/#core.middleware.input_guard_middleware.RegulatoryInputGuardMiddleware.__init__","text":"Initializes the middleware with a list of banned keywords. Parameters: Name Type Description Default banned_keywords list [ str ] A list of keywords to block. Defaults to a predefined list. None Source code in core/middleware/input_guard_middleware.py 13 14 15 16 17 18 19 20 21 22 23 def __init__ ( self , banned_keywords = None ): \"\"\" Initializes the middleware with a list of banned keywords. Args: banned_keywords (list[str], optional): A list of keywords to block. Defaults to a predefined list. \"\"\" super () . __init__ () self . banned_keywords = [ kw . lower () for kw in ( banned_keywords or [ \"politics\" , \"party\" , \"hate\" , \"religion\" , \"violence\" , \"personal\" ])]","title":"__init__"},{"location":"ai_backend/others/#core.middleware.input_guard_middleware.RegulatoryInputGuardMiddleware.before_agent","text":"Checks the user message for banned keywords and blocks the message if any are found. Parameters: Name Type Description Default state dict The current state of the agent, including user messages. required runtime Runtime The runtime environment for the agent. required Returns: Type Description dict or None: A response dict to block the message or None to allow processing to continue. Source code in core/middleware/input_guard_middleware.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 @hook_config ( can_jump_to = [ \"end\" ]) def before_agent ( self , state , runtime : Runtime ): \"\"\" Checks the user message for banned keywords and blocks the message if any are found. Args: state (dict): The current state of the agent, including user messages. runtime (Runtime): The runtime environment for the agent. Returns: dict or None: A response dict to block the message or None to allow processing to continue. \"\"\" if not state . get ( \"messages\" ): return None user_msg = state [ \"messages\" ][ 0 ] # normalize role role = getattr ( user_msg , \"type\" , None ) or getattr ( user_msg , \"role\" , None ) if role not in ( \"human\" , \"user\" ): return None # normalize content content = getattr ( user_msg , \"content\" , \"\" ) or user_msg . get ( \"content\" , \"\" ) content = content . lower () for keyword in self . banned_keywords : if keyword in content : return { \"messages\" : [{ \"role\" : \"assistant\" , \"content\" : ( \"This content appears to be outside the scope of regulatory analysis. \" \"Please focus on compliance, policy, or technical regulatory topics.\" ) }], \"jump_to\" : \"end\" } return None","title":"before_agent"},{"location":"ai_backend/others/#pii-middleware-protect-sensitive-information","text":"Automatically detects and filters personally identifiable information. Ensures privacy compliance and prevents unintentional data exposure.","title":"\ud83d\udd12 PII Middleware \u2014 Protect Sensitive Information"},{"location":"ai_backend/others/#core.middleware.pii_middleware.get_pii_middleware","text":"Returns a standard set of PII (Personally Identifiable Information) middleware layers. The middleware layers are configured to handle specific types of PII, such as email addresses and credit card numbers, by applying strategies like redaction or masking to the input data. Returns: Type Description list[PIIMiddleware]: A list of PII middleware layers with predefined strategies. Source code in core/middleware/pii_middleware.py 3 4 5 6 7 8 9 10 11 12 13 14 15 16 def get_pii_middleware (): \"\"\" Returns a standard set of PII (Personally Identifiable Information) middleware layers. The middleware layers are configured to handle specific types of PII, such as email addresses and credit card numbers, by applying strategies like redaction or masking to the input data. Returns: list[PIIMiddleware]: A list of PII middleware layers with predefined strategies. \"\"\" return [ PIIMiddleware ( \"email\" , strategy = \"redact\" , apply_to_input = True ), PIIMiddleware ( \"credit_card\" , strategy = \"mask\" , apply_to_input = True ), ]","title":"get_pii_middleware"},{"location":"ai_backend/others/#middleware-registry-centralized-pipeline-control","text":"Registers and manages middleware components for request preprocessing and validation. Provides structured execution flow across all middleware layers.","title":"\ud83d\uddc3\ufe0f Middleware Registry \u2014 Centralized Pipeline Control"},{"location":"ai_backend/others/#core.middleware.registry.get_regulatory_middlewares","text":"Returns the full middleware stack for regulatory compliance. The middleware stack includes: - RegulatoryInputGuardMiddleware : Filters and blocks inappropriate or non-compliant input. - PII middleware layers: Handles Personally Identifiable Information (PII) by applying strategies like redaction or masking to sensitive data. Returns: Name Type Description list A list of middleware instances for regulatory compliance. Source code in core/middleware/registry.py 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 def get_regulatory_middlewares (): \"\"\" Returns the full middleware stack for regulatory compliance. The middleware stack includes: - `RegulatoryInputGuardMiddleware`: Filters and blocks inappropriate or non-compliant input. - PII middleware layers: Handles Personally Identifiable Information (PII) by applying strategies like redaction or masking to sensitive data. Returns: list: A list of middleware instances for regulatory compliance. \"\"\" return [ RegulatoryInputGuardMiddleware (), * get_pii_middleware (), ]","title":"get_regulatory_middlewares"},{"location":"ai_backend/others/#gspr-mapper-map-device-features-to-gspr-clauses","text":"Links device components, risks, and performance attributes directly to relevant GSPR sections. Acts as the logical bridge between design inputs and regulatory requirements.","title":"\ud83d\uddfa\ufe0f GSPR Mapper \u2014 Map Device Features to GSPR Clauses"},{"location":"ai_backend/others/#core.gspr.gspr_mapper.GSPRSection","text":"Source code in core/gspr/gspr_mapper.py 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 class GSPRSection : def __init__ ( self , section_id : str , data : dict , parent_id : Optional [ str ] = None ): self . section_id = section_id self . full_id = f \" { parent_id } . { section_id } \" if parent_id else section_id self . chapter_id = data . get ( \"chapter_id\" ) self . chapter_title = data . get ( \"chapter_tittle\" ) self . title = data . get ( \"title\" ) self . description = data . get ( \"description\" ) self . requirement_type = data . get ( \"requirement_type\" , None ) self . subsections = { key : GSPRSection ( key , value , self . full_id ) for key , value in data . get ( \"subsections\" , {}) . items ()} def get_titles_with_requirements ( self ) -> list [ Tuple [ str , str , str ]]: \"\"\" Recursively fetch (section_id, title, requirement_type) for all sections that have requirement_type. \"\"\" results = [] if self . requirement_type : # only include sections with requirement_type results . append (( self . full_id , self . title , self . requirement_type , self . description )) for sub in self . subsections . values (): results . extend ( sub . get_titles_with_requirements ()) return results def __repr__ ( self ): return f \"<GSPRSection { self . full_id } : { self . title } >\"","title":"GSPRSection"},{"location":"ai_backend/others/#core.gspr.gspr_mapper.GSPRSection.get_titles_with_requirements","text":"Recursively fetch (section_id, title, requirement_type) for all sections that have requirement_type. Source code in core/gspr/gspr_mapper.py 56 57 58 59 60 61 62 63 64 65 66 67 68 def get_titles_with_requirements ( self ) -> list [ Tuple [ str , str , str ]]: \"\"\" Recursively fetch (section_id, title, requirement_type) for all sections that have requirement_type. \"\"\" results = [] if self . requirement_type : # only include sections with requirement_type results . append (( self . full_id , self . title , self . requirement_type , self . description )) for sub in self . subsections . values (): results . extend ( sub . get_titles_with_requirements ()) return results","title":"get_titles_with_requirements"},{"location":"ai_backend/others/#core.gspr.gspr_mapper.build_gspr_map","text":"Build and cache a GSPR map from .py files in the structure_gspr directory. Parameters: Name Type Description Default base_dir Path | None Directory containing the GSPR .py files. Defaults to /gspr/structure_gspr. None Returns: OrderedDict: Mapping of file stem (without .py) -> file contents. Source code in core/gspr/gspr_mapper.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 @lru_cache ( maxsize = 5 ) def build_gspr_map ( base_dir : Path | None = None ) -> OrderedDict : \"\"\" Build and cache a GSPR map from .py files in the structure_gspr directory. Args: base_dir (Path | None): Directory containing the GSPR .py files. Defaults to <current_file>/gspr/structure_gspr. Returns: OrderedDict: Mapping of file stem (without .py) -> file contents. \"\"\" if base_dir is None : base_dir = Path ( __file__ ) . parent / \"gspr\" / \"structure_gspr\" gspr_map = OrderedDict () for file in sorted ( base_dir . glob ( \"*.py\" ), key = lambda f : natural_key ( f . name )): if file . name != \"__init__.py\" : gspr_map [ file . stem ] = file . read_text ( encoding = \"utf-8\" ) . strip () return gspr_map","title":"build_gspr_map"},{"location":"ai_backend/others/#core.gspr.gspr_mapper.natural_key","text":"Sort helper: ensures natural sorting (e.g. 2 < 10). Source code in core/gspr/gspr_mapper.py 16 17 18 19 20 def natural_key ( string : str ): \"\"\"Sort helper: ensures natural sorting (e.g. 2 < 10).\"\"\" import re return [ int ( s ) if s . isdigit () else s for s in re . split ( r \"(\\d+)\" , string )]","title":"natural_key"},{"location":"ai_backend/others/#save-json-mapping-export-regulatory-mappings","text":"Saves generated GSPR and requirement mappings into structured JSON files. Supports traceability, audits, and integration with external tools.","title":"\ud83d\udcbe Save JSON Mapping \u2014 Export Regulatory Mappings"},{"location":"ai_backend/output_models/","text":"\ud83d\uddc2\ufe0f Core Output Models \u2014 AI Structured Output References \ud83e\udde9 API Models Reference for API-related data structures and serialization. Centralized Pydantic Models for Regulatory Compliance Workflow API This file contains all Pydantic models used across the application for consistency. APIConfig Bases: BaseModel API configuration model Source code in core/models/api_models.py 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 class APIConfig ( BaseModel ): \"\"\"API configuration model\"\"\" title : str = Field ( default = \"Regulatory Compliance Workflow API\" , description = \"API title\" , ) version : str = Field ( default = \"1.0.0\" , description = \"API version\" , ) description : str = Field ( default = \"FastAPI for medical device regulatory compliance workflow\" , description = \"API description\" , ) host : str = Field ( default = \"0.0.0.0\" , description = \"Host address\" , ) port : int = Field ( default = 8585 , description = \"Port number\" , ) debug : bool = Field ( default = False , description = \"Debug mode\" , ) ApplicableGSPRModel Bases: BaseModel GSPR applicability state model Source code in core/models/api_models.py 52 53 54 55 56 57 58 59 60 61 62 class ApplicableGSPRModel ( BaseModel ): \"\"\"GSPR applicability state model\"\"\" applicable_gspr : Dict [ str , List [ str ]] = Field ( default_factory = dict , description = \"Applicable GSPRs per component\" , ) justifications : Dict [ str , Dict [ str , List [ str ]]] = Field ( default_factory = dict , description = \"Justifications for GSPR applicability\" , ) BaseResponse Bases: BaseModel Base response model with common fields Source code in core/models/api_models.py 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 class BaseResponse ( BaseModel ): \"\"\"Base response model with common fields\"\"\" session_id : str = Field ( ... , description = \"Session identifier\" , json_schema_extra = { \"example\" : \"uuid session-id\" }, ) timestamp : datetime = Field ( default_factory = lambda : datetime . now ( timezone . utc ), description = \"Response timestamp\" , ) status : str = Field ( default = \"success\" , description = \"Response status\" , ) ComponentRecommenderResponse Bases: BaseResponse Response model for component recommender Source code in core/models/api_models.py 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 class ComponentRecommenderResponse ( BaseResponse ): \"\"\"Response model for component recommender\"\"\" recommended_components : List [ str ] = Field ( ... , description = \"AI recommended components\" , ) given_components : List [ str ] = Field ( ... , description = \"User provided components\" , ) all_components : List [ str ] = Field ( ... , description = \"Combined list of all components\" , ) ComponentRecommenderUpdateRequest Bases: BaseModel Request model for updating component recommendations Source code in core/models/api_models.py 144 145 146 147 148 149 150 151 152 153 154 155 156 class ComponentRecommenderUpdateRequest ( BaseModel ): \"\"\"Request model for updating component recommendations\"\"\" additional_components : List [ str ] = Field ( default_factory = list , description = \"Components to add\" , json_schema_extra = { \"example\" : [ \"Polyethylene Insert\" ]}, ) remove_components : List [ str ] = Field ( default_factory = list , description = \"Components to remove\" , json_schema_extra = { \"example\" : [ \"Obsolete Component\" ]}, ) ComponentStatus Bases: BaseModel Individual component processing status Source code in core/models/api_models.py 437 438 439 440 441 442 443 444 class ComponentStatus ( BaseModel ): \"\"\"Individual component processing status\"\"\" component_name : str = Field ( ... , description = \"Component name\" ) gspr_filtered : bool = Field ( default = False , description = \"GSPR filtering completed\" ) gspr_generated : bool = Field ( default = False , description = \"GSPR generation completed\" ) applicable_gsprs : List [ str ] = Field ( default_factory = list , description = \"Applicable GSPR numbers\" ) generated_gsprs : List [ str ] = Field ( default_factory = list , description = \"Generated GSPR numbers\" ) ErrorResponse Bases: BaseModel Error response model Source code in core/models/api_models.py 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 class ErrorResponse ( BaseModel ): \"\"\"Error response model\"\"\" error : str = Field ( ... , description = \"Error type\" , ) message : str = Field ( ... , description = \"Error message\" , ) details : Optional [ Dict [ str , Any ]] = Field ( default = None , description = \"Additional error details\" , ) timestamp : datetime = Field ( default_factory = datetime . utcnow , description = \"Error timestamp\" , ) GSPRFilterRequest Bases: BaseModel Request model for GSPR filtering Source code in core/models/api_models.py 179 180 181 182 183 184 185 186 187 188 class GSPRFilterRequest ( BaseModel ): \"\"\"Request model for GSPR filtering\"\"\" component_name : str = Field ( ... , description = \"Component name to filter GSPRs for\" , json_schema_extra = { \"example\" : \"Femoral Component\" , }, ) GSPRFilterResponse Bases: BaseResponse Response model for GSPR filtering Source code in core/models/api_models.py 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 class GSPRFilterResponse ( BaseResponse ): \"\"\"Response model for GSPR filtering\"\"\" component_name : str = Field ( ... , description = \"Component name\" , ) applicable_gsprs : List [ str ] = Field ( ... , description = \"List of applicable GSPR numbers\" , ) justifications : Dict [ str , List [ str ]] = Field ( ... , description = \"Justifications for each GSPR\" , ) GSPRGeneratedItemModel Bases: BaseModel Individual GSPR generated item Source code in core/models/api_models.py 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 class GSPRGeneratedItemModel ( BaseModel ): \"\"\"Individual GSPR generated item\"\"\" component : str = Field ( ... , description = \"Component name\" , ) gspr : str = Field ( ... , description = \"GSPR number\" , ) design_input : str = Field ( ... , description = \"Design input requirements\" , ) applicability : str = Field ( ... , description = \"Applicability assessment\" , ) justification : str = Field ( ... , description = \"Justification for applicability\" , ) requirements : str = Field ( ... , description = \"Specific requirements\" , ) standards : List [ str ] = Field ( default_factory = list , description = \"Applicable standards\" , ) GSPRGeneratorRequest Bases: BaseModel Request model for GSPR generation Source code in core/models/api_models.py 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 class GSPRGeneratorRequest ( BaseModel ): \"\"\"Request model for GSPR generation\"\"\" component_name : str = Field ( ... , description = \"Component name to generate GSPR for\" , json_schema_extra = { \"example\" : \"Femoral Component\" , }, ) gspr_number : str = Field ( ... , description = \"Specific GSPR number to generate details for\" , json_schema_extra = { \"example\" : \"10.1\" , }, ) GSPRGeneratorResponse Bases: BaseResponse Response model for GSPR generation Source code in core/models/api_models.py 310 311 312 313 314 315 316 class GSPRGeneratorResponse ( BaseResponse ): \"\"\"Response model for GSPR generation\"\"\" gspr_item : GSPRGeneratedItemModel = Field ( ... , description = \"Generated GSPR item\" , ) GlobalStateModel Bases: BaseModel Complete global state model Source code in core/models/api_models.py 98 99 100 101 102 103 104 105 106 107 class GlobalStateModel ( BaseModel ): \"\"\"Complete global state model\"\"\" user_input : UserInputModel recommender : RecommenderModel applicable_gspr : ApplicableGSPRModel gspr_generated : Dict [ str , GSPRGeneratedItemModel ] = Field ( default_factory = dict , description = \"Generated GSPR items per component\" , ) HealthResponse Bases: BaseModel Health check response model Source code in core/models/api_models.py 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 class HealthResponse ( BaseModel ): \"\"\"Health check response model\"\"\" status : str = Field ( ... , description = \"Health status\" , ) timestamp : datetime = Field ( default_factory = lambda : datetime . now ( timezone . utc ), description = \"Health check timestamp\" , ) active_sessions : int = Field ( ... , description = \"Number of active sessions\" , ) version : str = Field ( ... , description = \"API version\" , ) IntendedUserResponse Bases: BaseResponse Response model for intended user Source code in core/models/api_models.py 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 class IntendedUserResponse ( BaseResponse ): \"\"\"Response model for intended user\"\"\" intended_users : List [ str ] = Field ( ... , description = \"Intended users\" , ) device_type : str = Field ( ... , description = \"Device type\" , ) risk_classification : Dict [ str , str ] = Field ( ... , description = \"Risk classification\" , ) IntendedUserUpdateRequest Bases: BaseModel Request model for updating intended users Source code in core/models/api_models.py 169 170 171 172 173 174 175 176 class IntendedUserUpdateRequest ( BaseModel ): \"\"\"Request model for updating intended users\"\"\" intended_users : List [ str ] = Field ( ... , description = \"Updated intended users\" , json_schema_extra = { \"example\" : [ \"Orthopedic Surgeons\" , \"Trauma Surgeons\" ]}, ) RecommenderModel Bases: BaseModel Component recommender state model Source code in core/models/api_models.py 39 40 41 42 43 44 45 46 47 48 49 class RecommenderModel ( BaseModel ): \"\"\"Component recommender state model\"\"\" recommended_components : List [ str ] = Field ( default_factory = list , description = \"AI recommended components\" , ) given_components : List [ str ] = Field ( default_factory = list , description = \"User provided components\" , ) RegulatoryWorkflowStatus Bases: BaseModel Overall workflow status model Source code in core/models/api_models.py 424 425 426 427 428 429 430 431 432 433 434 class RegulatoryWorkflowStatus ( BaseModel ): \"\"\"Overall workflow status model\"\"\" session_id : str = Field ( ... , description = \"Session identifier\" ) user_input_complete : bool = Field ( default = False , description = \"User input completion status\" ) components_recommended : bool = Field ( default = False , description = \"Component recommendation status\" ) risk_classified : bool = Field ( default = False , description = \"Risk classification status\" ) intended_users_identified : bool = Field ( default = False , description = \"Intended users identification status\" ) gspr_filtered : Dict [ str , bool ] = Field ( default_factory = dict , description = \"GSPR filtering status per component\" ) gspr_generated : Dict [ str , bool ] = Field ( default_factory = dict , description = \"GSPR generation status per component\" ) completion_percentage : float = Field ( default = 0.0 , description = \"Overall completion percentage\" ) RiskClassificationResponse Bases: BaseResponse Response model for risk classification Source code in core/models/api_models.py 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 class RiskClassificationResponse ( BaseResponse ): \"\"\"Response model for risk classification\"\"\" risk_classification : Dict [ str , str ] = Field ( ... , description = \"Risk classification mapping\" , ) device_type : str = Field ( ... , description = \"Device type\" , ) intended_purpose : str = Field ( ... , description = \"Intended purpose\" , ) RiskClassificationUpdateRequest Bases: BaseModel Request model for updating risk classification Source code in core/models/api_models.py 159 160 161 162 163 164 165 166 class RiskClassificationUpdateRequest ( BaseModel ): \"\"\"Request model for updating risk classification\"\"\" risk_classification : Dict [ str , str ] = Field ( ... , description = \"Updated risk classification\" , json_schema_extra = { \"example\" : { \"femoral\" : \"Class III\" , \"tibial\" : \"Class III\" }}, ) SessionDeleteResponse Bases: BaseModel Session deletion response model Source code in core/models/api_models.py 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 class SessionDeleteResponse ( BaseModel ): \"\"\"Session deletion response model\"\"\" message : str = Field ( ... , description = \"Deletion confirmation message\" , ) session_id : str = Field ( ... , description = \"Deleted session ID\" , ) timestamp : datetime = Field ( default_factory = lambda : datetime . now ( timezone . utc ), description = \"Deletion timestamp\" , ) SessionInfo Bases: BaseModel Session information model Source code in core/models/api_models.py 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 class SessionInfo ( BaseModel ): \"\"\"Session information model\"\"\" session_id : str = Field ( ... , description = \"Session identifier\" , ) created_at : datetime = Field ( default_factory = datetime . utcnow , description = \"Session creation time\" , ) last_accessed : datetime = Field ( default_factory = datetime . utcnow , description = \"Last access time\" , ) state : GlobalStateModel = Field ( ... , description = \"Current session state\" , ) SessionListResponse Bases: BaseModel Session list response model Source code in core/models/api_models.py 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 class SessionListResponse ( BaseModel ): \"\"\"Session list response model\"\"\" active_sessions : List [ str ] = Field ( ... , description = \"List of active session IDs\" , ) total_sessions : int = Field ( ... , description = \"Total number of sessions\" , ) timestamp : datetime = Field ( default_factory = lambda : datetime . now ( timezone . utc ), description = \"Response timestamp\" , ) UserInputModel Bases: BaseModel Core user input data model Source code in core/models/api_models.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 class UserInputModel ( BaseModel ): \"\"\"Core user input data model\"\"\" device_type : str = Field ( ... , description = \"Type of medical device\" , ) intended_purpose : str = Field ( ... , description = \"Intended purpose of the device\" , ) components : List [ str ] = Field ( default_factory = list , description = \"Device components\" , ) intended_users : List [ str ] = Field ( default_factory = list , description = \"Intended users\" , ) risk_classification : Dict [ str , str ] = Field ( default_factory = dict , description = \"Risk classification mapping\" , ) UserInputRequest Bases: BaseModel Request model for user input creation Source code in core/models/api_models.py 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 class UserInputRequest ( BaseModel ): \"\"\"Request model for user input creation\"\"\" device_type : str = Field ( ... , description = \"Type of medical device\" , json_schema_extra = { \"example\" : \"Knee Implant\" }, ) intended_purpose : str = Field ( ... , description = \"Intended purpose of the device\" , json_schema_extra = { \"example\" : \"Total knee replacement for arthritis patients\" }, ) components : List [ str ] = Field ( default_factory = list , description = \"Device components\" , json_schema_extra = { \"example\" : [ \"Femoral Component\" , \"Tibial Component\" ]}, ) intended_users : List [ str ] = Field ( default_factory = list , description = \"Intended users\" , json_schema_extra = { \"example\" : [ \"Orthopedic Surgeons\" , \"Medical Residents\" ]}, ) risk_classification : Dict [ str , str ] = Field ( default_factory = dict , description = \"Risk classification mapping\" , json_schema_extra = { \"example\" : { \"overall\" : \"Class III\" }}, ) UserInputResponse Bases: BaseResponse Response model for user input creation Source code in core/models/api_models.py 232 233 234 235 236 237 238 239 class UserInputResponse ( BaseResponse ): \"\"\"Response model for user input creation\"\"\" user_input : UserInputModel message : str = Field ( ... , description = \"Response message\" , ) WorkflowSummary Bases: BaseModel Complete workflow summary model Source code in core/models/api_models.py 447 448 449 450 451 452 453 454 class WorkflowSummary ( BaseModel ): \"\"\"Complete workflow summary model\"\"\" session_id : str = Field ( ... , description = \"Session identifier\" ) device_info : UserInputModel = Field ( ... , description = \"Device information\" ) component_summary : List [ ComponentStatus ] = Field ( ... , description = \"Component processing summary\" ) overall_status : RegulatoryWorkflowStatus = Field ( ... , description = \"Overall workflow status\" ) generated_at : datetime = Field ( default_factory = datetime . utcnow , description = \"Summary generation time\" ) \ud83d\udcda Context Summary Model Handles summarization of context for GSPR and design inputs. ContextSummaryModel Bases: BaseModel Represents the LLM-enriched understanding of the device context. This does not introduce new domain fields \u2014 it only summarizes and interprets existing ones for downstream GSPR reasoning. Source code in core/models/gspr/context_summary_model.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 class ContextSummaryModel ( BaseModel ): \"\"\" Represents the LLM-enriched understanding of the device context. This does not introduce new domain fields \u2014 it only summarizes and interprets existing ones for downstream GSPR reasoning. \"\"\" project_name : Optional [ str ] = Field ( ... , description = \"Name of the medical device project.\" ) medical_device : Optional [ str ] = Field ( ... , description = \"Type or name of the medical device.\" ) intended_purpose : Optional [ str ] = Field ( ... , description = \"Intended purpose as defined by the manufacturer.\" ) device_type : Optional [ list [ str ]] = Field ( ... , description = \"Type(s) of medical device (e.g., implantable, software-based).\" ) material_type : Optional [ list [ str ]] = Field ( ... , description = \"Material types involved in the device design.\" ) components : Optional [ list [ str ]] = Field ( ... , description = \"System-generated list of device components.\" ) risk_classification : Optional [ dict [ str , dict [ str , str ]]] = Field ( ... , description = \"Regulatory risk classification across jurisdictions.\" ) intended_users : Optional [ list [ str ]] = Field ( ... , description = \"Identified or intended users of the device.\" ) # Interpretation / Enrichment Fields context_summary : Optional [ str ] = Field ( ... , description = \"Concise narrative summary of what the device is, how it works, and its main regulatory and design context \u2014 derived only from given data.\" ) reasoning_focus : Optional [ str ] = Field ( ... , description = \"LLM's interpretation of which aspects (components, risk rules, materials) should be prioritized for GSPR reasoning.\" ) \ud83e\udde0 Grouping Model Organizes requirements and design elements into structured groups. GroupItem Bases: BaseModel A single regulatory classification group with its associated section titles. Source code in core/models/gspr/grouping_model.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 class GroupItem ( BaseModel ): \"\"\" A single regulatory classification group with its associated section titles. \"\"\" name : Literal [ \"Performance and Safety\" , \"Device Compatibility and Interoperability\" , \"Environmental and External Influences\" , \"Chemical and Material Safety\" , \"Radiation Safety\" , \"Software and IT Security\" , \"Maintenance and Operational Safety\" , \"Labeling and Information Requirements\" , \"Risk Management and Evaluation\" , \"User Considerations and Ergonomics\" , \"Device Specifics and Customization\" , \"Miscellaneous\" , ] = Field ( ... , description = \"Name of one of the predefined regulatory groups.\" ) sections : list [ str ] = Field ( ... , description = \"list of section titles classified under this group.\" ) GroupingModel Bases: BaseModel Structured LLM output schema for section grouping. Source code in core/models/gspr/grouping_model.py 40 41 42 43 44 45 46 47 48 class GroupingModel ( BaseModel ): \"\"\" Structured LLM output schema for section grouping. \"\"\" groups : list [ GroupItem ] = Field ( ... , description = \"list of fixed regulatory groups with their classified section titles.\" , ) \ud83c\udf21\ufe0f Temperature Model Manages temperature-related parameters in device specifications. TemperatureModel Bases: BaseModel Structured model for LLM to return an appropriate temperature value. Source code in core/models/gspr/temperature_model.py 7 8 9 10 11 12 13 14 15 16 17 18 class TemperatureModel ( BaseModel ): \"\"\" Structured model for LLM to return an appropriate temperature value. \"\"\" temperature : float = Field ( ... , description = ( \"Chosen temperature value between 0.1 and 0.9 representing how creative or deterministic the reasoning should be.\" ), ge = 0.1 , le = 0.9 , examples = [ 0.3 , 0.5 , 0.8 ], ) \ud83c\udfd7\ufe0f Component Recommender Model Suggests device components and subsystems based on specifications. ComponentRecommenderModel Bases: BaseModel Model representing recommended components for regulatory compliance. This model contains a list of components that are recommended based on the device type, intended purpose, and regulatory requirements. Each component is carefully selected to ensure compliance with relevant safety and performance standards. Attributes: Name Type Description components_list List [ str ] A list of recommended component names for the medical device. Source code in core/models/component_recommender_model.py 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 class ComponentRecommenderModel ( BaseModel ): \"\"\" Model representing recommended components for regulatory compliance. This model contains a list of components that are recommended based on the device type, intended purpose, and regulatory requirements. Each component is carefully selected to ensure compliance with relevant safety and performance standards. Attributes: components_list (List[str]): A list of recommended component names for the medical device. \"\"\" components_list : List [ str ] = Field ( description = ( \"\"\"List of recommended components for regulatory compliance, safety, and performance.\"\"\" \"\"\"Each component is selected based on device type and use-case to ensure all relevant standards are met.\"\"\" ) ) \ud83d\udcdd Design Input Model Generates detailed, regulatory-aligned design inputs. DesignInputModel Bases: BaseModel Model representing design input requirements for a specific component and GSPR clause. Attributes: Name Type Description component str The name of the component being analyzed. requirement str The specific requirement name associated with the GSPR clause. gspr_text str The text description from the GSPR clause. standards List [ StandardItem ] A list of applicable standards with their justifications. Source code in core/models/design_input_model.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 class DesignInputModel ( BaseModel ): \"\"\" Model representing design input requirements for a specific component and GSPR clause. Attributes: component (str): The name of the component being analyzed. requirement (str): The specific requirement name associated with the GSPR clause. gspr_text (str): The text description from the GSPR clause. standards (List[StandardItem]): A list of applicable standards with their justifications. \"\"\" component : str = Field ( ... , description = \"Component name.\" ) requirement : str = Field ( ... , description = \"Specific requirement name associated with the GSPR clause.\" ) gspr_text : str = Field ( ... , description = \"Text description from the GSPR clause.\" ) standards : List [ StandardItem ] = Field ( ... , description = \"List of standards with justifications.\" ) StandardItem Bases: BaseModel Model representing a regulatory standard with its justification. Attributes: Name Type Description name str The name of the standard (e.g., ISO 14971). justification str A formalized justification explaining why this standard is applicable. Source code in core/models/design_input_model.py 6 7 8 9 10 11 12 13 14 15 class StandardItem ( BaseModel ): \"\"\" Model representing a regulatory standard with its justification. Attributes: name (str): The name of the standard (e.g., ISO 14971). justification (str): A formalized justification explaining why this standard is applicable. \"\"\" name : str = Field ( ... , description = \"Standard name (e.g., ISO 14971)\" ) justification : str = Field ( ... , description = \"Formalized justification for the standard\" ) \ud83d\udd04 GSPR Filter Model Filters and prioritizes GSPR clauses relevant to device features. GSPRFilterRequest Bases: BaseModel Model representing a request to filter GSPR applicability for a specific component. Attributes: Name Type Description component_name str The name of the component for which GSPR filtering is requested. Source code in core/models/gspr_filter_model.py 4 5 6 7 8 9 10 11 class GSPRFilterRequest ( BaseModel ): \"\"\" Model representing a request to filter GSPR applicability for a specific component. Attributes: component_name (str): The name of the component for which GSPR filtering is requested. \"\"\" component_name : str = Field ( ... , description = \"Name of the component for which the GSPR filter is being applied.\" ) GSPRFilterResponse Bases: BaseModel Model representing the response from GSPR filtering for a specific component. Attributes: Name Type Description component_name str The name of the component that was evaluated. is_applicable bool Whether the specified GSPR is applicable to the component. justification str Detailed reasoning explaining why the GSPR is applicable or not. Source code in core/models/gspr_filter_model.py 14 15 16 17 18 19 20 21 22 23 24 25 class GSPRFilterResponse ( BaseModel ): \"\"\" Model representing the response from GSPR filtering for a specific component. Attributes: component_name (str): The name of the component that was evaluated. is_applicable (bool): Whether the specified GSPR is applicable to the component. justification (str): Detailed reasoning explaining why the GSPR is applicable or not. \"\"\" component_name : str = Field ( ... , description = \"Name of the component that was evaluated.\" ) is_applicable : bool = Field ( ... , description = \"Indicates whether the specified GSPR is applicable to the component.\" ) justification : str = Field ( ... , description = \"Detailed reasoning behind why the GSPR is applicable or not.\" ) \ud83d\uddc2\ufe0f GSPR Generator Model Creates initial GSPR tables linking device features to regulatory clauses. GSPRGeneratorModel Bases: BaseModel Model representing the generated GSPR requirements and standards for a specific component. This model captures the output of the GSPR generation process, including the detailed requirements and applicable standards for a given component and GSPR section. Attributes: Name Type Description component str The name of the specific device component the GSPR applies to. gspr int The GSPR section number (1\u201323) that this input corresponds to. requirement str Detailed requirement derived from the GSPR applicable to the component. standard str Applicable harmonized or recognized standard that supports compliance. Source code in core/models/gspr_generator_model.py 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 class GSPRGeneratorModel ( BaseModel ): \"\"\" Model representing the generated GSPR requirements and standards for a specific component. This model captures the output of the GSPR generation process, including the detailed requirements and applicable standards for a given component and GSPR section. Attributes: component (str): The name of the specific device component the GSPR applies to. gspr (int): The GSPR section number (1\u201323) that this input corresponds to. requirement (str): Detailed requirement derived from the GSPR applicable to the component. standard (str): Applicable harmonized or recognized standard that supports compliance. \"\"\" component : str = Field ( ... , description = \"Name of the specific device component the GSPR applies to.\" ) gspr : int = Field ( ... , description = \"GSPR section number (1\u201323) that this input corresponds to.\" ) # design_input: str = Field(..., description=\"Specific design input or requirement related to this component and GSPR.\") # justification: str = Field(..., description=\"Rationale for applicability status, explaining why it's applicable or not.\") requirement : str = Field ( ... , description = \"Detailed requirement derived from the GSPR applicable to the component.\" ) standard : str = Field ( ... , description = \"Applicable harmonized or recognized standard that supports compliance.\" ) \ud83d\udce4 GSPR Output Model Structures and exports final GSPR tables for audit and submission. DesignOutputClause Bases: BaseModel Represents one actionable clause in the generated Design Output Report. This model captures a single design output clause that maps to specific regulatory standards and provides actionable statements for compliance activities or test requirements. Attributes: Name Type Description clause Optional [ str ] Clause or identifier number (e.g., 12.1, 14.3). category str Design input category (e.g., Biocompatibility, Electrical Safety). standard str Applicable ISO/IEC standard (e.g., ISO 10993-1, IEC 60601-1). statement str Generated design output statement describing compliance or test activity. Source code in core/models/gspr_output_model.py 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 class DesignOutputClause ( BaseModel ): \"\"\" Represents one actionable clause in the generated Design Output Report. This model captures a single design output clause that maps to specific regulatory standards and provides actionable statements for compliance activities or test requirements. Attributes: clause (Optional[str]): Clause or identifier number (e.g., 12.1, 14.3). category (str): Design input category (e.g., Biocompatibility, Electrical Safety). standard (str): Applicable ISO/IEC standard (e.g., ISO 10993-1, IEC 60601-1). statement (str): Generated design output statement describing compliance or test activity. \"\"\" clause : Optional [ str ] = Field ( None , description = \"Clause or identifier number (e.g., 12.1, 14.3).\" ) category : str = Field ( ... , description = \"Design input category (e.g., Biocompatibility, Electrical Safety).\" ) standard : str = Field ( ... , description = \"Applicable ISO/IEC standard (e.g., ISO 10993-1, IEC 60601-1).\" ) statement : str = Field ( ... , description = \"Generated design output statement describing compliance or test activity.\" ) DesignOutputModel Bases: BaseModel Model representing the structured Design Output Report generated for a medical device component. Source code in core/models/gspr_output_model.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 class DesignOutputModel ( BaseModel ): \"\"\" Model representing the structured Design Output Report generated for a medical device component. \"\"\" component : str = Field ( ... , description = \"Name of the component (e.g., Tibial Component, Control Unit, Software Module).\" ) device_type : Optional [ str ] = Field ( None , description = \"Type or category of the medical device.\" ) requirement : Optional [ str ] = Field ( None , description = \"Design requirement or constraint being addressed.\" ) gspr_text : Optional [ str ] = Field ( None , description = \"Referenced GSPR text or clause driving the output generation.\" ) design_outputs : List [ DesignOutputClause ] = Field ( default_factory = list , description = \"Structured list of generated design outputs mapped to ISO standards.\" ) standards_applied : Optional [ List [ str ]] = Field ( None , description = \"List of all standards referenced or applied across the generated outputs.\" ) rationale_summary : Optional [ str ] = Field ( None , description = \"High-level summary explaining design decisions and traceability to standards and GSPRs.\" ) metadata : Optional [ Any ] = Field ( None , description = \"Additional metadata or AI model generation details (e.g., timestamp, model version).\" ) \ud83d\udc64 Intended User Model Maps user context and use-environment into design inputs. IntendedUserModel Bases: BaseModel Model representing the intended users for a medical device. This model captures the device type and identifies the categories of users who are intended to operate, maintain, or interact with the medical device in various healthcare settings. Attributes: Name Type Description device_type str The type or category of the medical device. intended_users list [ str ] A list of intended user categories such as doctors, technicians, patients, or other healthcare professionals. Source code in core/models/intended_user_model.py 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 class IntendedUserModel ( BaseModel ): \"\"\" Model representing the intended users for a medical device. This model captures the device type and identifies the categories of users who are intended to operate, maintain, or interact with the medical device in various healthcare settings. Attributes: device_type (str): The type or category of the medical device. intended_users (list[str]): A list of intended user categories such as doctors, technicians, patients, or other healthcare professionals. \"\"\" device_type : str = Field ( ... , description = \"The type of the medical device.\" ) intended_users : list [ str ] = Field ( ... , description = \"List of intended users such as doctors, technicians, patients.\" ) \u2696\ufe0f Risk Classification Model Classifies device according to FDA and MDR risk frameworks. RiskClassificationModel Bases: BaseModel Model representing risk classification for medical devices across different regulatory regions. This model captures the risk classification of a medical device according to various regulatory frameworks (EU MDR, US FDA, Indian MDR), providing both the classification class and the justification for that classification. Attributes: Name Type Description risk_classification dict [ str , dict [ str , str ]] A dictionary mapping regulatory regions to their risk classifications, where each region contains 'class' and 'justification' keys. Source code in core/models/risk_classification_model.py 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 class RiskClassificationModel ( BaseModel ): \"\"\" Model representing risk classification for medical devices across different regulatory regions. This model captures the risk classification of a medical device according to various regulatory frameworks (EU MDR, US FDA, Indian MDR), providing both the classification class and the justification for that classification. Attributes: risk_classification (dict[str, dict[str, str]]): A dictionary mapping regulatory regions to their risk classifications, where each region contains 'class' and 'justification' keys. \"\"\" risk_classification : dict [ str , dict [ str , str ]] = Field ( description = ( \"Region-wise risk classification. \" \"Keys: 'EU MDR', 'US FDA', 'Indian MDR'. \" \"Values: dictionaries with keys 'class' (risk class name like 'Class IIb', 'Class II', 'Class C') \" \"and 'justification' (the explanation for classification).\" ), )","title":"Output Models"},{"location":"ai_backend/output_models/#core-output-models-ai-structured-output-references","text":"","title":"\ud83d\uddc2\ufe0f Core Output Models \u2014 AI Structured Output References"},{"location":"ai_backend/output_models/#api-models","text":"Reference for API-related data structures and serialization. Centralized Pydantic Models for Regulatory Compliance Workflow API This file contains all Pydantic models used across the application for consistency.","title":"\ud83e\udde9 API Models"},{"location":"ai_backend/output_models/#core.models.api_models.APIConfig","text":"Bases: BaseModel API configuration model Source code in core/models/api_models.py 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 class APIConfig ( BaseModel ): \"\"\"API configuration model\"\"\" title : str = Field ( default = \"Regulatory Compliance Workflow API\" , description = \"API title\" , ) version : str = Field ( default = \"1.0.0\" , description = \"API version\" , ) description : str = Field ( default = \"FastAPI for medical device regulatory compliance workflow\" , description = \"API description\" , ) host : str = Field ( default = \"0.0.0.0\" , description = \"Host address\" , ) port : int = Field ( default = 8585 , description = \"Port number\" , ) debug : bool = Field ( default = False , description = \"Debug mode\" , )","title":"APIConfig"},{"location":"ai_backend/output_models/#core.models.api_models.ApplicableGSPRModel","text":"Bases: BaseModel GSPR applicability state model Source code in core/models/api_models.py 52 53 54 55 56 57 58 59 60 61 62 class ApplicableGSPRModel ( BaseModel ): \"\"\"GSPR applicability state model\"\"\" applicable_gspr : Dict [ str , List [ str ]] = Field ( default_factory = dict , description = \"Applicable GSPRs per component\" , ) justifications : Dict [ str , Dict [ str , List [ str ]]] = Field ( default_factory = dict , description = \"Justifications for GSPR applicability\" , )","title":"ApplicableGSPRModel"},{"location":"ai_backend/output_models/#core.models.api_models.BaseResponse","text":"Bases: BaseModel Base response model with common fields Source code in core/models/api_models.py 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 class BaseResponse ( BaseModel ): \"\"\"Base response model with common fields\"\"\" session_id : str = Field ( ... , description = \"Session identifier\" , json_schema_extra = { \"example\" : \"uuid session-id\" }, ) timestamp : datetime = Field ( default_factory = lambda : datetime . now ( timezone . utc ), description = \"Response timestamp\" , ) status : str = Field ( default = \"success\" , description = \"Response status\" , )","title":"BaseResponse"},{"location":"ai_backend/output_models/#core.models.api_models.ComponentRecommenderResponse","text":"Bases: BaseResponse Response model for component recommender Source code in core/models/api_models.py 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 class ComponentRecommenderResponse ( BaseResponse ): \"\"\"Response model for component recommender\"\"\" recommended_components : List [ str ] = Field ( ... , description = \"AI recommended components\" , ) given_components : List [ str ] = Field ( ... , description = \"User provided components\" , ) all_components : List [ str ] = Field ( ... , description = \"Combined list of all components\" , )","title":"ComponentRecommenderResponse"},{"location":"ai_backend/output_models/#core.models.api_models.ComponentRecommenderUpdateRequest","text":"Bases: BaseModel Request model for updating component recommendations Source code in core/models/api_models.py 144 145 146 147 148 149 150 151 152 153 154 155 156 class ComponentRecommenderUpdateRequest ( BaseModel ): \"\"\"Request model for updating component recommendations\"\"\" additional_components : List [ str ] = Field ( default_factory = list , description = \"Components to add\" , json_schema_extra = { \"example\" : [ \"Polyethylene Insert\" ]}, ) remove_components : List [ str ] = Field ( default_factory = list , description = \"Components to remove\" , json_schema_extra = { \"example\" : [ \"Obsolete Component\" ]}, )","title":"ComponentRecommenderUpdateRequest"},{"location":"ai_backend/output_models/#core.models.api_models.ComponentStatus","text":"Bases: BaseModel Individual component processing status Source code in core/models/api_models.py 437 438 439 440 441 442 443 444 class ComponentStatus ( BaseModel ): \"\"\"Individual component processing status\"\"\" component_name : str = Field ( ... , description = \"Component name\" ) gspr_filtered : bool = Field ( default = False , description = \"GSPR filtering completed\" ) gspr_generated : bool = Field ( default = False , description = \"GSPR generation completed\" ) applicable_gsprs : List [ str ] = Field ( default_factory = list , description = \"Applicable GSPR numbers\" ) generated_gsprs : List [ str ] = Field ( default_factory = list , description = \"Generated GSPR numbers\" )","title":"ComponentStatus"},{"location":"ai_backend/output_models/#core.models.api_models.ErrorResponse","text":"Bases: BaseModel Error response model Source code in core/models/api_models.py 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 class ErrorResponse ( BaseModel ): \"\"\"Error response model\"\"\" error : str = Field ( ... , description = \"Error type\" , ) message : str = Field ( ... , description = \"Error message\" , ) details : Optional [ Dict [ str , Any ]] = Field ( default = None , description = \"Additional error details\" , ) timestamp : datetime = Field ( default_factory = datetime . utcnow , description = \"Error timestamp\" , )","title":"ErrorResponse"},{"location":"ai_backend/output_models/#core.models.api_models.GSPRFilterRequest","text":"Bases: BaseModel Request model for GSPR filtering Source code in core/models/api_models.py 179 180 181 182 183 184 185 186 187 188 class GSPRFilterRequest ( BaseModel ): \"\"\"Request model for GSPR filtering\"\"\" component_name : str = Field ( ... , description = \"Component name to filter GSPRs for\" , json_schema_extra = { \"example\" : \"Femoral Component\" , }, )","title":"GSPRFilterRequest"},{"location":"ai_backend/output_models/#core.models.api_models.GSPRFilterResponse","text":"Bases: BaseResponse Response model for GSPR filtering Source code in core/models/api_models.py 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 class GSPRFilterResponse ( BaseResponse ): \"\"\"Response model for GSPR filtering\"\"\" component_name : str = Field ( ... , description = \"Component name\" , ) applicable_gsprs : List [ str ] = Field ( ... , description = \"List of applicable GSPR numbers\" , ) justifications : Dict [ str , List [ str ]] = Field ( ... , description = \"Justifications for each GSPR\" , )","title":"GSPRFilterResponse"},{"location":"ai_backend/output_models/#core.models.api_models.GSPRGeneratedItemModel","text":"Bases: BaseModel Individual GSPR generated item Source code in core/models/api_models.py 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 class GSPRGeneratedItemModel ( BaseModel ): \"\"\"Individual GSPR generated item\"\"\" component : str = Field ( ... , description = \"Component name\" , ) gspr : str = Field ( ... , description = \"GSPR number\" , ) design_input : str = Field ( ... , description = \"Design input requirements\" , ) applicability : str = Field ( ... , description = \"Applicability assessment\" , ) justification : str = Field ( ... , description = \"Justification for applicability\" , ) requirements : str = Field ( ... , description = \"Specific requirements\" , ) standards : List [ str ] = Field ( default_factory = list , description = \"Applicable standards\" , )","title":"GSPRGeneratedItemModel"},{"location":"ai_backend/output_models/#core.models.api_models.GSPRGeneratorRequest","text":"Bases: BaseModel Request model for GSPR generation Source code in core/models/api_models.py 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 class GSPRGeneratorRequest ( BaseModel ): \"\"\"Request model for GSPR generation\"\"\" component_name : str = Field ( ... , description = \"Component name to generate GSPR for\" , json_schema_extra = { \"example\" : \"Femoral Component\" , }, ) gspr_number : str = Field ( ... , description = \"Specific GSPR number to generate details for\" , json_schema_extra = { \"example\" : \"10.1\" , }, )","title":"GSPRGeneratorRequest"},{"location":"ai_backend/output_models/#core.models.api_models.GSPRGeneratorResponse","text":"Bases: BaseResponse Response model for GSPR generation Source code in core/models/api_models.py 310 311 312 313 314 315 316 class GSPRGeneratorResponse ( BaseResponse ): \"\"\"Response model for GSPR generation\"\"\" gspr_item : GSPRGeneratedItemModel = Field ( ... , description = \"Generated GSPR item\" , )","title":"GSPRGeneratorResponse"},{"location":"ai_backend/output_models/#core.models.api_models.GlobalStateModel","text":"Bases: BaseModel Complete global state model Source code in core/models/api_models.py 98 99 100 101 102 103 104 105 106 107 class GlobalStateModel ( BaseModel ): \"\"\"Complete global state model\"\"\" user_input : UserInputModel recommender : RecommenderModel applicable_gspr : ApplicableGSPRModel gspr_generated : Dict [ str , GSPRGeneratedItemModel ] = Field ( default_factory = dict , description = \"Generated GSPR items per component\" , )","title":"GlobalStateModel"},{"location":"ai_backend/output_models/#core.models.api_models.HealthResponse","text":"Bases: BaseModel Health check response model Source code in core/models/api_models.py 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 class HealthResponse ( BaseModel ): \"\"\"Health check response model\"\"\" status : str = Field ( ... , description = \"Health status\" , ) timestamp : datetime = Field ( default_factory = lambda : datetime . now ( timezone . utc ), description = \"Health check timestamp\" , ) active_sessions : int = Field ( ... , description = \"Number of active sessions\" , ) version : str = Field ( ... , description = \"API version\" , )","title":"HealthResponse"},{"location":"ai_backend/output_models/#core.models.api_models.IntendedUserResponse","text":"Bases: BaseResponse Response model for intended user Source code in core/models/api_models.py 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 class IntendedUserResponse ( BaseResponse ): \"\"\"Response model for intended user\"\"\" intended_users : List [ str ] = Field ( ... , description = \"Intended users\" , ) device_type : str = Field ( ... , description = \"Device type\" , ) risk_classification : Dict [ str , str ] = Field ( ... , description = \"Risk classification\" , )","title":"IntendedUserResponse"},{"location":"ai_backend/output_models/#core.models.api_models.IntendedUserUpdateRequest","text":"Bases: BaseModel Request model for updating intended users Source code in core/models/api_models.py 169 170 171 172 173 174 175 176 class IntendedUserUpdateRequest ( BaseModel ): \"\"\"Request model for updating intended users\"\"\" intended_users : List [ str ] = Field ( ... , description = \"Updated intended users\" , json_schema_extra = { \"example\" : [ \"Orthopedic Surgeons\" , \"Trauma Surgeons\" ]}, )","title":"IntendedUserUpdateRequest"},{"location":"ai_backend/output_models/#core.models.api_models.RecommenderModel","text":"Bases: BaseModel Component recommender state model Source code in core/models/api_models.py 39 40 41 42 43 44 45 46 47 48 49 class RecommenderModel ( BaseModel ): \"\"\"Component recommender state model\"\"\" recommended_components : List [ str ] = Field ( default_factory = list , description = \"AI recommended components\" , ) given_components : List [ str ] = Field ( default_factory = list , description = \"User provided components\" , )","title":"RecommenderModel"},{"location":"ai_backend/output_models/#core.models.api_models.RegulatoryWorkflowStatus","text":"Bases: BaseModel Overall workflow status model Source code in core/models/api_models.py 424 425 426 427 428 429 430 431 432 433 434 class RegulatoryWorkflowStatus ( BaseModel ): \"\"\"Overall workflow status model\"\"\" session_id : str = Field ( ... , description = \"Session identifier\" ) user_input_complete : bool = Field ( default = False , description = \"User input completion status\" ) components_recommended : bool = Field ( default = False , description = \"Component recommendation status\" ) risk_classified : bool = Field ( default = False , description = \"Risk classification status\" ) intended_users_identified : bool = Field ( default = False , description = \"Intended users identification status\" ) gspr_filtered : Dict [ str , bool ] = Field ( default_factory = dict , description = \"GSPR filtering status per component\" ) gspr_generated : Dict [ str , bool ] = Field ( default_factory = dict , description = \"GSPR generation status per component\" ) completion_percentage : float = Field ( default = 0.0 , description = \"Overall completion percentage\" )","title":"RegulatoryWorkflowStatus"},{"location":"ai_backend/output_models/#core.models.api_models.RiskClassificationResponse","text":"Bases: BaseResponse Response model for risk classification Source code in core/models/api_models.py 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 class RiskClassificationResponse ( BaseResponse ): \"\"\"Response model for risk classification\"\"\" risk_classification : Dict [ str , str ] = Field ( ... , description = \"Risk classification mapping\" , ) device_type : str = Field ( ... , description = \"Device type\" , ) intended_purpose : str = Field ( ... , description = \"Intended purpose\" , )","title":"RiskClassificationResponse"},{"location":"ai_backend/output_models/#core.models.api_models.RiskClassificationUpdateRequest","text":"Bases: BaseModel Request model for updating risk classification Source code in core/models/api_models.py 159 160 161 162 163 164 165 166 class RiskClassificationUpdateRequest ( BaseModel ): \"\"\"Request model for updating risk classification\"\"\" risk_classification : Dict [ str , str ] = Field ( ... , description = \"Updated risk classification\" , json_schema_extra = { \"example\" : { \"femoral\" : \"Class III\" , \"tibial\" : \"Class III\" }}, )","title":"RiskClassificationUpdateRequest"},{"location":"ai_backend/output_models/#core.models.api_models.SessionDeleteResponse","text":"Bases: BaseModel Session deletion response model Source code in core/models/api_models.py 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 class SessionDeleteResponse ( BaseModel ): \"\"\"Session deletion response model\"\"\" message : str = Field ( ... , description = \"Deletion confirmation message\" , ) session_id : str = Field ( ... , description = \"Deleted session ID\" , ) timestamp : datetime = Field ( default_factory = lambda : datetime . now ( timezone . utc ), description = \"Deletion timestamp\" , )","title":"SessionDeleteResponse"},{"location":"ai_backend/output_models/#core.models.api_models.SessionInfo","text":"Bases: BaseModel Session information model Source code in core/models/api_models.py 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 class SessionInfo ( BaseModel ): \"\"\"Session information model\"\"\" session_id : str = Field ( ... , description = \"Session identifier\" , ) created_at : datetime = Field ( default_factory = datetime . utcnow , description = \"Session creation time\" , ) last_accessed : datetime = Field ( default_factory = datetime . utcnow , description = \"Last access time\" , ) state : GlobalStateModel = Field ( ... , description = \"Current session state\" , )","title":"SessionInfo"},{"location":"ai_backend/output_models/#core.models.api_models.SessionListResponse","text":"Bases: BaseModel Session list response model Source code in core/models/api_models.py 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 class SessionListResponse ( BaseModel ): \"\"\"Session list response model\"\"\" active_sessions : List [ str ] = Field ( ... , description = \"List of active session IDs\" , ) total_sessions : int = Field ( ... , description = \"Total number of sessions\" , ) timestamp : datetime = Field ( default_factory = lambda : datetime . now ( timezone . utc ), description = \"Response timestamp\" , )","title":"SessionListResponse"},{"location":"ai_backend/output_models/#core.models.api_models.UserInputModel","text":"Bases: BaseModel Core user input data model Source code in core/models/api_models.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 class UserInputModel ( BaseModel ): \"\"\"Core user input data model\"\"\" device_type : str = Field ( ... , description = \"Type of medical device\" , ) intended_purpose : str = Field ( ... , description = \"Intended purpose of the device\" , ) components : List [ str ] = Field ( default_factory = list , description = \"Device components\" , ) intended_users : List [ str ] = Field ( default_factory = list , description = \"Intended users\" , ) risk_classification : Dict [ str , str ] = Field ( default_factory = dict , description = \"Risk classification mapping\" , )","title":"UserInputModel"},{"location":"ai_backend/output_models/#core.models.api_models.UserInputRequest","text":"Bases: BaseModel Request model for user input creation Source code in core/models/api_models.py 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 class UserInputRequest ( BaseModel ): \"\"\"Request model for user input creation\"\"\" device_type : str = Field ( ... , description = \"Type of medical device\" , json_schema_extra = { \"example\" : \"Knee Implant\" }, ) intended_purpose : str = Field ( ... , description = \"Intended purpose of the device\" , json_schema_extra = { \"example\" : \"Total knee replacement for arthritis patients\" }, ) components : List [ str ] = Field ( default_factory = list , description = \"Device components\" , json_schema_extra = { \"example\" : [ \"Femoral Component\" , \"Tibial Component\" ]}, ) intended_users : List [ str ] = Field ( default_factory = list , description = \"Intended users\" , json_schema_extra = { \"example\" : [ \"Orthopedic Surgeons\" , \"Medical Residents\" ]}, ) risk_classification : Dict [ str , str ] = Field ( default_factory = dict , description = \"Risk classification mapping\" , json_schema_extra = { \"example\" : { \"overall\" : \"Class III\" }}, )","title":"UserInputRequest"},{"location":"ai_backend/output_models/#core.models.api_models.UserInputResponse","text":"Bases: BaseResponse Response model for user input creation Source code in core/models/api_models.py 232 233 234 235 236 237 238 239 class UserInputResponse ( BaseResponse ): \"\"\"Response model for user input creation\"\"\" user_input : UserInputModel message : str = Field ( ... , description = \"Response message\" , )","title":"UserInputResponse"},{"location":"ai_backend/output_models/#core.models.api_models.WorkflowSummary","text":"Bases: BaseModel Complete workflow summary model Source code in core/models/api_models.py 447 448 449 450 451 452 453 454 class WorkflowSummary ( BaseModel ): \"\"\"Complete workflow summary model\"\"\" session_id : str = Field ( ... , description = \"Session identifier\" ) device_info : UserInputModel = Field ( ... , description = \"Device information\" ) component_summary : List [ ComponentStatus ] = Field ( ... , description = \"Component processing summary\" ) overall_status : RegulatoryWorkflowStatus = Field ( ... , description = \"Overall workflow status\" ) generated_at : datetime = Field ( default_factory = datetime . utcnow , description = \"Summary generation time\" )","title":"WorkflowSummary"},{"location":"ai_backend/output_models/#context-summary-model","text":"Handles summarization of context for GSPR and design inputs.","title":"\ud83d\udcda Context Summary Model"},{"location":"ai_backend/output_models/#core.models.gspr.context_summary_model.ContextSummaryModel","text":"Bases: BaseModel Represents the LLM-enriched understanding of the device context. This does not introduce new domain fields \u2014 it only summarizes and interprets existing ones for downstream GSPR reasoning. Source code in core/models/gspr/context_summary_model.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 class ContextSummaryModel ( BaseModel ): \"\"\" Represents the LLM-enriched understanding of the device context. This does not introduce new domain fields \u2014 it only summarizes and interprets existing ones for downstream GSPR reasoning. \"\"\" project_name : Optional [ str ] = Field ( ... , description = \"Name of the medical device project.\" ) medical_device : Optional [ str ] = Field ( ... , description = \"Type or name of the medical device.\" ) intended_purpose : Optional [ str ] = Field ( ... , description = \"Intended purpose as defined by the manufacturer.\" ) device_type : Optional [ list [ str ]] = Field ( ... , description = \"Type(s) of medical device (e.g., implantable, software-based).\" ) material_type : Optional [ list [ str ]] = Field ( ... , description = \"Material types involved in the device design.\" ) components : Optional [ list [ str ]] = Field ( ... , description = \"System-generated list of device components.\" ) risk_classification : Optional [ dict [ str , dict [ str , str ]]] = Field ( ... , description = \"Regulatory risk classification across jurisdictions.\" ) intended_users : Optional [ list [ str ]] = Field ( ... , description = \"Identified or intended users of the device.\" ) # Interpretation / Enrichment Fields context_summary : Optional [ str ] = Field ( ... , description = \"Concise narrative summary of what the device is, how it works, and its main regulatory and design context \u2014 derived only from given data.\" ) reasoning_focus : Optional [ str ] = Field ( ... , description = \"LLM's interpretation of which aspects (components, risk rules, materials) should be prioritized for GSPR reasoning.\" )","title":"ContextSummaryModel"},{"location":"ai_backend/output_models/#grouping-model","text":"Organizes requirements and design elements into structured groups.","title":"\ud83e\udde0 Grouping Model"},{"location":"ai_backend/output_models/#core.models.gspr.grouping_model.GroupItem","text":"Bases: BaseModel A single regulatory classification group with its associated section titles. Source code in core/models/gspr/grouping_model.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 class GroupItem ( BaseModel ): \"\"\" A single regulatory classification group with its associated section titles. \"\"\" name : Literal [ \"Performance and Safety\" , \"Device Compatibility and Interoperability\" , \"Environmental and External Influences\" , \"Chemical and Material Safety\" , \"Radiation Safety\" , \"Software and IT Security\" , \"Maintenance and Operational Safety\" , \"Labeling and Information Requirements\" , \"Risk Management and Evaluation\" , \"User Considerations and Ergonomics\" , \"Device Specifics and Customization\" , \"Miscellaneous\" , ] = Field ( ... , description = \"Name of one of the predefined regulatory groups.\" ) sections : list [ str ] = Field ( ... , description = \"list of section titles classified under this group.\" )","title":"GroupItem"},{"location":"ai_backend/output_models/#core.models.gspr.grouping_model.GroupingModel","text":"Bases: BaseModel Structured LLM output schema for section grouping. Source code in core/models/gspr/grouping_model.py 40 41 42 43 44 45 46 47 48 class GroupingModel ( BaseModel ): \"\"\" Structured LLM output schema for section grouping. \"\"\" groups : list [ GroupItem ] = Field ( ... , description = \"list of fixed regulatory groups with their classified section titles.\" , )","title":"GroupingModel"},{"location":"ai_backend/output_models/#temperature-model","text":"Manages temperature-related parameters in device specifications.","title":"\ud83c\udf21\ufe0f Temperature Model"},{"location":"ai_backend/output_models/#core.models.gspr.temperature_model.TemperatureModel","text":"Bases: BaseModel Structured model for LLM to return an appropriate temperature value. Source code in core/models/gspr/temperature_model.py 7 8 9 10 11 12 13 14 15 16 17 18 class TemperatureModel ( BaseModel ): \"\"\" Structured model for LLM to return an appropriate temperature value. \"\"\" temperature : float = Field ( ... , description = ( \"Chosen temperature value between 0.1 and 0.9 representing how creative or deterministic the reasoning should be.\" ), ge = 0.1 , le = 0.9 , examples = [ 0.3 , 0.5 , 0.8 ], )","title":"TemperatureModel"},{"location":"ai_backend/output_models/#component-recommender-model","text":"Suggests device components and subsystems based on specifications.","title":"\ud83c\udfd7\ufe0f Component Recommender Model"},{"location":"ai_backend/output_models/#core.models.component_recommender_model.ComponentRecommenderModel","text":"Bases: BaseModel Model representing recommended components for regulatory compliance. This model contains a list of components that are recommended based on the device type, intended purpose, and regulatory requirements. Each component is carefully selected to ensure compliance with relevant safety and performance standards. Attributes: Name Type Description components_list List [ str ] A list of recommended component names for the medical device. Source code in core/models/component_recommender_model.py 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 class ComponentRecommenderModel ( BaseModel ): \"\"\" Model representing recommended components for regulatory compliance. This model contains a list of components that are recommended based on the device type, intended purpose, and regulatory requirements. Each component is carefully selected to ensure compliance with relevant safety and performance standards. Attributes: components_list (List[str]): A list of recommended component names for the medical device. \"\"\" components_list : List [ str ] = Field ( description = ( \"\"\"List of recommended components for regulatory compliance, safety, and performance.\"\"\" \"\"\"Each component is selected based on device type and use-case to ensure all relevant standards are met.\"\"\" ) )","title":"ComponentRecommenderModel"},{"location":"ai_backend/output_models/#design-input-model","text":"Generates detailed, regulatory-aligned design inputs.","title":"\ud83d\udcdd Design Input Model"},{"location":"ai_backend/output_models/#core.models.design_input_model.DesignInputModel","text":"Bases: BaseModel Model representing design input requirements for a specific component and GSPR clause. Attributes: Name Type Description component str The name of the component being analyzed. requirement str The specific requirement name associated with the GSPR clause. gspr_text str The text description from the GSPR clause. standards List [ StandardItem ] A list of applicable standards with their justifications. Source code in core/models/design_input_model.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 class DesignInputModel ( BaseModel ): \"\"\" Model representing design input requirements for a specific component and GSPR clause. Attributes: component (str): The name of the component being analyzed. requirement (str): The specific requirement name associated with the GSPR clause. gspr_text (str): The text description from the GSPR clause. standards (List[StandardItem]): A list of applicable standards with their justifications. \"\"\" component : str = Field ( ... , description = \"Component name.\" ) requirement : str = Field ( ... , description = \"Specific requirement name associated with the GSPR clause.\" ) gspr_text : str = Field ( ... , description = \"Text description from the GSPR clause.\" ) standards : List [ StandardItem ] = Field ( ... , description = \"List of standards with justifications.\" )","title":"DesignInputModel"},{"location":"ai_backend/output_models/#core.models.design_input_model.StandardItem","text":"Bases: BaseModel Model representing a regulatory standard with its justification. Attributes: Name Type Description name str The name of the standard (e.g., ISO 14971). justification str A formalized justification explaining why this standard is applicable. Source code in core/models/design_input_model.py 6 7 8 9 10 11 12 13 14 15 class StandardItem ( BaseModel ): \"\"\" Model representing a regulatory standard with its justification. Attributes: name (str): The name of the standard (e.g., ISO 14971). justification (str): A formalized justification explaining why this standard is applicable. \"\"\" name : str = Field ( ... , description = \"Standard name (e.g., ISO 14971)\" ) justification : str = Field ( ... , description = \"Formalized justification for the standard\" )","title":"StandardItem"},{"location":"ai_backend/output_models/#gspr-filter-model","text":"Filters and prioritizes GSPR clauses relevant to device features.","title":"\ud83d\udd04 GSPR Filter Model"},{"location":"ai_backend/output_models/#core.models.gspr_filter_model.GSPRFilterRequest","text":"Bases: BaseModel Model representing a request to filter GSPR applicability for a specific component. Attributes: Name Type Description component_name str The name of the component for which GSPR filtering is requested. Source code in core/models/gspr_filter_model.py 4 5 6 7 8 9 10 11 class GSPRFilterRequest ( BaseModel ): \"\"\" Model representing a request to filter GSPR applicability for a specific component. Attributes: component_name (str): The name of the component for which GSPR filtering is requested. \"\"\" component_name : str = Field ( ... , description = \"Name of the component for which the GSPR filter is being applied.\" )","title":"GSPRFilterRequest"},{"location":"ai_backend/output_models/#core.models.gspr_filter_model.GSPRFilterResponse","text":"Bases: BaseModel Model representing the response from GSPR filtering for a specific component. Attributes: Name Type Description component_name str The name of the component that was evaluated. is_applicable bool Whether the specified GSPR is applicable to the component. justification str Detailed reasoning explaining why the GSPR is applicable or not. Source code in core/models/gspr_filter_model.py 14 15 16 17 18 19 20 21 22 23 24 25 class GSPRFilterResponse ( BaseModel ): \"\"\" Model representing the response from GSPR filtering for a specific component. Attributes: component_name (str): The name of the component that was evaluated. is_applicable (bool): Whether the specified GSPR is applicable to the component. justification (str): Detailed reasoning explaining why the GSPR is applicable or not. \"\"\" component_name : str = Field ( ... , description = \"Name of the component that was evaluated.\" ) is_applicable : bool = Field ( ... , description = \"Indicates whether the specified GSPR is applicable to the component.\" ) justification : str = Field ( ... , description = \"Detailed reasoning behind why the GSPR is applicable or not.\" )","title":"GSPRFilterResponse"},{"location":"ai_backend/output_models/#gspr-generator-model","text":"Creates initial GSPR tables linking device features to regulatory clauses.","title":"\ud83d\uddc2\ufe0f GSPR Generator Model"},{"location":"ai_backend/output_models/#core.models.gspr_generator_model.GSPRGeneratorModel","text":"Bases: BaseModel Model representing the generated GSPR requirements and standards for a specific component. This model captures the output of the GSPR generation process, including the detailed requirements and applicable standards for a given component and GSPR section. Attributes: Name Type Description component str The name of the specific device component the GSPR applies to. gspr int The GSPR section number (1\u201323) that this input corresponds to. requirement str Detailed requirement derived from the GSPR applicable to the component. standard str Applicable harmonized or recognized standard that supports compliance. Source code in core/models/gspr_generator_model.py 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 class GSPRGeneratorModel ( BaseModel ): \"\"\" Model representing the generated GSPR requirements and standards for a specific component. This model captures the output of the GSPR generation process, including the detailed requirements and applicable standards for a given component and GSPR section. Attributes: component (str): The name of the specific device component the GSPR applies to. gspr (int): The GSPR section number (1\u201323) that this input corresponds to. requirement (str): Detailed requirement derived from the GSPR applicable to the component. standard (str): Applicable harmonized or recognized standard that supports compliance. \"\"\" component : str = Field ( ... , description = \"Name of the specific device component the GSPR applies to.\" ) gspr : int = Field ( ... , description = \"GSPR section number (1\u201323) that this input corresponds to.\" ) # design_input: str = Field(..., description=\"Specific design input or requirement related to this component and GSPR.\") # justification: str = Field(..., description=\"Rationale for applicability status, explaining why it's applicable or not.\") requirement : str = Field ( ... , description = \"Detailed requirement derived from the GSPR applicable to the component.\" ) standard : str = Field ( ... , description = \"Applicable harmonized or recognized standard that supports compliance.\" )","title":"GSPRGeneratorModel"},{"location":"ai_backend/output_models/#gspr-output-model","text":"Structures and exports final GSPR tables for audit and submission.","title":"\ud83d\udce4 GSPR Output Model"},{"location":"ai_backend/output_models/#core.models.gspr_output_model.DesignOutputClause","text":"Bases: BaseModel Represents one actionable clause in the generated Design Output Report. This model captures a single design output clause that maps to specific regulatory standards and provides actionable statements for compliance activities or test requirements. Attributes: Name Type Description clause Optional [ str ] Clause or identifier number (e.g., 12.1, 14.3). category str Design input category (e.g., Biocompatibility, Electrical Safety). standard str Applicable ISO/IEC standard (e.g., ISO 10993-1, IEC 60601-1). statement str Generated design output statement describing compliance or test activity. Source code in core/models/gspr_output_model.py 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 class DesignOutputClause ( BaseModel ): \"\"\" Represents one actionable clause in the generated Design Output Report. This model captures a single design output clause that maps to specific regulatory standards and provides actionable statements for compliance activities or test requirements. Attributes: clause (Optional[str]): Clause or identifier number (e.g., 12.1, 14.3). category (str): Design input category (e.g., Biocompatibility, Electrical Safety). standard (str): Applicable ISO/IEC standard (e.g., ISO 10993-1, IEC 60601-1). statement (str): Generated design output statement describing compliance or test activity. \"\"\" clause : Optional [ str ] = Field ( None , description = \"Clause or identifier number (e.g., 12.1, 14.3).\" ) category : str = Field ( ... , description = \"Design input category (e.g., Biocompatibility, Electrical Safety).\" ) standard : str = Field ( ... , description = \"Applicable ISO/IEC standard (e.g., ISO 10993-1, IEC 60601-1).\" ) statement : str = Field ( ... , description = \"Generated design output statement describing compliance or test activity.\" )","title":"DesignOutputClause"},{"location":"ai_backend/output_models/#core.models.gspr_output_model.DesignOutputModel","text":"Bases: BaseModel Model representing the structured Design Output Report generated for a medical device component. Source code in core/models/gspr_output_model.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 class DesignOutputModel ( BaseModel ): \"\"\" Model representing the structured Design Output Report generated for a medical device component. \"\"\" component : str = Field ( ... , description = \"Name of the component (e.g., Tibial Component, Control Unit, Software Module).\" ) device_type : Optional [ str ] = Field ( None , description = \"Type or category of the medical device.\" ) requirement : Optional [ str ] = Field ( None , description = \"Design requirement or constraint being addressed.\" ) gspr_text : Optional [ str ] = Field ( None , description = \"Referenced GSPR text or clause driving the output generation.\" ) design_outputs : List [ DesignOutputClause ] = Field ( default_factory = list , description = \"Structured list of generated design outputs mapped to ISO standards.\" ) standards_applied : Optional [ List [ str ]] = Field ( None , description = \"List of all standards referenced or applied across the generated outputs.\" ) rationale_summary : Optional [ str ] = Field ( None , description = \"High-level summary explaining design decisions and traceability to standards and GSPRs.\" ) metadata : Optional [ Any ] = Field ( None , description = \"Additional metadata or AI model generation details (e.g., timestamp, model version).\" )","title":"DesignOutputModel"},{"location":"ai_backend/output_models/#intended-user-model","text":"Maps user context and use-environment into design inputs.","title":"\ud83d\udc64 Intended User Model"},{"location":"ai_backend/output_models/#core.models.intended_user_model.IntendedUserModel","text":"Bases: BaseModel Model representing the intended users for a medical device. This model captures the device type and identifies the categories of users who are intended to operate, maintain, or interact with the medical device in various healthcare settings. Attributes: Name Type Description device_type str The type or category of the medical device. intended_users list [ str ] A list of intended user categories such as doctors, technicians, patients, or other healthcare professionals. Source code in core/models/intended_user_model.py 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 class IntendedUserModel ( BaseModel ): \"\"\" Model representing the intended users for a medical device. This model captures the device type and identifies the categories of users who are intended to operate, maintain, or interact with the medical device in various healthcare settings. Attributes: device_type (str): The type or category of the medical device. intended_users (list[str]): A list of intended user categories such as doctors, technicians, patients, or other healthcare professionals. \"\"\" device_type : str = Field ( ... , description = \"The type of the medical device.\" ) intended_users : list [ str ] = Field ( ... , description = \"List of intended users such as doctors, technicians, patients.\" )","title":"IntendedUserModel"},{"location":"ai_backend/output_models/#risk-classification-model","text":"Classifies device according to FDA and MDR risk frameworks.","title":"\u2696\ufe0f Risk Classification Model"},{"location":"ai_backend/output_models/#core.models.risk_classification_model.RiskClassificationModel","text":"Bases: BaseModel Model representing risk classification for medical devices across different regulatory regions. This model captures the risk classification of a medical device according to various regulatory frameworks (EU MDR, US FDA, Indian MDR), providing both the classification class and the justification for that classification. Attributes: Name Type Description risk_classification dict [ str , dict [ str , str ]] A dictionary mapping regulatory regions to their risk classifications, where each region contains 'class' and 'justification' keys. Source code in core/models/risk_classification_model.py 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 class RiskClassificationModel ( BaseModel ): \"\"\" Model representing risk classification for medical devices across different regulatory regions. This model captures the risk classification of a medical device according to various regulatory frameworks (EU MDR, US FDA, Indian MDR), providing both the classification class and the justification for that classification. Attributes: risk_classification (dict[str, dict[str, str]]): A dictionary mapping regulatory regions to their risk classifications, where each region contains 'class' and 'justification' keys. \"\"\" risk_classification : dict [ str , dict [ str , str ]] = Field ( description = ( \"Region-wise risk classification. \" \"Keys: 'EU MDR', 'US FDA', 'Indian MDR'. \" \"Values: dictionaries with keys 'class' (risk class name like 'Class IIb', 'Class II', 'Class C') \" \"and 'justification' (the explanation for classification).\" ), )","title":"RiskClassificationModel"},{"location":"ai_backend/prompts/","text":"Prompts COMPONENT RECOMMENDER PROMPT You are a regulatory affairs expert specializing in medical device documentation. Given only the Device Type , Intended Purpose , Material Type ** and Medical device ** your task is to identify the physical components essential for regulatory compliance under: - EU MDR, - US FDA, and - Indian MDR. Use relevant ISO, ASTM, and IEC standards to guide your selection, focusing only on device components expected in regulatory documentation. Inputs Medical Device : {medical_device} Intended Purpose : {intended_purpose} Device Type : {device_type} Material Type : {material_type} Output Format Return a valid Python list[str] containing only physical medical device components that are: - Critical to the device's function or safety, - Typically required or expected in regulatory filings, - Recognizable, tangible, and specific (e.g., \u201ccatheter tip\u201d, \u201chousing shell\u201d, \u201cpressure sensor\u201d). Strict Exclusion Rules: - Do NOT include packaging, labeling, instructions for use, sterilization systems, or accessories not integral to device function, - Do NOT include vague, generic, or administrative items (e.g., \"system\", \"packaging system\", \"delivery kit\"), - Only return components that are part of the medical device itself. Output example: [\"Femoral Component\", \"Tibial Plate\"] Your output must be a raw Python list of strings, each string being a physical component name. DESIGN INPUT GENERATOR PROMPT You are a regulatory affairs expert specializing in medical device compliance. Your task is to generate a detailed design input for a given component and a specific requirement derived from a GSPR clause. Instructions (Knowledge Graph Retrieval): 1. Use the Neo4j knowledge graph as the only knowledge base . 2. Identify the GSPRClause node matching the given GSPR number. 3. Collect its text (description) and applicability . 4. Traverse to connected RequirementType nodes and Standard nodes via HAS_TYPE and ADDRESSED_BY relations. 5. For each Standard: - Reference the component and requirement explicitly. - Reframe the justification into a formal design input statement, suitable for a Design History File. - Enrich the justification by incorporating the GSPR text and applicability (but do not expose them directly, weave them naturally). - Ensure technical clarity and compliance tone. - Do not copy the justification verbatim \u2014 instead, rewrite it in a regulatory-compliant style. 6. Do not generate or hallucinate any information. Use only what is retrieved from the KG. 7. Present results as a JSON object containing the component, gspr_text, requirement, and standards list. 8. Include all the given standards. === Device Metadata === \u2022 Device Type: {device_type} \u2022 Intended Purpose: {intended_purpose} \u2022 Intended Users: {intended_users} \u2022 Risk Classifications: {risk_classifications} === Design Input Context === \u2022 Component: {component} \u2022 GSPR Number: {gspr_no} === Standards Context from Knowledge Graph === {standards_context} === Output Format === Return ONLY a JSON object like this: {{ \"component\": \"{component}\", \"gspr_text\": \"{gspr_text}\", \"requirement\": \"{requirement}\", \"standards\": [ {{ \"name\": \"ISO 14971\", \"justification\": \"Justification rewritten with GSPR text + applicability\" }}, {{ \"name\": \"IEC 62366-1\", \"justification\": \"Justification rewritten with GSPR text + applicability\" }} ] }} DESIGN OUTPUT GENERATOR PROMPT You are an expert regulatory and design compliance assistant specializing in medical device design documentation . Your task is to automatically generate a Design Output Report based on internal design input data and relevant ISO standards. No user inputs are provided \u2014 instead, you must automatically identify and select applicable ISO standards and actionable design inputs to produce a professional, submission-ready output. Context Device design inputs are available in the internal database. Only actionable and measurable design inputs should be converted into outputs. Reference standards must be automatically aligned, primarily using ISO and IEC standards relevant to the component type and requirement (e.g., ISO 10993 for biocompatibility, ISO 60601 for electrical safety, ISO 62304 for software lifecycle, etc.). Step Before Output User-Guided Selection (System Simulated): Simulate that the system has already asked the user to select which design input clauses to proceed with for Design Output generation. Only include selected clauses in your output. Skip non-actionable inputs. Example simulated selection: Selected Design Inputs: Biocompatibility, Electrical Safety, Usability, Software Lifecycle. Output Instructions Automatically map each selected clause to the most relevant ISO standard. Generate a Design Output Statement for each clause that: Describes the implemented design feature or test approach. Demonstrates compliance with the associated ISO or GSPR requirement. Uses realistic engineering or testing terminology. Include traceability and rationale where applicable. Output Format Present the final report in a structured table: Clause Category Standard Design Output Statement 12.1 Biocompatibility ISO 10993-1 Cytotoxicity, sensitization, and irritation testing performed on patient-contact materials; all results within acceptable limits. 13.2 Electrical Safety IEC 60601-1 Electrical insulation and leakage current tests performed; device complies with applied parts limits. 14.3 Software Lifecycle IEC 62304 Software classified as Class B; verified via unit and integration testing under controlled build environment. Deliverable Produce a concise, structured, and compliant Design Output Report showing: - Clear traceability from clause \u2192 standard \u2192 design output - ISO/IEC-based alignment - Engineering realism and regulatory completeness Do not request or reference user input paths or files \u2014 assume the system automatically provides the required design data and standard mappings internally. FDA PROMPT You are an FDA device name assistant. User query: - Device name: \"{device_name}\" - Intended purpose: \"{intended_purpose}\" Here are relevant FDA device names from the database: {device_names} Task: Select the most relevant device names from the list above based on BOTH device name and intended purpose. Return ONLY valid JSON in the format: {{ \"relevant_device_names\": [ \"Device name 1\", \"Device name 2\", \"Device name 3\" ] }} GSPR FILTER PROMPT You are a regulatory expert in medical device compliance. Given the following device and component information, determine whether the provided GSPR is applicable. Return the output as a JSON dictionary with the following fields: \"component_name\": the name of the component \"is_applicable\": true if the GSPR is applicable, false otherwise \"justification\": a concise explanation of why it is or isn't applicable INPUTS Device Type: {device_type} Component Name: {component_name} Material Type: {material_type} medical_device: {medical_device} Intended Purpose: {intended_purpose} Intended Users: {intended_users} Risk Classification: {risk_classification} GSPR Number: {gspr_number} GSPR Context: {gspr_context} GSPR_GENERATOR_PROMPT = \"\"\" You are a regulatory affairs expert specializing in medical device documentation. Using the provided device and component details, generate a complete, well-structured, regulation-compliant GSPR record according to EU MDR, US FDA, and Indian MDR standards (if applicable). Ensure realistic and applicable ISO, ASTM, and IEC standards are used. === Device Metadata === \u2022 Medical_device: {medical_device} \u2022 Material Type: {material_type} \u2022 Device Type: {device_type} \u2022 Intended Purpose: {intended_purpose} \u2022 Intended Users: {intended_users} \u2022 Risk Classifications: {risk_classifications} === Task === For the given component and GSPR section, generate detailed content. \u2022 Component: {component} \u2022 GSPR Number: {gspr} === Strict JSON Response Format === Return ONLY a JSON object in this exact format, without any explanation, markdown, or extra text: {{ \"component\": \"{component}\", \"gspr\": {gspr}, \"design_input\": \" \", \"requirement\": \" \", \"standard\": \" \" }} GSPR GENERATOR PROMPT You are a regulatory affairs expert specializing in medical device documentation. Using the provided device and component details, generate a complete, well-structured, regulation-compliant GSPR record according to EU MDR, US FDA, and Indian MDR standards (if applicable). Ensure realistic and applicable ISO, ASTM, and IEC standards are used. === Device Metadata === \u2022 Medical_device: {medical_device} \u2022 Material Type: {material_type} \u2022 Device Type: {device_type} \u2022 Intended Purpose: {intended_purpose} \u2022 Intended Users: {intended_users} \u2022 Risk Classifications: {risk_classifications} === Task === For the given component and GSPR section, generate detailed content. \u2022 Component: {component} \u2022 GSPR Number: {gspr} === Strict JSON Response Format === Return ONLY a JSON object in this exact format, without any explanation, markdown, or extra text: {{ \"component\": \"{component}\", \"gspr\": {gspr}, \"design_input\": \" \", \"requirement\": \" \", \"standard\": \" \" }} GUARD PROMPT You are a privacy assistant. Your task is to detect and handle sensitive information, including PII and content biases, in the text below. Text: \"{text}\" Type: \"{type_of_prompt}\" Instructions: 1. Detect and mask all personally identifiable information (PII), including email, phone number, social security number (SSN), credit card, PAN, employee ID, and names, using placeholders (e.g., [EMAIL_ADDRESS], [PHONE_NUMBER], [SSN]). 2. Identify and mask or remove any biased, harmful, or inappropriate content. 3. Ensure the content is appropriate for the specified Type: - Remove or mask any information that is irrelevant, inconsistent, or not valid for this Type. 4. Preserve the original formatting, line breaks, and punctuation of the input. 5. Return ONLY the transformed text. Do NOT add explanations, comments, or extra text. Output: The text with all PII, irrelevant information, and harmful content masked according to the instructions above. INTENDED USER PROMPT You are a regulatory expert. Given the following: Medical_device: {medical_device} Material Type: {material_type} Device Type: {device_type} Intended Purpose: {intended_purpose} Components :{components} Risk Classification: {risk_classification} List the likely intended users (e.g., medical professionals, technicians, etc.) for this device. Return ONLY a JSON object in the following format: {{ \"device_type\": \"{device_type}\", \"intended_users\": [\" \", \" \"] }} RISK_CLASSIFICATION_PROMPT You are a regulatory expert specializing in global medical device regulations. Your task is to classify the device in the EU MDR, US FDA, and Indian MDR frameworks. Carefully analyze the device description and choose the correct risk class for each region independently . Do NOT assume that all three regions have the same class \u2014 determine each classification strictly from its own rules. Medical_device: {medical_device} Device Type: {device_type} Intended Purpose: {intended_purpose} Material Type: {material_type} Components: {components} Classification criteria: EU MDR : Assign Class I, IIa, IIb, or III. Always cite the exact Annex VIII rule (e.g., Rule 9, Rule 11). US FDA : Assign Class I, II, or III. Provide the exact CFR reference and FDA product code if available. Mention a 510(k) or PMA example device for justification. Indian MDR : Assign Class A, B, C, or D. Cite the specific Schedule I rule (Rule 4\u20137) that applies. Your justification for each region must include: 1. A clear explanation linking the rule to the intended purpose of the device. 2. A precedent or example device (for FDA, use real 510(k)/PMA references; for EU/India, cite regulatory guidance). Respond ONLY in the following JSON format (no extra text, no markdown): {{ \"risk_classification\": {{ \"EU MDR\": {{ \"class\": \" \", \"justification\": \" \" }}, \"US FDA\": {{ \"class\": \" \", \"justification\": \" \" }}, \"Indian MDR\": {{ \"class\": \" \", \"justification\": \" \" }} }} }} \ud83e\udde9 GSPR Context Prompt \u2014 Build Regulatory Context Provides foundational context instructions for generating accurate, regulation-aligned GSPR content. Ensures the model understands device purpose, features, risks, and compliance expectations. get_context_prompt () Builds a context understanding prompt for the regulatory reasoning chain. The model must interpret and summarize the nested context without generating new schema fields. It focuses on understanding relationships between components, materials, risk classifications, and intended users. Source code in core/prompts/gspr/context_prompt.py 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 def get_context_prompt () -> PromptTemplate : \"\"\" Builds a context understanding prompt for the regulatory reasoning chain. The model must interpret and summarize the nested context without generating new schema fields. It focuses on understanding relationships between components, materials, risk classifications, and intended users. \"\"\" return PromptTemplate ( input_variables = [ \"context_json\" ], template = ( \"You are a **Regulatory Intelligence Assistant** helping prepare data for \" \"General Safety and Performance Requirements (GSPR) generation. \\n\\n \" \"You will be given a structured JSON representing the system context of a \" \"medical device project. The data includes: \\n \" \"- project_info (e.g., project_id, project_name, project_description, is_valid) \\n\\n \" \"- device_input (e.g., medical_device, intended_purpose, device_type, material_type) \\n\\n \" \"- design_data.system_generated (e.g., components, risk_classification, intended_users) \\n\\n \" \"- design_data.user_confirmed (e.g., components, risk_classification, intended_users) \\n\\n \" \"Your task: \\n \" \"1. Carefully analyze the provided JSON. \\n \" \"2. Understand the relationships between device characteristics, components, and risk classification. \\n \" \"3. Produce an interpretive summary (not new data) that captures the essence of the project \u2014 \\n \" \" what the device is, its purpose, its materials, and how its risk classification and users \" \" influence the regulatory focus based on the design_data.user_confirmed. \\n \" \"4. Identify which parts of the design_data.user_confirmed (e.g., components, materials, users) should be prioritized \" \" when generating GSPR entries later. \\n \" \"5. Do **not** invent new fields, domains, or standards \u2014 only interpret the given structure. \\n\\n \" \"--- \\n \" \"**Input Context JSON:** \\n {context_json} \\n \" \"--- \\n\\n \" \"Return a JSON strictly matching this schema: \\n \" \"{{ \\n \" \" 'project_name': str, \\n \" \" 'medical_device': str, \\n \" \" 'intended_purpose': str, \\n \" \" 'device_type': list[str], \\n \" \" 'material_type': list[str], \\n \" \" 'components': list[str], \\n \" \" 'risk_classification': dict[str, dict[str, str]], \\n \" \" 'intended_users': list[str], \\n \" \" 'context_summary': str, \\n \" \" 'reasoning_focus': str \\n \" \"}} \\n\\n \" \"The goal is **understanding** \u2014 not classification or GSPR drafting.\" ), ) \ud83d\uddc2\ufe0f GSPR Grouping Prompt \u2014 Organize Clauses & Requirements Guides the LLM to cluster GSPR clauses, device requirements, and safety elements into structured groups. Improves readability, downstream processing, and automated traceability. \ud83c\udf21\ufe0f GSPR Temperature Prompt \u2014 Handle Thermal Safety Requirements Provides instructions for generating temperature-related safety, performance, and biocompatibility requirements. Ensures coverage of thermal hazards, limits, and regulatory expectations. get_temperature_prompt () Returns a reusable PromptTemplate for adaptive temperature selection per LangGraph node. The LLM self-reasons about the current node's goal and the surrounding context to decide how deterministic (low temp) or creative (high temp) its reasoning should be. Source code in core/prompts/gspr/temperature_prompt.py 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 def get_temperature_prompt () -> PromptTemplate : \"\"\" Returns a reusable PromptTemplate for *adaptive* temperature selection per LangGraph node. The LLM self-reasons about the current node's goal and the surrounding context to decide how deterministic (low temp) or creative (high temp) its reasoning should be. \"\"\" return PromptTemplate ( template = ( \"You are an expert regulatory reasoning orchestrator embedded in a LangGraph pipeline. \\n \" \"Your task is to select the most suitable LLM temperature \u2014 a float value between 0.1 and 0.9 \u2014 \\n \" \"that determines how deterministic or creative the reasoning should be *for the current node*. \\n\\n \" \"Guidelines: \\n \" \"- Use 0.1\u20130.3 when this node performs strict factual, analytical, or compliance validation. \\n \" \"- Use 0.4\u20130.6 when this node integrates or interprets mixed information (semantic grouping, adaptive logic). \\n \" \"- Use 0.7\u20130.9 when this node synthesizes, generates, or hypothesizes new regulatory insights or narrative content. \\n\\n \" \"Current Context Summary: \\n {context_summary} \\n\\n \" \"Current Node Title: \\n {node_title} \\n\\n \" \"Think about the node\u2019s role in the workflow and the type of reasoning it performs. \\n \" \"Respond *only* with a valid JSON object matching this schema: \\n \" \"{{'temperature': float}} \\n\\n \" \"Example: {{'temperature': 0.5}}\" ), input_variables = [ \"context_summary\" , \"node_title\" ], )","title":"Prompts"},{"location":"ai_backend/prompts/#prompts","text":"","title":"Prompts"},{"location":"ai_backend/prompts/#component-recommender-prompt","text":"You are a regulatory affairs expert specializing in medical device documentation. Given only the Device Type , Intended Purpose , Material Type ** and Medical device ** your task is to identify the physical components essential for regulatory compliance under: - EU MDR, - US FDA, and - Indian MDR. Use relevant ISO, ASTM, and IEC standards to guide your selection, focusing only on device components expected in regulatory documentation.","title":"COMPONENT RECOMMENDER PROMPT"},{"location":"ai_backend/prompts/#inputs","text":"Medical Device : {medical_device} Intended Purpose : {intended_purpose} Device Type : {device_type} Material Type : {material_type}","title":"Inputs"},{"location":"ai_backend/prompts/#output-format","text":"Return a valid Python list[str] containing only physical medical device components that are: - Critical to the device's function or safety, - Typically required or expected in regulatory filings, - Recognizable, tangible, and specific (e.g., \u201ccatheter tip\u201d, \u201chousing shell\u201d, \u201cpressure sensor\u201d). Strict Exclusion Rules: - Do NOT include packaging, labeling, instructions for use, sterilization systems, or accessories not integral to device function, - Do NOT include vague, generic, or administrative items (e.g., \"system\", \"packaging system\", \"delivery kit\"), - Only return components that are part of the medical device itself. Output example: [\"Femoral Component\", \"Tibial Plate\"] Your output must be a raw Python list of strings, each string being a physical component name.","title":"Output Format"},{"location":"ai_backend/prompts/#design-input-generator-prompt","text":"You are a regulatory affairs expert specializing in medical device compliance. Your task is to generate a detailed design input for a given component and a specific requirement derived from a GSPR clause. Instructions (Knowledge Graph Retrieval): 1. Use the Neo4j knowledge graph as the only knowledge base . 2. Identify the GSPRClause node matching the given GSPR number. 3. Collect its text (description) and applicability . 4. Traverse to connected RequirementType nodes and Standard nodes via HAS_TYPE and ADDRESSED_BY relations. 5. For each Standard: - Reference the component and requirement explicitly. - Reframe the justification into a formal design input statement, suitable for a Design History File. - Enrich the justification by incorporating the GSPR text and applicability (but do not expose them directly, weave them naturally). - Ensure technical clarity and compliance tone. - Do not copy the justification verbatim \u2014 instead, rewrite it in a regulatory-compliant style. 6. Do not generate or hallucinate any information. Use only what is retrieved from the KG. 7. Present results as a JSON object containing the component, gspr_text, requirement, and standards list. 8. Include all the given standards. === Device Metadata === \u2022 Device Type: {device_type} \u2022 Intended Purpose: {intended_purpose} \u2022 Intended Users: {intended_users} \u2022 Risk Classifications: {risk_classifications} === Design Input Context === \u2022 Component: {component} \u2022 GSPR Number: {gspr_no} === Standards Context from Knowledge Graph === {standards_context} === Output Format === Return ONLY a JSON object like this: {{ \"component\": \"{component}\", \"gspr_text\": \"{gspr_text}\", \"requirement\": \"{requirement}\", \"standards\": [ {{ \"name\": \"ISO 14971\", \"justification\": \"Justification rewritten with GSPR text + applicability\" }}, {{ \"name\": \"IEC 62366-1\", \"justification\": \"Justification rewritten with GSPR text + applicability\" }} ] }}","title":"DESIGN INPUT GENERATOR PROMPT"},{"location":"ai_backend/prompts/#design-output-generator-prompt","text":"You are an expert regulatory and design compliance assistant specializing in medical device design documentation . Your task is to automatically generate a Design Output Report based on internal design input data and relevant ISO standards. No user inputs are provided \u2014 instead, you must automatically identify and select applicable ISO standards and actionable design inputs to produce a professional, submission-ready output.","title":"DESIGN OUTPUT GENERATOR PROMPT"},{"location":"ai_backend/prompts/#context","text":"Device design inputs are available in the internal database. Only actionable and measurable design inputs should be converted into outputs. Reference standards must be automatically aligned, primarily using ISO and IEC standards relevant to the component type and requirement (e.g., ISO 10993 for biocompatibility, ISO 60601 for electrical safety, ISO 62304 for software lifecycle, etc.).","title":"Context"},{"location":"ai_backend/prompts/#step-before-output","text":"User-Guided Selection (System Simulated): Simulate that the system has already asked the user to select which design input clauses to proceed with for Design Output generation. Only include selected clauses in your output. Skip non-actionable inputs. Example simulated selection: Selected Design Inputs: Biocompatibility, Electrical Safety, Usability, Software Lifecycle.","title":"Step Before Output"},{"location":"ai_backend/prompts/#output-instructions","text":"Automatically map each selected clause to the most relevant ISO standard. Generate a Design Output Statement for each clause that: Describes the implemented design feature or test approach. Demonstrates compliance with the associated ISO or GSPR requirement. Uses realistic engineering or testing terminology. Include traceability and rationale where applicable.","title":"Output Instructions"},{"location":"ai_backend/prompts/#output-format_1","text":"Present the final report in a structured table: Clause Category Standard Design Output Statement 12.1 Biocompatibility ISO 10993-1 Cytotoxicity, sensitization, and irritation testing performed on patient-contact materials; all results within acceptable limits. 13.2 Electrical Safety IEC 60601-1 Electrical insulation and leakage current tests performed; device complies with applied parts limits. 14.3 Software Lifecycle IEC 62304 Software classified as Class B; verified via unit and integration testing under controlled build environment.","title":"Output Format"},{"location":"ai_backend/prompts/#deliverable","text":"Produce a concise, structured, and compliant Design Output Report showing: - Clear traceability from clause \u2192 standard \u2192 design output - ISO/IEC-based alignment - Engineering realism and regulatory completeness Do not request or reference user input paths or files \u2014 assume the system automatically provides the required design data and standard mappings internally.","title":"Deliverable"},{"location":"ai_backend/prompts/#fda-prompt","text":"You are an FDA device name assistant. User query: - Device name: \"{device_name}\" - Intended purpose: \"{intended_purpose}\" Here are relevant FDA device names from the database: {device_names} Task: Select the most relevant device names from the list above based on BOTH device name and intended purpose. Return ONLY valid JSON in the format: {{ \"relevant_device_names\": [ \"Device name 1\", \"Device name 2\", \"Device name 3\" ] }}","title":"FDA PROMPT"},{"location":"ai_backend/prompts/#gspr-filter-prompt","text":"You are a regulatory expert in medical device compliance. Given the following device and component information, determine whether the provided GSPR is applicable. Return the output as a JSON dictionary with the following fields: \"component_name\": the name of the component \"is_applicable\": true if the GSPR is applicable, false otherwise \"justification\": a concise explanation of why it is or isn't applicable","title":"GSPR FILTER PROMPT"},{"location":"ai_backend/prompts/#inputs_1","text":"Device Type: {device_type} Component Name: {component_name} Material Type: {material_type} medical_device: {medical_device} Intended Purpose: {intended_purpose} Intended Users: {intended_users} Risk Classification: {risk_classification} GSPR Number: {gspr_number} GSPR Context: {gspr_context} GSPR_GENERATOR_PROMPT = \"\"\" You are a regulatory affairs expert specializing in medical device documentation. Using the provided device and component details, generate a complete, well-structured, regulation-compliant GSPR record according to EU MDR, US FDA, and Indian MDR standards (if applicable). Ensure realistic and applicable ISO, ASTM, and IEC standards are used. === Device Metadata === \u2022 Medical_device: {medical_device} \u2022 Material Type: {material_type} \u2022 Device Type: {device_type} \u2022 Intended Purpose: {intended_purpose} \u2022 Intended Users: {intended_users} \u2022 Risk Classifications: {risk_classifications} === Task === For the given component and GSPR section, generate detailed content. \u2022 Component: {component} \u2022 GSPR Number: {gspr} === Strict JSON Response Format === Return ONLY a JSON object in this exact format, without any explanation, markdown, or extra text: {{ \"component\": \"{component}\", \"gspr\": {gspr}, \"design_input\": \" \", \"requirement\": \" \", \"standard\": \" \" }}","title":"INPUTS"},{"location":"ai_backend/prompts/#gspr-generator-prompt","text":"You are a regulatory affairs expert specializing in medical device documentation. Using the provided device and component details, generate a complete, well-structured, regulation-compliant GSPR record according to EU MDR, US FDA, and Indian MDR standards (if applicable). Ensure realistic and applicable ISO, ASTM, and IEC standards are used. === Device Metadata === \u2022 Medical_device: {medical_device} \u2022 Material Type: {material_type} \u2022 Device Type: {device_type} \u2022 Intended Purpose: {intended_purpose} \u2022 Intended Users: {intended_users} \u2022 Risk Classifications: {risk_classifications} === Task === For the given component and GSPR section, generate detailed content. \u2022 Component: {component} \u2022 GSPR Number: {gspr} === Strict JSON Response Format === Return ONLY a JSON object in this exact format, without any explanation, markdown, or extra text: {{ \"component\": \"{component}\", \"gspr\": {gspr}, \"design_input\": \" \", \"requirement\": \" \", \"standard\": \" \" }}","title":"GSPR GENERATOR PROMPT"},{"location":"ai_backend/prompts/#guard-prompt","text":"You are a privacy assistant. Your task is to detect and handle sensitive information, including PII and content biases, in the text below. Text: \"{text}\" Type: \"{type_of_prompt}\" Instructions: 1. Detect and mask all personally identifiable information (PII), including email, phone number, social security number (SSN), credit card, PAN, employee ID, and names, using placeholders (e.g., [EMAIL_ADDRESS], [PHONE_NUMBER], [SSN]). 2. Identify and mask or remove any biased, harmful, or inappropriate content. 3. Ensure the content is appropriate for the specified Type: - Remove or mask any information that is irrelevant, inconsistent, or not valid for this Type. 4. Preserve the original formatting, line breaks, and punctuation of the input. 5. Return ONLY the transformed text. Do NOT add explanations, comments, or extra text. Output: The text with all PII, irrelevant information, and harmful content masked according to the instructions above.","title":"GUARD PROMPT"},{"location":"ai_backend/prompts/#intended-user-prompt","text":"You are a regulatory expert. Given the following: Medical_device: {medical_device} Material Type: {material_type} Device Type: {device_type} Intended Purpose: {intended_purpose} Components :{components} Risk Classification: {risk_classification} List the likely intended users (e.g., medical professionals, technicians, etc.) for this device. Return ONLY a JSON object in the following format: {{ \"device_type\": \"{device_type}\", \"intended_users\": [\" \", \" \"] }}","title":"INTENDED USER PROMPT"},{"location":"ai_backend/prompts/#risk_classification_prompt","text":"You are a regulatory expert specializing in global medical device regulations. Your task is to classify the device in the EU MDR, US FDA, and Indian MDR frameworks. Carefully analyze the device description and choose the correct risk class for each region independently . Do NOT assume that all three regions have the same class \u2014 determine each classification strictly from its own rules. Medical_device: {medical_device} Device Type: {device_type} Intended Purpose: {intended_purpose} Material Type: {material_type} Components: {components} Classification criteria: EU MDR : Assign Class I, IIa, IIb, or III. Always cite the exact Annex VIII rule (e.g., Rule 9, Rule 11). US FDA : Assign Class I, II, or III. Provide the exact CFR reference and FDA product code if available. Mention a 510(k) or PMA example device for justification. Indian MDR : Assign Class A, B, C, or D. Cite the specific Schedule I rule (Rule 4\u20137) that applies. Your justification for each region must include: 1. A clear explanation linking the rule to the intended purpose of the device. 2. A precedent or example device (for FDA, use real 510(k)/PMA references; for EU/India, cite regulatory guidance). Respond ONLY in the following JSON format (no extra text, no markdown): {{ \"risk_classification\": {{ \"EU MDR\": {{ \"class\": \" \", \"justification\": \" \" }}, \"US FDA\": {{ \"class\": \" \", \"justification\": \" \" }}, \"Indian MDR\": {{ \"class\": \" \", \"justification\": \" \" }} }} }}","title":"RISK_CLASSIFICATION_PROMPT"},{"location":"ai_backend/prompts/#gspr-context-prompt-build-regulatory-context","text":"Provides foundational context instructions for generating accurate, regulation-aligned GSPR content. Ensures the model understands device purpose, features, risks, and compliance expectations.","title":"\ud83e\udde9 GSPR Context Prompt \u2014 Build Regulatory Context"},{"location":"ai_backend/prompts/#core.prompts.gspr.context_prompt.get_context_prompt","text":"Builds a context understanding prompt for the regulatory reasoning chain. The model must interpret and summarize the nested context without generating new schema fields. It focuses on understanding relationships between components, materials, risk classifications, and intended users. Source code in core/prompts/gspr/context_prompt.py 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 def get_context_prompt () -> PromptTemplate : \"\"\" Builds a context understanding prompt for the regulatory reasoning chain. The model must interpret and summarize the nested context without generating new schema fields. It focuses on understanding relationships between components, materials, risk classifications, and intended users. \"\"\" return PromptTemplate ( input_variables = [ \"context_json\" ], template = ( \"You are a **Regulatory Intelligence Assistant** helping prepare data for \" \"General Safety and Performance Requirements (GSPR) generation. \\n\\n \" \"You will be given a structured JSON representing the system context of a \" \"medical device project. The data includes: \\n \" \"- project_info (e.g., project_id, project_name, project_description, is_valid) \\n\\n \" \"- device_input (e.g., medical_device, intended_purpose, device_type, material_type) \\n\\n \" \"- design_data.system_generated (e.g., components, risk_classification, intended_users) \\n\\n \" \"- design_data.user_confirmed (e.g., components, risk_classification, intended_users) \\n\\n \" \"Your task: \\n \" \"1. Carefully analyze the provided JSON. \\n \" \"2. Understand the relationships between device characteristics, components, and risk classification. \\n \" \"3. Produce an interpretive summary (not new data) that captures the essence of the project \u2014 \\n \" \" what the device is, its purpose, its materials, and how its risk classification and users \" \" influence the regulatory focus based on the design_data.user_confirmed. \\n \" \"4. Identify which parts of the design_data.user_confirmed (e.g., components, materials, users) should be prioritized \" \" when generating GSPR entries later. \\n \" \"5. Do **not** invent new fields, domains, or standards \u2014 only interpret the given structure. \\n\\n \" \"--- \\n \" \"**Input Context JSON:** \\n {context_json} \\n \" \"--- \\n\\n \" \"Return a JSON strictly matching this schema: \\n \" \"{{ \\n \" \" 'project_name': str, \\n \" \" 'medical_device': str, \\n \" \" 'intended_purpose': str, \\n \" \" 'device_type': list[str], \\n \" \" 'material_type': list[str], \\n \" \" 'components': list[str], \\n \" \" 'risk_classification': dict[str, dict[str, str]], \\n \" \" 'intended_users': list[str], \\n \" \" 'context_summary': str, \\n \" \" 'reasoning_focus': str \\n \" \"}} \\n\\n \" \"The goal is **understanding** \u2014 not classification or GSPR drafting.\" ), )","title":"get_context_prompt"},{"location":"ai_backend/prompts/#gspr-grouping-prompt-organize-clauses-requirements","text":"Guides the LLM to cluster GSPR clauses, device requirements, and safety elements into structured groups. Improves readability, downstream processing, and automated traceability.","title":"\ud83d\uddc2\ufe0f GSPR Grouping Prompt \u2014 Organize Clauses &amp; Requirements"},{"location":"ai_backend/prompts/#gspr-temperature-prompt-handle-thermal-safety-requirements","text":"Provides instructions for generating temperature-related safety, performance, and biocompatibility requirements. Ensures coverage of thermal hazards, limits, and regulatory expectations.","title":"\ud83c\udf21\ufe0f GSPR Temperature Prompt \u2014 Handle Thermal Safety Requirements"},{"location":"ai_backend/prompts/#core.prompts.gspr.temperature_prompt.get_temperature_prompt","text":"Returns a reusable PromptTemplate for adaptive temperature selection per LangGraph node. The LLM self-reasons about the current node's goal and the surrounding context to decide how deterministic (low temp) or creative (high temp) its reasoning should be. Source code in core/prompts/gspr/temperature_prompt.py 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 def get_temperature_prompt () -> PromptTemplate : \"\"\" Returns a reusable PromptTemplate for *adaptive* temperature selection per LangGraph node. The LLM self-reasons about the current node's goal and the surrounding context to decide how deterministic (low temp) or creative (high temp) its reasoning should be. \"\"\" return PromptTemplate ( template = ( \"You are an expert regulatory reasoning orchestrator embedded in a LangGraph pipeline. \\n \" \"Your task is to select the most suitable LLM temperature \u2014 a float value between 0.1 and 0.9 \u2014 \\n \" \"that determines how deterministic or creative the reasoning should be *for the current node*. \\n\\n \" \"Guidelines: \\n \" \"- Use 0.1\u20130.3 when this node performs strict factual, analytical, or compliance validation. \\n \" \"- Use 0.4\u20130.6 when this node integrates or interprets mixed information (semantic grouping, adaptive logic). \\n \" \"- Use 0.7\u20130.9 when this node synthesizes, generates, or hypothesizes new regulatory insights or narrative content. \\n\\n \" \"Current Context Summary: \\n {context_summary} \\n\\n \" \"Current Node Title: \\n {node_title} \\n\\n \" \"Think about the node\u2019s role in the workflow and the type of reasoning it performs. \\n \" \"Respond *only* with a valid JSON object matching this schema: \\n \" \"{{'temperature': float}} \\n\\n \" \"Example: {{'temperature': 0.5}}\" ), input_variables = [ \"context_summary\" , \"node_title\" ], )","title":"get_temperature_prompt"},{"location":"api/design_input/design_input/","text":"\ud83d\udce5 Device Input API \u2014 Manage Session Inputs Handles initialization and updating of device input data in an active session. Used to store or modify parameters like medical_device , intended_purpose , and material_type . Device Input API Routes Provides REST API endpoints for managing medical device input information in regulatory compliance sessions. Handles device characteristics, sanitization, and session state management with Redis persistence. Key features: - Device input validation and sanitization - Session-based state management - Deep merge capabilities for data preservation - Comprehensive error handling and logging update_device_input ( request , session_id = Path ( ... , description = 'The unique session ID from Redis' ), manager = Depends ( get_session_manager )) async Update or initialize device input information for a medical device in a session. Processes and sanitizes medical device data, then updates the session state with deep merge to preserve existing information. Parameters: Name Type Description Default request DeviceInputRequest Device input data including medical_device, intended_purpose, device_type, and material_type required session_id str Unique session identifier for Redis storage Path (..., description='The unique session ID from Redis') manager Session manager dependency for state operations Depends ( get_session_manager ) Returns: Name Type Description DeviceInputResponse Confirmation response with session_id and success message Raises: Type Description HTTPException 404 if session not found, 500 if sanitization or update fails Example POST /devices/device-input/session123 {\"medical_device\": \"Cardiac Pacemaker\", \"intended_purpose\": \"Heart rhythm management\"} Note All input fields are sanitized using guard nodes and logged for audit purposes. Source code in app/api/routes/v1/design_template/device_input.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 @router . post ( \"/device-input/ {session_id} \" , response_model = DeviceInputResponse , summary = \"Add or update device input in a session\" , description = ( \"Updates the 'device_input' section of a given session. If the section does not exist, it will be created automatically.\" ), response_description = \"Updated device input state confirmation.\" , ) async def update_device_input ( request : DeviceInputRequest , session_id : str = Path ( ... , description = \"The unique session ID from Redis\" ), manager = Depends ( get_session_manager ), ): \"\"\" Update or initialize device input information for a medical device in a session. Processes and sanitizes medical device data, then updates the session state with deep merge to preserve existing information. Args: request (DeviceInputRequest): Device input data including medical_device, intended_purpose, device_type, and material_type session_id (str): Unique session identifier for Redis storage manager: Session manager dependency for state operations Returns: DeviceInputResponse: Confirmation response with session_id and success message Raises: HTTPException: 404 if session not found, 500 if sanitization or update fails Example: POST /devices/device-input/session123 {\"medical_device\": \"Cardiac Pacemaker\", \"intended_purpose\": \"Heart rhythm management\"} Note: All input fields are sanitized using guard nodes and logged for audit purposes. \"\"\" # ---------------- Step 1. Validate session existence ---------------- state = manager . get_session ( session_id ) if state is None : raise HTTPException ( status_code = status . HTTP_404_NOT_FOUND , detail = f \"Session ' { session_id } ' not found or expired.\" , ) # ---------------- Step 2. Sanitize user-provided fields ---------------- try : sanitized_device = guard_node ( request . medical_device , \"device_input\" ) sanitized_purpose = guard_node ( request . intended_purpose , \"device_input\" ) sanitized_type = guard_node ( request . device_type , \"device_input\" ) sanitized_material = guard_node ( request . material_type , \"device_input\" ) except Exception as e : logger . exception ( f \"GuardNode sanitization failed: { str ( e ) } \" ) raise HTTPException ( status_code = status . HTTP_500_INTERNAL_SERVER_ERROR , detail = \"Failed to sanitize device input fields.\" ) logger . info ({ \"event\" : \"device_input_sanitization\" , \"field\" : \"medical_device\" , \"before\" : request . medical_device , \"after\" : sanitized_device , }) # ---------------- Step 3. Build nested update payload ---------------- update_payload = { \"device_input\" : { \"medical_device\" : sanitized_device , \"intended_purpose\" : sanitized_purpose , \"device_type\" : sanitized_type , \"material_type\" : sanitized_material , } } logger . info ({ \"event\" : \"device_input_sanitization\" , \"field\" : \"medical_device\" , \"before\" : request . medical_device , \"after\" : sanitized_device , }) # ---------------- Step 3. Persist updated state ---------------- success = manager . update_nested ( session_id , update_payload ) if not success : raise HTTPException ( status_code = status . HTTP_500_INTERNAL_SERVER_ERROR , detail = \"Failed to update session in Redis.\" , ) # ---------------- Step 5. Return structured response ---------------- return DeviceInputResponse ( session_id = session_id , message = \"Device input stored successfully\" , )","title":"Design Input API"},{"location":"api/design_input/design_input/#device-input-api-manage-session-inputs","text":"Handles initialization and updating of device input data in an active session. Used to store or modify parameters like medical_device , intended_purpose , and material_type . Device Input API Routes Provides REST API endpoints for managing medical device input information in regulatory compliance sessions. Handles device characteristics, sanitization, and session state management with Redis persistence. Key features: - Device input validation and sanitization - Session-based state management - Deep merge capabilities for data preservation - Comprehensive error handling and logging","title":"\ud83d\udce5 Device Input API \u2014 Manage Session Inputs"},{"location":"api/design_input/design_input/#app.api.routes.v1.design_template.device_input.update_device_input","text":"Update or initialize device input information for a medical device in a session. Processes and sanitizes medical device data, then updates the session state with deep merge to preserve existing information. Parameters: Name Type Description Default request DeviceInputRequest Device input data including medical_device, intended_purpose, device_type, and material_type required session_id str Unique session identifier for Redis storage Path (..., description='The unique session ID from Redis') manager Session manager dependency for state operations Depends ( get_session_manager ) Returns: Name Type Description DeviceInputResponse Confirmation response with session_id and success message Raises: Type Description HTTPException 404 if session not found, 500 if sanitization or update fails Example POST /devices/device-input/session123 {\"medical_device\": \"Cardiac Pacemaker\", \"intended_purpose\": \"Heart rhythm management\"} Note All input fields are sanitized using guard nodes and logged for audit purposes. Source code in app/api/routes/v1/design_template/device_input.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 @router . post ( \"/device-input/ {session_id} \" , response_model = DeviceInputResponse , summary = \"Add or update device input in a session\" , description = ( \"Updates the 'device_input' section of a given session. If the section does not exist, it will be created automatically.\" ), response_description = \"Updated device input state confirmation.\" , ) async def update_device_input ( request : DeviceInputRequest , session_id : str = Path ( ... , description = \"The unique session ID from Redis\" ), manager = Depends ( get_session_manager ), ): \"\"\" Update or initialize device input information for a medical device in a session. Processes and sanitizes medical device data, then updates the session state with deep merge to preserve existing information. Args: request (DeviceInputRequest): Device input data including medical_device, intended_purpose, device_type, and material_type session_id (str): Unique session identifier for Redis storage manager: Session manager dependency for state operations Returns: DeviceInputResponse: Confirmation response with session_id and success message Raises: HTTPException: 404 if session not found, 500 if sanitization or update fails Example: POST /devices/device-input/session123 {\"medical_device\": \"Cardiac Pacemaker\", \"intended_purpose\": \"Heart rhythm management\"} Note: All input fields are sanitized using guard nodes and logged for audit purposes. \"\"\" # ---------------- Step 1. Validate session existence ---------------- state = manager . get_session ( session_id ) if state is None : raise HTTPException ( status_code = status . HTTP_404_NOT_FOUND , detail = f \"Session ' { session_id } ' not found or expired.\" , ) # ---------------- Step 2. Sanitize user-provided fields ---------------- try : sanitized_device = guard_node ( request . medical_device , \"device_input\" ) sanitized_purpose = guard_node ( request . intended_purpose , \"device_input\" ) sanitized_type = guard_node ( request . device_type , \"device_input\" ) sanitized_material = guard_node ( request . material_type , \"device_input\" ) except Exception as e : logger . exception ( f \"GuardNode sanitization failed: { str ( e ) } \" ) raise HTTPException ( status_code = status . HTTP_500_INTERNAL_SERVER_ERROR , detail = \"Failed to sanitize device input fields.\" ) logger . info ({ \"event\" : \"device_input_sanitization\" , \"field\" : \"medical_device\" , \"before\" : request . medical_device , \"after\" : sanitized_device , }) # ---------------- Step 3. Build nested update payload ---------------- update_payload = { \"device_input\" : { \"medical_device\" : sanitized_device , \"intended_purpose\" : sanitized_purpose , \"device_type\" : sanitized_type , \"material_type\" : sanitized_material , } } logger . info ({ \"event\" : \"device_input_sanitization\" , \"field\" : \"medical_device\" , \"before\" : request . medical_device , \"after\" : sanitized_device , }) # ---------------- Step 3. Persist updated state ---------------- success = manager . update_nested ( session_id , update_payload ) if not success : raise HTTPException ( status_code = status . HTTP_500_INTERNAL_SERVER_ERROR , detail = \"Failed to update session in Redis.\" , ) # ---------------- Step 5. Return structured response ---------------- return DeviceInputResponse ( session_id = session_id , message = \"Device input stored successfully\" , )","title":"update_device_input"},{"location":"api/design_output/design_output/","text":"\ud83e\udde9 Design Output API \u2014 Generate Regulatory Design Artifacts Responsible for compiling, formatting, and delivering structured design-stage outputs throughout the regulatory pipeline. This module converts processed insights into clear, validated, and compliant documentation ready for downstream review. Design Output API Routes This module provides REST API endpoints for generating design outputs in the regulatory AI system. Design outputs are structured reports that transform design input requirements into specific, measurable outputs that demonstrate compliance with medical device regulatory standards. The module handles: - Processing design output requests for selected components - Filtering and validating user-selected design inputs - Integration with the design output processing node using LangGraph - Session-based state management for design output generation - Automatic referencing of relevant ISO/IEC standards - Generation of structured design output reports Key Features: - Selective component processing based on user selection - Comprehensive error handling and logging - Integration with regulatory standards databases - Asynchronous processing for improved performance post_design_output ( session_id , request ) async Generate a structured Design Output Report for selected design inputs in a session. This endpoint processes user-selected design input components and generates comprehensive design outputs that demonstrate compliance with medical device regulatory standards. The system automatically references relevant ISO/IEC standards and creates structured reports suitable for regulatory submissions. Workflow: 1. Retrieves the active session and validates its existence 2. Filters design inputs based on user selection or processes all if none specified 3. Validates that selected components exist in the session 4. Generates design outputs using the LangGraph processing chain 5. Updates session state with generated outputs 6. Returns structured design output response Parameters: Name Type Description Default session_id str Unique identifier for the session containing design inputs required request DesignOutputRequest Request object containing: - selected_components (Optional[List[str]]): List of component names to process. If not provided, all available components will be processed. required Returns: Name Type Description DesignOutputResponse Structured response containing: - session_id (str): The session identifier - output (dict): Generated design output data with detailed specifications, compliance information, and referenced standards Raises: Type Description HTTPException 404 if session is not found 400 if no design inputs found in session 400 if no valid components selected for processing 500 if design output generation fails due to internal errors Example POST /devices/design-output/session123 { \"selected_components\": [\"sensor\", \"actuator\"] } Response: { \"session_id\": \"session123\", \"output\": { \"sensor\": {...}, \"actuator\": {...} } } Note The function processes only user-selected components for targeted output generation All generated outputs automatically reference relevant ISO/IEC standards Session state is persistently updated with generated design outputs Comprehensive logging is provided for debugging and audit purposes Source code in app/api/routes/v1/design_output/design_output.py 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 @router . post ( \"/design-output/ {session_id} \" , response_model = DesignOutputResponse , status_code = status . HTTP_200_OK , ) async def post_design_output ( session_id : str , request : DesignOutputRequest ): \"\"\" Generate a structured Design Output Report for selected design inputs in a session. This endpoint processes user-selected design input components and generates comprehensive design outputs that demonstrate compliance with medical device regulatory standards. The system automatically references relevant ISO/IEC standards and creates structured reports suitable for regulatory submissions. Workflow: 1. Retrieves the active session and validates its existence 2. Filters design inputs based on user selection or processes all if none specified 3. Validates that selected components exist in the session 4. Generates design outputs using the LangGraph processing chain 5. Updates session state with generated outputs 6. Returns structured design output response Args: session_id (str): Unique identifier for the session containing design inputs request (DesignOutputRequest): Request object containing: - selected_components (Optional[List[str]]): List of component names to process. If not provided, all available components will be processed. Returns: DesignOutputResponse: Structured response containing: - session_id (str): The session identifier - output (dict): Generated design output data with detailed specifications, compliance information, and referenced standards Raises: HTTPException: - 404 if session is not found - 400 if no design inputs found in session - 400 if no valid components selected for processing - 500 if design output generation fails due to internal errors Example: POST /devices/design-output/session123 { \"selected_components\": [\"sensor\", \"actuator\"] } Response: { \"session_id\": \"session123\", \"output\": { \"sensor\": {...}, \"actuator\": {...} } } Note: - The function processes only user-selected components for targeted output generation - All generated outputs automatically reference relevant ISO/IEC standards - Session state is persistently updated with generated design outputs - Comprehensive logging is provided for debugging and audit purposes \"\"\" # --- Step 1: Retrieve the active session --- state = session_manager . get_session ( session_id ) if not state : logger . error ( f \"Session ' { session_id } ' not found.\" ) raise HTTPException ( status_code = 404 , detail = \"Session not found\" ) # --- Step 2: Filter only user-selected design inputs --- design_inputs = state . get ( \"design_input\" , {}) if not design_inputs : raise HTTPException ( status_code = 400 , detail = \"No design input found in session\" ) selected_components = request . selected_components or list ( design_inputs . keys ()) filtered_inputs = { comp : design_inputs [ comp ] for comp in selected_components if comp in design_inputs } if not filtered_inputs : raise HTTPException ( status_code = 400 , detail = \"No valid components selected for output generation\" ) # Update session state state [ \"design_input\" ] = filtered_inputs # --- Step 3: Generate design outputs using the LangGraph chain --- try : state = await design_output_node ( state = state ) except Exception as e : logger . exception ( f \"Error generating design output for session ' { session_id } ': { e } \" ) raise HTTPException ( status_code = 500 , detail = \"Design Output generation failed\" ) # --- Step 4: Save updated session --- session_manager . update_session ( session_id , state ) logger . info ( f \"\u2705 Design Output successfully generated for session ' { session_id } '\" ) # --- Step 5: Return structured response --- return DesignOutputResponse ( session_id = session_id , output = state . get ( \"design_output\" , {}), )","title":"Design Output API"},{"location":"api/design_output/design_output/#design-output-api-generate-regulatory-design-artifacts","text":"Responsible for compiling, formatting, and delivering structured design-stage outputs throughout the regulatory pipeline. This module converts processed insights into clear, validated, and compliant documentation ready for downstream review. Design Output API Routes This module provides REST API endpoints for generating design outputs in the regulatory AI system. Design outputs are structured reports that transform design input requirements into specific, measurable outputs that demonstrate compliance with medical device regulatory standards. The module handles: - Processing design output requests for selected components - Filtering and validating user-selected design inputs - Integration with the design output processing node using LangGraph - Session-based state management for design output generation - Automatic referencing of relevant ISO/IEC standards - Generation of structured design output reports Key Features: - Selective component processing based on user selection - Comprehensive error handling and logging - Integration with regulatory standards databases - Asynchronous processing for improved performance","title":"\ud83e\udde9 Design Output API \u2014 Generate Regulatory Design Artifacts"},{"location":"api/design_output/design_output/#app.api.routes.v1.design_output.design_output.post_design_output","text":"Generate a structured Design Output Report for selected design inputs in a session. This endpoint processes user-selected design input components and generates comprehensive design outputs that demonstrate compliance with medical device regulatory standards. The system automatically references relevant ISO/IEC standards and creates structured reports suitable for regulatory submissions. Workflow: 1. Retrieves the active session and validates its existence 2. Filters design inputs based on user selection or processes all if none specified 3. Validates that selected components exist in the session 4. Generates design outputs using the LangGraph processing chain 5. Updates session state with generated outputs 6. Returns structured design output response Parameters: Name Type Description Default session_id str Unique identifier for the session containing design inputs required request DesignOutputRequest Request object containing: - selected_components (Optional[List[str]]): List of component names to process. If not provided, all available components will be processed. required Returns: Name Type Description DesignOutputResponse Structured response containing: - session_id (str): The session identifier - output (dict): Generated design output data with detailed specifications, compliance information, and referenced standards Raises: Type Description HTTPException 404 if session is not found 400 if no design inputs found in session 400 if no valid components selected for processing 500 if design output generation fails due to internal errors Example POST /devices/design-output/session123 { \"selected_components\": [\"sensor\", \"actuator\"] } Response: { \"session_id\": \"session123\", \"output\": { \"sensor\": {...}, \"actuator\": {...} } } Note The function processes only user-selected components for targeted output generation All generated outputs automatically reference relevant ISO/IEC standards Session state is persistently updated with generated design outputs Comprehensive logging is provided for debugging and audit purposes Source code in app/api/routes/v1/design_output/design_output.py 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 @router . post ( \"/design-output/ {session_id} \" , response_model = DesignOutputResponse , status_code = status . HTTP_200_OK , ) async def post_design_output ( session_id : str , request : DesignOutputRequest ): \"\"\" Generate a structured Design Output Report for selected design inputs in a session. This endpoint processes user-selected design input components and generates comprehensive design outputs that demonstrate compliance with medical device regulatory standards. The system automatically references relevant ISO/IEC standards and creates structured reports suitable for regulatory submissions. Workflow: 1. Retrieves the active session and validates its existence 2. Filters design inputs based on user selection or processes all if none specified 3. Validates that selected components exist in the session 4. Generates design outputs using the LangGraph processing chain 5. Updates session state with generated outputs 6. Returns structured design output response Args: session_id (str): Unique identifier for the session containing design inputs request (DesignOutputRequest): Request object containing: - selected_components (Optional[List[str]]): List of component names to process. If not provided, all available components will be processed. Returns: DesignOutputResponse: Structured response containing: - session_id (str): The session identifier - output (dict): Generated design output data with detailed specifications, compliance information, and referenced standards Raises: HTTPException: - 404 if session is not found - 400 if no design inputs found in session - 400 if no valid components selected for processing - 500 if design output generation fails due to internal errors Example: POST /devices/design-output/session123 { \"selected_components\": [\"sensor\", \"actuator\"] } Response: { \"session_id\": \"session123\", \"output\": { \"sensor\": {...}, \"actuator\": {...} } } Note: - The function processes only user-selected components for targeted output generation - All generated outputs automatically reference relevant ISO/IEC standards - Session state is persistently updated with generated design outputs - Comprehensive logging is provided for debugging and audit purposes \"\"\" # --- Step 1: Retrieve the active session --- state = session_manager . get_session ( session_id ) if not state : logger . error ( f \"Session ' { session_id } ' not found.\" ) raise HTTPException ( status_code = 404 , detail = \"Session not found\" ) # --- Step 2: Filter only user-selected design inputs --- design_inputs = state . get ( \"design_input\" , {}) if not design_inputs : raise HTTPException ( status_code = 400 , detail = \"No design input found in session\" ) selected_components = request . selected_components or list ( design_inputs . keys ()) filtered_inputs = { comp : design_inputs [ comp ] for comp in selected_components if comp in design_inputs } if not filtered_inputs : raise HTTPException ( status_code = 400 , detail = \"No valid components selected for output generation\" ) # Update session state state [ \"design_input\" ] = filtered_inputs # --- Step 3: Generate design outputs using the LangGraph chain --- try : state = await design_output_node ( state = state ) except Exception as e : logger . exception ( f \"Error generating design output for session ' { session_id } ': { e } \" ) raise HTTPException ( status_code = 500 , detail = \"Design Output generation failed\" ) # --- Step 4: Save updated session --- session_manager . update_session ( session_id , state ) logger . info ( f \"\u2705 Design Output successfully generated for session ' { session_id } '\" ) # --- Step 5: Return structured response --- return DesignOutputResponse ( session_id = session_id , output = state . get ( \"design_output\" , {}), )","title":"post_design_output"},{"location":"api/design_template/template_api/","text":"\ud83e\udde9 API Reference Welcome to the Regulatory AI API Documentation . Below you\u2019ll find detailed references for all available API endpoints in the design_template module. \ud83d\udca1 Device Suggestions API \u2014 Generate Intelligent Recommendations Generates AI-based suggestions for medical device components, categories, or materials based on existing session data and specifications. Device Suggestions API Routes This module provides an endpoint for retrieving FDA device name suggestions based on user-provided device names and intended purposes. It leverages the FDAAgent service to fetch relevant suggestions for regulatory compliance workflows. Key Features: - Accepts alphanumeric device names and intended purposes as input - Validates input length and format - Integrates with the FDAAgent service for suggestion retrieval - Returns a structured response with suggested device names Security: - Input validation ensures proper formatting and prevents injection attacks - Exception handling for robust error reporting suggest_devices ( device_name = Query ( ... , min_length = 3 , max_length = 50 , pattern = '^[a-zA-Z0-9 ]+$' , description = 'User input for device name search (alphanumeric, 3\u201350 chars)' ), intended_purpose = Query ( ... , min_length = 5 , max_length = 200 , description = 'User input for intended purpose (5\u2013200 chars)' )) async Retrieve FDA device name suggestions based on user input. This endpoint accepts a device name and intended purpose, validates the input, and fetches relevant FDA device name suggestions using the FDAAgent service. Parameters: Name Type Description Default device_name str Alphanumeric device name (3\u201350 characters) Query (..., min_length=3, max_length=50, pattern='^[a-zA-Z0-9 ]+$', description='User input for device name search (alphanumeric, 3\u201350 chars)') intended_purpose str Description of the intended purpose (5\u2013200 characters) Query (..., min_length=5, max_length=200, description='User input for intended purpose (5\u2013200 chars)') Returns: Name Type Description DeviceSuggestionResponse A structured response containing a list of suggested device names relevant to the input criteria. Raises: Type Description HTTPException 500 if the suggestion service encounters an error Example GET /suggest/devices_names?device_name=Pacemaker&intended_purpose=Heart+rhythm+management Response: { \"suggested_devices\": [\"Cardiac Pacemaker\", \"Implantable Pacemaker\"] } Source code in app/api/routes/v1/design_template/device_suggestions.py 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 @router . get ( \"/devices_names\" , summary = \"Get FDA device name suggestions\" , response_model = DeviceSuggestionResponse , name = \"suggest_devices_names\" , ) async def suggest_devices ( device_name : str = Query ( ... , min_length = 3 , max_length = 50 , pattern = \"^[a-zA-Z0-9 ]+$\" , description = \"User input for device name search (alphanumeric, 3\u201350 chars)\" , ), intended_purpose : str = Query ( ... , min_length = 5 , max_length = 200 , description = \"User input for intended purpose (5\u2013200 chars)\" , ), ): \"\"\" Retrieve FDA device name suggestions based on user input. This endpoint accepts a device name and intended purpose, validates the input, and fetches relevant FDA device name suggestions using the FDAAgent service. Args: device_name (str): Alphanumeric device name (3\u201350 characters) intended_purpose (str): Description of the intended purpose (5\u2013200 characters) Returns: DeviceSuggestionResponse: A structured response containing a list of suggested device names relevant to the input criteria. Raises: HTTPException: 500 if the suggestion service encounters an error Example: GET /suggest/devices_names?device_name=Pacemaker&intended_purpose=Heart+rhythm+management Response: { \"suggested_devices\": [\"Cardiac Pacemaker\", \"Implantable Pacemaker\"] } \"\"\" try : # Build request model manually (since GET cannot take JSON body) request = DeviceSuggestionRequest ( device_name = device_name , intended_purpose = intended_purpose , ) suggestions = agent . get_suggestions ( request . device_name , request . intended_purpose ) # \ud83d\udd11 normalize to list[str] if isinstance ( suggestions , dict ): suggested_devices = suggestions . get ( \"relevant_device_names\" , []) else : suggested_devices = getattr ( suggestions , \"relevant_device_names\" , []) return DeviceSuggestionResponse ( suggested_devices = suggested_devices ) except Exception as e : raise HTTPException ( status_code = 500 , detail = f \"Suggestion service error: { str ( e ) } \" ) \ud83d\udc64 Intended User API \u2014 Manage User Profiles Defines user categories, skill levels, and roles associated with device usage. get_intended ( session_id = Path ( ... , description = 'The ID of the session' ), manager = Depends ( get_session_manager )) async Retrieve system-generated intended users for a session. This endpoint fetches the intended users generated by the system for a given session. If no intended users exist, it triggers the intended user node to populate the data. Parameters: Name Type Description Default session_id str The unique identifier for the session. Path (..., description='The ID of the session') manager Dependency-injected session manager for state operations. Depends ( get_session_manager ) Returns: Name Type Description IntendedUserResponse Contains the session ID, list of intended users, and status. Raises: Type Description HTTPException 404 if the session is not found. Example GET /intended-user/{session_id} Response: { \"session_id\": \"session123\", \"intended_users\": [\"Surgeons\", \"Nurses\"], \"status\": \"success\" } Source code in app/api/routes/v1/design_template/intended_user.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 @router . get ( \"/ {session_id} \" , response_model = IntendedUserResponse , summary = \"Get system-generated intended users\" , name = \"get_intended\" , ) async def get_intended ( session_id : str = Path ( ... , description = \"The ID of the session\" ), manager = Depends ( get_session_manager ), ): \"\"\" Retrieve system-generated intended users for a session. This endpoint fetches the intended users generated by the system for a given session. If no intended users exist, it triggers the intended user node to populate the data. Args: session_id (str): The unique identifier for the session. manager: Dependency-injected session manager for state operations. Returns: IntendedUserResponse: Contains the session ID, list of intended users, and status. Raises: HTTPException: 404 if the session is not found. Example: GET /intended-user/{session_id} Response: { \"session_id\": \"session123\", \"intended_users\": [\"Surgeons\", \"Nurses\"], \"status\": \"success\" } \"\"\" state = manager . get_session ( session_id ) if not state : raise HTTPException ( status_code = status . HTTP_404_NOT_FOUND , detail = \"Session not found\" ) update_payload = { \"design_data\" : { \"system_generated\" : { \"intended_users\" : [], } } } manager . update_nested ( session_id , update_payload ) if not state [ \"design_data\" ][ \"system_generated\" ][ \"intended_users\" ]: state = intended_user_node ( state ) manager . update_nested ( session_id , state ) iu = state [ \"design_data\" ][ \"system_generated\" ][ \"intended_users\" ] return IntendedUserResponse ( session_id = session_id , intended_users = iu , status = \"success\" , ) post_intended ( request , session_id = Path ( ... , description = 'The ID of the session' ), manager = Depends ( get_session_manager )) async Update user-confirmed intended users for a session. This endpoint allows users to update the list of intended users for a session. The provided list is merged with the existing user-confirmed intended users. Parameters: Name Type Description Default request IntendedUserUpdateRequest Contains the list of intended users to add. required session_id str The unique identifier for the session. Path (..., description='The ID of the session') manager Dependency-injected session manager for state operations. Depends ( get_session_manager ) Returns: Name Type Description IntendedUserUpdateResponse Contains the session ID and a success message. Raises: Type Description HTTPException 404 if the session is not found. Example POST /intended-user/{session_id} { \"intended_users\": [\"Technicians\"] } Response: { \"session_id\": \"session123\", \"message\": \"Intended users updated successfully.\" } Source code in app/api/routes/v1/design_template/intended_user.py 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 @router . post ( \"/ {session_id} \" , response_model = IntendedUserUpdateResponse , summary = \"Update user-confirmed intended users\" , name = \"post_intended\" , ) async def post_intended ( request : IntendedUserUpdateRequest , session_id : str = Path ( ... , description = \"The ID of the session\" ), manager = Depends ( get_session_manager ), ): \"\"\" Update user-confirmed intended users for a session. This endpoint allows users to update the list of intended users for a session. The provided list is merged with the existing user-confirmed intended users. Args: request (IntendedUserUpdateRequest): Contains the list of intended users to add. session_id (str): The unique identifier for the session. manager: Dependency-injected session manager for state operations. Returns: IntendedUserUpdateResponse: Contains the session ID and a success message. Raises: HTTPException: 404 if the session is not found. Example: POST /intended-user/{session_id} { \"intended_users\": [\"Technicians\"] } Response: { \"session_id\": \"session123\", \"message\": \"Intended users updated successfully.\" } \"\"\" state = manager . get_session ( session_id ) if not state : raise HTTPException ( status_code = status . HTTP_404_NOT_FOUND , detail = \"Session not found\" ) update_payload = { \"design_data\" : { \"user_confirmed\" : { \"intended_users\" : [], } } } manager . update_nested ( session_id , update_payload ) iu = state [ \"design_data\" ][ \"user_confirmed\" ][ \"intended_users\" ] iu = list ( set ( iu + request . intended_users )) state [ \"design_data\" ][ \"user_confirmed\" ][ \"intended_users\" ] = iu manager . update_nested ( session_id , state ) return IntendedUserUpdateResponse ( session_id = session_id , message = \"Intended users updated successfully.\" , ) \ud83e\udde0 Recommender API \u2014 Predict Classifications Provides predictive classification, material, or intended-purpose recommendations based on current device input data. get_component ( session_id = Path ( ... , description = 'The ID of the session' ), manager = Depends ( get_session_manager )) async Retrieve system-generated component recommendations for a session. This endpoint fetches recommended components generated by the system for a given session. If no recommendations exist, it triggers the component recommender node to populate the data. Parameters: Name Type Description Default session_id str The unique identifier for the session. Path (..., description='The ID of the session') manager Dependency-injected session manager for state operations. Depends ( get_session_manager ) Returns: Name Type Description ComponentRecommenderResponse Contains the session ID and a list of recommended components. Raises: Type Description HTTPException 404 if the session is not found, 500 if session update fails. Example GET /recommender/{session_id} Response: { \"session_id\": \"session123\", \"recommended_components\": [\"Sensor\", \"Actuator\"] } Source code in app/api/routes/v1/design_template/recommender.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 @router . get ( \"/ {session_id} \" , response_model = ComponentRecommenderResponse , summary = \"Get system-generated component recommendations\" , name = \"get_component\" , ) async def get_component ( session_id : str = Path ( ... , description = \"The ID of the session\" ), manager = Depends ( get_session_manager ), ): \"\"\" Retrieve system-generated component recommendations for a session. This endpoint fetches recommended components generated by the system for a given session. If no recommendations exist, it triggers the component recommender node to populate the data. Args: session_id (str): The unique identifier for the session. manager: Dependency-injected session manager for state operations. Returns: ComponentRecommenderResponse: Contains the session ID and a list of recommended components. Raises: HTTPException: 404 if the session is not found, 500 if session update fails. Example: GET /recommender/{session_id} Response: { \"session_id\": \"session123\", \"recommended_components\": [\"Sensor\", \"Actuator\"] } \"\"\" state = manager . get_session ( session_id ) if not state : raise HTTPException ( status_code = status . HTTP_404_NOT_FOUND , detail = \"Session not found\" ) # Ensure design_data/system_generated exists update_payload = { \"design_data\" : { \"system_generated\" : { \"components\" : [], }, } } manager . update_nested ( session_id , update_payload ) if not state [ \"design_data\" ][ \"system_generated\" ][ \"components\" ]: state = component_recommender_node ( state ) success = manager . update_session ( session_id , state ) if not success : raise HTTPException ( status_code = status . HTTP_500_INTERNAL_SERVER_ERROR , detail = \"Failed to update session in Redis.\" , ) comps = state [ \"design_data\" ][ \"system_generated\" ][ \"components\" ] return ComponentRecommenderResponse ( session_id = session_id , recommended_components = comps , ) update_component ( request , session_id = Path ( ... , description = 'The ID of the session' ), manager = Depends ( get_session_manager )) async Update user-confirmed component selections for a session. This endpoint allows users to update the list of confirmed components for a session. The provided user-selected and user-added components are merged with the existing list. Parameters: Name Type Description Default request ComponentSelectionRequest Contains user-selected and user-added components. required session_id str The unique identifier for the session. Path (..., description='The ID of the session') manager Dependency-injected session manager for state operations. Depends ( get_session_manager ) Returns: Name Type Description ComponentSelectionResponse Contains the session ID and a success message. Raises: Type Description HTTPException 404 if the session is not found. Example POST /recommender/{session_id} { \"user_selected_components\": [\"Sensor\"], \"user_added_components\": [\"Custom Component\"] } Response: { \"session_id\": \"session123\", \"message\": \"Component selections and additions updated successfully.\" } Source code in app/api/routes/v1/design_template/recommender.py 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 @router . post ( \"/ {session_id} \" , response_model = ComponentSelectionResponse , summary = \"Update user-confirmed component selections\" , name = \"update_component\" , ) async def update_component ( request : ComponentSelectionRequest , session_id : str = Path ( ... , description = \"The ID of the session\" ), manager = Depends ( get_session_manager ), ): \"\"\" Update user-confirmed component selections for a session. This endpoint allows users to update the list of confirmed components for a session. The provided user-selected and user-added components are merged with the existing list. Args: request (ComponentSelectionRequest): Contains user-selected and user-added components. session_id (str): The unique identifier for the session. manager: Dependency-injected session manager for state operations. Returns: ComponentSelectionResponse: Contains the session ID and a success message. Raises: HTTPException: 404 if the session is not found. Example: POST /recommender/{session_id} { \"user_selected_components\": [\"Sensor\"], \"user_added_components\": [\"Custom Component\"] } Response: { \"session_id\": \"session123\", \"message\": \"Component selections and additions updated successfully.\" } \"\"\" state = manager . get_session ( session_id ) if not state : raise HTTPException ( status_code = status . HTTP_404_NOT_FOUND , detail = \"Session not found\" ) update_payload = { \"design_data\" : { \"user_confirmed\" : { \"components\" : [], }, } } manager . update_nested ( session_id , update_payload ) # Add user-selected and user-added components to the confirmed components list confirmed_components = state [ \"design_data\" ][ \"user_confirmed\" ][ \"components\" ] confirmed_components . extend ( request . user_selected_components ) confirmed_components . extend ( request . user_added_components ) state [ \"design_data\" ][ \"user_confirmed\" ][ \"components\" ] = sorted ( confirmed_components ) manager . update_session ( session_id , state ) return ComponentSelectionResponse ( session_id = session_id , message = \"Component selections and additions updated successfully.\" , ) \u26a0\ufe0f Risk Assessment API \u2014 Evaluate Device Risk Analyzes medical device parameters and assigns potential risk categories for compliance documentation. get_risk ( session_id = Path ( ... , description = 'The ID of the session' ), manager = Depends ( get_session_manager )) async Retrieve system-generated risk classification for a session. This endpoint fetches the risk classification generated by the system for a given session. If no classification exists, it triggers the risk classification node to populate the data. Parameters: Name Type Description Default session_id str The unique identifier for the session. Path (..., description='The ID of the session') manager Dependency-injected session manager for state operations. Depends ( get_session_manager ) Returns: Name Type Description RiskClassificationResponse Contains the session ID and the risk classification data. Raises: Type Description HTTPException 404 if the session is not found. Example GET /risk/{session_id} Response: { \"session_id\": \"session123\", \"risk_classification\": { \"classification\": \"Class II\", \"justification\": \"Moderate risk device requiring special controls.\" } } Source code in app/api/routes/v1/design_template/risk.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 @router . get ( \"/ {session_id} \" , response_model = RiskClassificationResponse , summary = \"Get system-generated risk classification\" , name = \"get_risk\" , ) async def get_risk ( session_id : str = Path ( ... , description = \"The ID of the session\" ), manager = Depends ( get_session_manager ), ): \"\"\" Retrieve system-generated risk classification for a session. This endpoint fetches the risk classification generated by the system for a given session. If no classification exists, it triggers the risk classification node to populate the data. Args: session_id (str): The unique identifier for the session. manager: Dependency-injected session manager for state operations. Returns: RiskClassificationResponse: Contains the session ID and the risk classification data. Raises: HTTPException: 404 if the session is not found. Example: GET /risk/{session_id} Response: { \"session_id\": \"session123\", \"risk_classification\": { \"classification\": \"Class II\", \"justification\": \"Moderate risk device requiring special controls.\" } } \"\"\" state = manager . get_session ( session_id ) if not state : raise HTTPException ( status_code = status . HTTP_404_NOT_FOUND , detail = \"Session not found\" ) update_payload = { \"design_data\" : { \"system_generated\" : { \"risk_classification\" : {}, } } } manager . update_nested ( session_id , update_payload ) if not state [ \"design_data\" ][ \"system_generated\" ][ \"risk_classification\" ]: state = risk_classify_node ( state ) manager . update_session ( session_id , state ) rc = state [ \"design_data\" ][ \"system_generated\" ][ \"risk_classification\" ] return RiskClassificationResponse ( session_id = session_id , risk_classification = rc , ) post_risk ( request , session_id = Path ( ... , description = 'The ID of the session' ), manager = Depends ( get_session_manager )) async Update user-confirmed risk classification for a session. This endpoint allows users to update the risk classification for a session. The provided classification data is merged with the existing user-confirmed data. Parameters: Name Type Description Default request RiskClassificationUpdateRequest Contains the updated risk classification data. required session_id str The unique identifier for the session. Path (..., description='The ID of the session') manager Dependency-injected session manager for state operations. Depends ( get_session_manager ) Returns: Name Type Description RiskClassificationUpdateResponse Contains the session ID and a success message. Raises: Type Description HTTPException 404 if the session is not found. Example POST /risk/{session_id} { \"risk_classification\": { \"classification\": \"Class III\", \"justification\": \"High risk device requiring premarket approval.\" } } Response: { \"session_id\": \"session123\", \"message\": \"Risk classifications updated successfully.\" } Source code in app/api/routes/v1/design_template/risk.py 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 @router . post ( \"/ {session_id} \" , response_model = RiskClassificationUpdateResponse , summary = \"Update user-confirmed risk classification\" , name = \"post_risk\" , ) async def post_risk ( request : RiskClassificationUpdateRequest , session_id : str = Path ( ... , description = \"The ID of the session\" ), manager = Depends ( get_session_manager ), ): \"\"\" Update user-confirmed risk classification for a session. This endpoint allows users to update the risk classification for a session. The provided classification data is merged with the existing user-confirmed data. Args: request (RiskClassificationUpdateRequest): Contains the updated risk classification data. session_id (str): The unique identifier for the session. manager: Dependency-injected session manager for state operations. Returns: RiskClassificationUpdateResponse: Contains the session ID and a success message. Raises: HTTPException: 404 if the session is not found. Example: POST /risk/{session_id} { \"risk_classification\": { \"classification\": \"Class III\", \"justification\": \"High risk device requiring premarket approval.\" } } Response: { \"session_id\": \"session123\", \"message\": \"Risk classifications updated successfully.\" } \"\"\" state = manager . get_session ( session_id ) if not state : raise HTTPException ( status_code = status . HTTP_404_NOT_FOUND , detail = \"Session not found\" ) update_payload = { \"design_data\" : { \"user_confirmed\" : { \"risk_classification\" : {}, } } } manager . update_nested ( session_id , update_payload ) state [ \"design_data\" ][ \"user_confirmed\" ][ \"risk_classification\" ] . update ( request . risk_classification ) manager . update_session ( session_id , state ) return RiskClassificationUpdateResponse ( session_id = session_id , message = \"Risk classifications updated successfully.\" , )","title":"Design Template API"},{"location":"api/design_template/template_api/#api-reference","text":"Welcome to the Regulatory AI API Documentation . Below you\u2019ll find detailed references for all available API endpoints in the design_template module.","title":"\ud83e\udde9 API Reference"},{"location":"api/design_template/template_api/#device-suggestions-api-generate-intelligent-recommendations","text":"Generates AI-based suggestions for medical device components, categories, or materials based on existing session data and specifications. Device Suggestions API Routes This module provides an endpoint for retrieving FDA device name suggestions based on user-provided device names and intended purposes. It leverages the FDAAgent service to fetch relevant suggestions for regulatory compliance workflows. Key Features: - Accepts alphanumeric device names and intended purposes as input - Validates input length and format - Integrates with the FDAAgent service for suggestion retrieval - Returns a structured response with suggested device names Security: - Input validation ensures proper formatting and prevents injection attacks - Exception handling for robust error reporting","title":"\ud83d\udca1 Device Suggestions API \u2014 Generate Intelligent Recommendations"},{"location":"api/design_template/template_api/#app.api.routes.v1.design_template.device_suggestions.suggest_devices","text":"Retrieve FDA device name suggestions based on user input. This endpoint accepts a device name and intended purpose, validates the input, and fetches relevant FDA device name suggestions using the FDAAgent service. Parameters: Name Type Description Default device_name str Alphanumeric device name (3\u201350 characters) Query (..., min_length=3, max_length=50, pattern='^[a-zA-Z0-9 ]+$', description='User input for device name search (alphanumeric, 3\u201350 chars)') intended_purpose str Description of the intended purpose (5\u2013200 characters) Query (..., min_length=5, max_length=200, description='User input for intended purpose (5\u2013200 chars)') Returns: Name Type Description DeviceSuggestionResponse A structured response containing a list of suggested device names relevant to the input criteria. Raises: Type Description HTTPException 500 if the suggestion service encounters an error Example GET /suggest/devices_names?device_name=Pacemaker&intended_purpose=Heart+rhythm+management Response: { \"suggested_devices\": [\"Cardiac Pacemaker\", \"Implantable Pacemaker\"] } Source code in app/api/routes/v1/design_template/device_suggestions.py 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 @router . get ( \"/devices_names\" , summary = \"Get FDA device name suggestions\" , response_model = DeviceSuggestionResponse , name = \"suggest_devices_names\" , ) async def suggest_devices ( device_name : str = Query ( ... , min_length = 3 , max_length = 50 , pattern = \"^[a-zA-Z0-9 ]+$\" , description = \"User input for device name search (alphanumeric, 3\u201350 chars)\" , ), intended_purpose : str = Query ( ... , min_length = 5 , max_length = 200 , description = \"User input for intended purpose (5\u2013200 chars)\" , ), ): \"\"\" Retrieve FDA device name suggestions based on user input. This endpoint accepts a device name and intended purpose, validates the input, and fetches relevant FDA device name suggestions using the FDAAgent service. Args: device_name (str): Alphanumeric device name (3\u201350 characters) intended_purpose (str): Description of the intended purpose (5\u2013200 characters) Returns: DeviceSuggestionResponse: A structured response containing a list of suggested device names relevant to the input criteria. Raises: HTTPException: 500 if the suggestion service encounters an error Example: GET /suggest/devices_names?device_name=Pacemaker&intended_purpose=Heart+rhythm+management Response: { \"suggested_devices\": [\"Cardiac Pacemaker\", \"Implantable Pacemaker\"] } \"\"\" try : # Build request model manually (since GET cannot take JSON body) request = DeviceSuggestionRequest ( device_name = device_name , intended_purpose = intended_purpose , ) suggestions = agent . get_suggestions ( request . device_name , request . intended_purpose ) # \ud83d\udd11 normalize to list[str] if isinstance ( suggestions , dict ): suggested_devices = suggestions . get ( \"relevant_device_names\" , []) else : suggested_devices = getattr ( suggestions , \"relevant_device_names\" , []) return DeviceSuggestionResponse ( suggested_devices = suggested_devices ) except Exception as e : raise HTTPException ( status_code = 500 , detail = f \"Suggestion service error: { str ( e ) } \" )","title":"suggest_devices"},{"location":"api/design_template/template_api/#intended-user-api-manage-user-profiles","text":"Defines user categories, skill levels, and roles associated with device usage.","title":"\ud83d\udc64 Intended User API \u2014 Manage User Profiles"},{"location":"api/design_template/template_api/#app.api.routes.v1.design_template.intended_user.get_intended","text":"Retrieve system-generated intended users for a session. This endpoint fetches the intended users generated by the system for a given session. If no intended users exist, it triggers the intended user node to populate the data. Parameters: Name Type Description Default session_id str The unique identifier for the session. Path (..., description='The ID of the session') manager Dependency-injected session manager for state operations. Depends ( get_session_manager ) Returns: Name Type Description IntendedUserResponse Contains the session ID, list of intended users, and status. Raises: Type Description HTTPException 404 if the session is not found. Example GET /intended-user/{session_id} Response: { \"session_id\": \"session123\", \"intended_users\": [\"Surgeons\", \"Nurses\"], \"status\": \"success\" } Source code in app/api/routes/v1/design_template/intended_user.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 @router . get ( \"/ {session_id} \" , response_model = IntendedUserResponse , summary = \"Get system-generated intended users\" , name = \"get_intended\" , ) async def get_intended ( session_id : str = Path ( ... , description = \"The ID of the session\" ), manager = Depends ( get_session_manager ), ): \"\"\" Retrieve system-generated intended users for a session. This endpoint fetches the intended users generated by the system for a given session. If no intended users exist, it triggers the intended user node to populate the data. Args: session_id (str): The unique identifier for the session. manager: Dependency-injected session manager for state operations. Returns: IntendedUserResponse: Contains the session ID, list of intended users, and status. Raises: HTTPException: 404 if the session is not found. Example: GET /intended-user/{session_id} Response: { \"session_id\": \"session123\", \"intended_users\": [\"Surgeons\", \"Nurses\"], \"status\": \"success\" } \"\"\" state = manager . get_session ( session_id ) if not state : raise HTTPException ( status_code = status . HTTP_404_NOT_FOUND , detail = \"Session not found\" ) update_payload = { \"design_data\" : { \"system_generated\" : { \"intended_users\" : [], } } } manager . update_nested ( session_id , update_payload ) if not state [ \"design_data\" ][ \"system_generated\" ][ \"intended_users\" ]: state = intended_user_node ( state ) manager . update_nested ( session_id , state ) iu = state [ \"design_data\" ][ \"system_generated\" ][ \"intended_users\" ] return IntendedUserResponse ( session_id = session_id , intended_users = iu , status = \"success\" , )","title":"get_intended"},{"location":"api/design_template/template_api/#app.api.routes.v1.design_template.intended_user.post_intended","text":"Update user-confirmed intended users for a session. This endpoint allows users to update the list of intended users for a session. The provided list is merged with the existing user-confirmed intended users. Parameters: Name Type Description Default request IntendedUserUpdateRequest Contains the list of intended users to add. required session_id str The unique identifier for the session. Path (..., description='The ID of the session') manager Dependency-injected session manager for state operations. Depends ( get_session_manager ) Returns: Name Type Description IntendedUserUpdateResponse Contains the session ID and a success message. Raises: Type Description HTTPException 404 if the session is not found. Example POST /intended-user/{session_id} { \"intended_users\": [\"Technicians\"] } Response: { \"session_id\": \"session123\", \"message\": \"Intended users updated successfully.\" } Source code in app/api/routes/v1/design_template/intended_user.py 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 @router . post ( \"/ {session_id} \" , response_model = IntendedUserUpdateResponse , summary = \"Update user-confirmed intended users\" , name = \"post_intended\" , ) async def post_intended ( request : IntendedUserUpdateRequest , session_id : str = Path ( ... , description = \"The ID of the session\" ), manager = Depends ( get_session_manager ), ): \"\"\" Update user-confirmed intended users for a session. This endpoint allows users to update the list of intended users for a session. The provided list is merged with the existing user-confirmed intended users. Args: request (IntendedUserUpdateRequest): Contains the list of intended users to add. session_id (str): The unique identifier for the session. manager: Dependency-injected session manager for state operations. Returns: IntendedUserUpdateResponse: Contains the session ID and a success message. Raises: HTTPException: 404 if the session is not found. Example: POST /intended-user/{session_id} { \"intended_users\": [\"Technicians\"] } Response: { \"session_id\": \"session123\", \"message\": \"Intended users updated successfully.\" } \"\"\" state = manager . get_session ( session_id ) if not state : raise HTTPException ( status_code = status . HTTP_404_NOT_FOUND , detail = \"Session not found\" ) update_payload = { \"design_data\" : { \"user_confirmed\" : { \"intended_users\" : [], } } } manager . update_nested ( session_id , update_payload ) iu = state [ \"design_data\" ][ \"user_confirmed\" ][ \"intended_users\" ] iu = list ( set ( iu + request . intended_users )) state [ \"design_data\" ][ \"user_confirmed\" ][ \"intended_users\" ] = iu manager . update_nested ( session_id , state ) return IntendedUserUpdateResponse ( session_id = session_id , message = \"Intended users updated successfully.\" , )","title":"post_intended"},{"location":"api/design_template/template_api/#recommender-api-predict-classifications","text":"Provides predictive classification, material, or intended-purpose recommendations based on current device input data.","title":"\ud83e\udde0 Recommender API \u2014 Predict Classifications"},{"location":"api/design_template/template_api/#app.api.routes.v1.design_template.recommender.get_component","text":"Retrieve system-generated component recommendations for a session. This endpoint fetches recommended components generated by the system for a given session. If no recommendations exist, it triggers the component recommender node to populate the data. Parameters: Name Type Description Default session_id str The unique identifier for the session. Path (..., description='The ID of the session') manager Dependency-injected session manager for state operations. Depends ( get_session_manager ) Returns: Name Type Description ComponentRecommenderResponse Contains the session ID and a list of recommended components. Raises: Type Description HTTPException 404 if the session is not found, 500 if session update fails. Example GET /recommender/{session_id} Response: { \"session_id\": \"session123\", \"recommended_components\": [\"Sensor\", \"Actuator\"] } Source code in app/api/routes/v1/design_template/recommender.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 @router . get ( \"/ {session_id} \" , response_model = ComponentRecommenderResponse , summary = \"Get system-generated component recommendations\" , name = \"get_component\" , ) async def get_component ( session_id : str = Path ( ... , description = \"The ID of the session\" ), manager = Depends ( get_session_manager ), ): \"\"\" Retrieve system-generated component recommendations for a session. This endpoint fetches recommended components generated by the system for a given session. If no recommendations exist, it triggers the component recommender node to populate the data. Args: session_id (str): The unique identifier for the session. manager: Dependency-injected session manager for state operations. Returns: ComponentRecommenderResponse: Contains the session ID and a list of recommended components. Raises: HTTPException: 404 if the session is not found, 500 if session update fails. Example: GET /recommender/{session_id} Response: { \"session_id\": \"session123\", \"recommended_components\": [\"Sensor\", \"Actuator\"] } \"\"\" state = manager . get_session ( session_id ) if not state : raise HTTPException ( status_code = status . HTTP_404_NOT_FOUND , detail = \"Session not found\" ) # Ensure design_data/system_generated exists update_payload = { \"design_data\" : { \"system_generated\" : { \"components\" : [], }, } } manager . update_nested ( session_id , update_payload ) if not state [ \"design_data\" ][ \"system_generated\" ][ \"components\" ]: state = component_recommender_node ( state ) success = manager . update_session ( session_id , state ) if not success : raise HTTPException ( status_code = status . HTTP_500_INTERNAL_SERVER_ERROR , detail = \"Failed to update session in Redis.\" , ) comps = state [ \"design_data\" ][ \"system_generated\" ][ \"components\" ] return ComponentRecommenderResponse ( session_id = session_id , recommended_components = comps , )","title":"get_component"},{"location":"api/design_template/template_api/#app.api.routes.v1.design_template.recommender.update_component","text":"Update user-confirmed component selections for a session. This endpoint allows users to update the list of confirmed components for a session. The provided user-selected and user-added components are merged with the existing list. Parameters: Name Type Description Default request ComponentSelectionRequest Contains user-selected and user-added components. required session_id str The unique identifier for the session. Path (..., description='The ID of the session') manager Dependency-injected session manager for state operations. Depends ( get_session_manager ) Returns: Name Type Description ComponentSelectionResponse Contains the session ID and a success message. Raises: Type Description HTTPException 404 if the session is not found. Example POST /recommender/{session_id} { \"user_selected_components\": [\"Sensor\"], \"user_added_components\": [\"Custom Component\"] } Response: { \"session_id\": \"session123\", \"message\": \"Component selections and additions updated successfully.\" } Source code in app/api/routes/v1/design_template/recommender.py 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 @router . post ( \"/ {session_id} \" , response_model = ComponentSelectionResponse , summary = \"Update user-confirmed component selections\" , name = \"update_component\" , ) async def update_component ( request : ComponentSelectionRequest , session_id : str = Path ( ... , description = \"The ID of the session\" ), manager = Depends ( get_session_manager ), ): \"\"\" Update user-confirmed component selections for a session. This endpoint allows users to update the list of confirmed components for a session. The provided user-selected and user-added components are merged with the existing list. Args: request (ComponentSelectionRequest): Contains user-selected and user-added components. session_id (str): The unique identifier for the session. manager: Dependency-injected session manager for state operations. Returns: ComponentSelectionResponse: Contains the session ID and a success message. Raises: HTTPException: 404 if the session is not found. Example: POST /recommender/{session_id} { \"user_selected_components\": [\"Sensor\"], \"user_added_components\": [\"Custom Component\"] } Response: { \"session_id\": \"session123\", \"message\": \"Component selections and additions updated successfully.\" } \"\"\" state = manager . get_session ( session_id ) if not state : raise HTTPException ( status_code = status . HTTP_404_NOT_FOUND , detail = \"Session not found\" ) update_payload = { \"design_data\" : { \"user_confirmed\" : { \"components\" : [], }, } } manager . update_nested ( session_id , update_payload ) # Add user-selected and user-added components to the confirmed components list confirmed_components = state [ \"design_data\" ][ \"user_confirmed\" ][ \"components\" ] confirmed_components . extend ( request . user_selected_components ) confirmed_components . extend ( request . user_added_components ) state [ \"design_data\" ][ \"user_confirmed\" ][ \"components\" ] = sorted ( confirmed_components ) manager . update_session ( session_id , state ) return ComponentSelectionResponse ( session_id = session_id , message = \"Component selections and additions updated successfully.\" , )","title":"update_component"},{"location":"api/design_template/template_api/#risk-assessment-api-evaluate-device-risk","text":"Analyzes medical device parameters and assigns potential risk categories for compliance documentation.","title":"\u26a0\ufe0f Risk Assessment API \u2014 Evaluate Device Risk"},{"location":"api/design_template/template_api/#app.api.routes.v1.design_template.risk.get_risk","text":"Retrieve system-generated risk classification for a session. This endpoint fetches the risk classification generated by the system for a given session. If no classification exists, it triggers the risk classification node to populate the data. Parameters: Name Type Description Default session_id str The unique identifier for the session. Path (..., description='The ID of the session') manager Dependency-injected session manager for state operations. Depends ( get_session_manager ) Returns: Name Type Description RiskClassificationResponse Contains the session ID and the risk classification data. Raises: Type Description HTTPException 404 if the session is not found. Example GET /risk/{session_id} Response: { \"session_id\": \"session123\", \"risk_classification\": { \"classification\": \"Class II\", \"justification\": \"Moderate risk device requiring special controls.\" } } Source code in app/api/routes/v1/design_template/risk.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 @router . get ( \"/ {session_id} \" , response_model = RiskClassificationResponse , summary = \"Get system-generated risk classification\" , name = \"get_risk\" , ) async def get_risk ( session_id : str = Path ( ... , description = \"The ID of the session\" ), manager = Depends ( get_session_manager ), ): \"\"\" Retrieve system-generated risk classification for a session. This endpoint fetches the risk classification generated by the system for a given session. If no classification exists, it triggers the risk classification node to populate the data. Args: session_id (str): The unique identifier for the session. manager: Dependency-injected session manager for state operations. Returns: RiskClassificationResponse: Contains the session ID and the risk classification data. Raises: HTTPException: 404 if the session is not found. Example: GET /risk/{session_id} Response: { \"session_id\": \"session123\", \"risk_classification\": { \"classification\": \"Class II\", \"justification\": \"Moderate risk device requiring special controls.\" } } \"\"\" state = manager . get_session ( session_id ) if not state : raise HTTPException ( status_code = status . HTTP_404_NOT_FOUND , detail = \"Session not found\" ) update_payload = { \"design_data\" : { \"system_generated\" : { \"risk_classification\" : {}, } } } manager . update_nested ( session_id , update_payload ) if not state [ \"design_data\" ][ \"system_generated\" ][ \"risk_classification\" ]: state = risk_classify_node ( state ) manager . update_session ( session_id , state ) rc = state [ \"design_data\" ][ \"system_generated\" ][ \"risk_classification\" ] return RiskClassificationResponse ( session_id = session_id , risk_classification = rc , )","title":"get_risk"},{"location":"api/design_template/template_api/#app.api.routes.v1.design_template.risk.post_risk","text":"Update user-confirmed risk classification for a session. This endpoint allows users to update the risk classification for a session. The provided classification data is merged with the existing user-confirmed data. Parameters: Name Type Description Default request RiskClassificationUpdateRequest Contains the updated risk classification data. required session_id str The unique identifier for the session. Path (..., description='The ID of the session') manager Dependency-injected session manager for state operations. Depends ( get_session_manager ) Returns: Name Type Description RiskClassificationUpdateResponse Contains the session ID and a success message. Raises: Type Description HTTPException 404 if the session is not found. Example POST /risk/{session_id} { \"risk_classification\": { \"classification\": \"Class III\", \"justification\": \"High risk device requiring premarket approval.\" } } Response: { \"session_id\": \"session123\", \"message\": \"Risk classifications updated successfully.\" } Source code in app/api/routes/v1/design_template/risk.py 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 @router . post ( \"/ {session_id} \" , response_model = RiskClassificationUpdateResponse , summary = \"Update user-confirmed risk classification\" , name = \"post_risk\" , ) async def post_risk ( request : RiskClassificationUpdateRequest , session_id : str = Path ( ... , description = \"The ID of the session\" ), manager = Depends ( get_session_manager ), ): \"\"\" Update user-confirmed risk classification for a session. This endpoint allows users to update the risk classification for a session. The provided classification data is merged with the existing user-confirmed data. Args: request (RiskClassificationUpdateRequest): Contains the updated risk classification data. session_id (str): The unique identifier for the session. manager: Dependency-injected session manager for state operations. Returns: RiskClassificationUpdateResponse: Contains the session ID and a success message. Raises: HTTPException: 404 if the session is not found. Example: POST /risk/{session_id} { \"risk_classification\": { \"classification\": \"Class III\", \"justification\": \"High risk device requiring premarket approval.\" } } Response: { \"session_id\": \"session123\", \"message\": \"Risk classifications updated successfully.\" } \"\"\" state = manager . get_session ( session_id ) if not state : raise HTTPException ( status_code = status . HTTP_404_NOT_FOUND , detail = \"Session not found\" ) update_payload = { \"design_data\" : { \"user_confirmed\" : { \"risk_classification\" : {}, } } } manager . update_nested ( session_id , update_payload ) state [ \"design_data\" ][ \"user_confirmed\" ][ \"risk_classification\" ] . update ( request . risk_classification ) manager . update_session ( session_id , state ) return RiskClassificationUpdateResponse ( session_id = session_id , message = \"Risk classifications updated successfully.\" , )","title":"post_risk"},{"location":"api/gspr_table/gspr_table_api/","text":"\u2699\ufe0f GSPR API Reference The GSPR (General Safety and Performance Requirements) APIs handle automated document generation, real-time job tracking, and streaming updates within the Regulatory AI system. Each endpoint below is designed for seamless integration with the design-template workflows. \ud83e\uddfe GSPR Generate API \u2014 Create Compliance Tables Generates structured GSPR compliance tables based on device data, intended purpose, and regulatory mappings. This endpoint initiates the document generation workflow and returns a job reference ID. generate_gspr_table ( background_tasks , session_id = Path ( ... , description = 'The unique session ID from Redis' ), component = Query ( None , description = 'Single component to generate sections for (must be user-confirmed).' ), session_manager = Depends ( get_session_manager ), job_manager = Depends ( get_job_manager )) async Start a mock GSPR table generation job for a specific user-confirmed component. Overview This endpoint is responsible for initiating a simulated GSPR generation process for one component at a time. It performs multiple validation steps to ensure that the session is active and that the requested component exists within the user's confirmed components list stored in Redis ( design_data.user_confirmed.components ). Once validated, the endpoint: 1. Loads GSPR mapping data ( grouped_sections.json ) from MongoDB. 2. Creates a unique background job entry using the Job Manager. 3. Triggers an asynchronous background task to simulate GSPR generation. 4. Returns job metadata immediately to the client. Parameters session_id ( str ): Unique identifier for the user session stored in Redis. component ( Optional[str] ): The specific component to process. Must exist in the user\u2019s confirmed components list. Example: ?component=PowerModule background_tasks ( BackgroundTasks ): FastAPI background task manager for non-blocking job execution. session_manager ( SessionManager ): Dependency that interfaces with the Redis-based session state. job_manager ( JobManager ): Dependency responsible for job creation, progress updates, and event publishing. Validation Raises 404 if the session ID is not found in Redis. Raises 400 if no component is provided. Raises 400 if the component is not in the confirmed components list. Returns JSON response with: - message : Status message confirming job creation. - job_id : Unique identifier of the spawned background job. - component : The component being processed. - stream_url : SSE endpoint for listening to progress updates. Example Request POST /api/v1/gspr/generate/abc123?component=ECG_Module Example Response { \"message\": \"GSPR generation started successfully for component ECG_Module in session id abc123\", \"job_id\": \"2b1c4e8d-fb29-4b97-9b4e-cc8d3b42e76e\", \"component\": \"ECG_Module\", \"stream_url\": \"/api/v1/gspr/stream/2b1c4e8d-fb29-4b97-9b4e-cc8d3b42e76e\" } Source code in app/api/routes/v1/gspr_table/gspr_generate_router.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 @router . post ( path = \"/generate/ {session_id} \" , summary = \"Start a new GSPR generation job\" , status_code = status . HTTP_202_ACCEPTED , description = \"\"\" Create a new background job for GSPR (General Safety and Performance Requirements) table generation. This endpoint validates the provided session and ensures the specified component is one of the user's confirmed components (stored in Redis). Once validated, it spawns a background worker to simulate asynchronous GSPR table generation and immediately returns job metadata, including a stream URL for progress updates (SSE). \"\"\" , name = \"Start GSPR Generation Job\" , ) async def generate_gspr_table ( background_tasks : BackgroundTasks , session_id : str = Path ( ... , description = \"The unique session ID from Redis\" ), component : Optional [ str ] = Query ( None , description = \"Single component to generate sections for (must be user-confirmed).\" ), session_manager : SessionManager = Depends ( get_session_manager ), job_manager : JobManager = Depends ( get_job_manager ), ): \"\"\" Start a mock GSPR table generation job for a specific user-confirmed component. ### Overview This endpoint is responsible for initiating a simulated GSPR generation process for one component at a time. It performs multiple validation steps to ensure that the session is active and that the requested component exists within the user's confirmed components list stored in Redis (`design_data.user_confirmed.components`). Once validated, the endpoint: 1. Loads GSPR mapping data (`grouped_sections.json`) from MongoDB. 2. Creates a unique background job entry using the Job Manager. 3. Triggers an asynchronous background task to simulate GSPR generation. 4. Returns job metadata immediately to the client. ### Parameters - **session_id** (`str`): Unique identifier for the user session stored in Redis. - **component** (`Optional[str]`): The specific component to process. Must exist in the user\u2019s confirmed components list. Example: `?component=PowerModule` - **background_tasks** (`BackgroundTasks`): FastAPI background task manager for non-blocking job execution. - **session_manager** (`SessionManager`): Dependency that interfaces with the Redis-based session state. - **job_manager** (`JobManager`): Dependency responsible for job creation, progress updates, and event publishing. ### Validation - Raises `404` if the session ID is not found in Redis. - Raises `400` if no component is provided. - Raises `400` if the component is not in the confirmed components list. ### Returns JSON response with: - `message`: Status message confirming job creation. - `job_id`: Unique identifier of the spawned background job. - `component`: The component being processed. - `stream_url`: SSE endpoint for listening to progress updates. ### Example Request ```bash POST /api/v1/gspr/generate/abc123?component=ECG_Module ``` ### Example Response ```json { \"message\": \"GSPR generation started successfully for component ECG_Module in session id abc123\", \"job_id\": \"2b1c4e8d-fb29-4b97-9b4e-cc8d3b42e76e\", \"component\": \"ECG_Module\", \"stream_url\": \"/api/v1/gspr/stream/2b1c4e8d-fb29-4b97-9b4e-cc8d3b42e76e\" } ``` \"\"\" logger . info ( f \"[API] Incoming GSPR generation request | session_id= { session_id } , component= { component } \" ) # Validate session exists state : Optional [ dict ] = session_manager . get_session ( session_id ) if not state : logger . warning ( f \"[API] Session not found in Redis | session_id= { session_id } \" ) raise HTTPException ( status_code = status . HTTP_404_NOT_FOUND , detail = f \"Session { session_id } not found in Redis.\" , ) # Extract confirmed components confirmed_components : list [ str ] = state . get ( \"design_data\" , {}) . get ( \"user_confirmed\" , {}) . get ( \"components\" , []) logger . debug ( f \"[API] Confirmed components retrieved from session | session_id= { session_id } , confirmed= { confirmed_components } \" ) # Require a specific component if not component : logger . error ( f \"[API] No component provided in request | session_id= { session_id } \" ) raise HTTPException ( status_code = status . HTTP_400_BAD_REQUEST , detail = \"No component specified. Please provide ?component=<component_name>.\" , ) # Validate against confirmed components if component not in confirmed_components : logger . error ( f \"[API] Component not found in confirmed list | session_id= { session_id } , component= { component } \" ) raise HTTPException ( status_code = status . HTTP_400_BAD_REQUEST , detail = { \"message\" : f \"Component ' { component } ' not found in user's confirmed list.\" , \"confirmed_components\" : confirmed_components , }, ) # Create a new job ID job_id = str ( uuid4 ()) # Fetch grouped sections from MongoDB collection gspr_mapping try : requirement_sections = mongo_db . load_json_asset ( \"grouped_sections.json\" , collection_name = \"gspr_mapping\" ) logger . info ( f \"[API] Loaded grouped_sections from MongoDB | collection=gspr_mapping, count= { len ( requirement_sections ) } \" ) except ValueError as e : logger . error ( f \"[API] Failed to load grouped_sections | error= { str ( e ) } \" ) raise HTTPException ( status_code = status . HTTP_400_BAD_REQUEST , detail = str ( e )) total_sections = sum ( len ( sections ) for sections in requirement_sections . values ()) # Create a new job ID job_id = str ( uuid4 ()) job_manager . create_job ( job_id , total_sections ) print ( f \"[API] Created job { job_id } with { total_sections } sections for session { session_id } \" ) logger . info ( f \"[API] Created new GSPR job | job_id= { job_id } , session_id= { session_id } , component= { component } , total_sections= { total_sections } \" ) # Launch async background generation all_sections = [] for req_type , sections in requirement_sections . items (): for section in sections : section [ \"requirement_type\" ] = req_type all_sections . append ( section ) background_tasks . add_task ( run_gspr_table_generation , component , session_id , job_id , requirement_sections , all_sections , ) logger . info ( f \"[API] Background GSPR generation task scheduled | job_id= { job_id } \" ) del requirement_sections # free memory del total_sections # free memory del state # free memory return { \"message\" : f \"GSPR generation started successfully for component { component } in session id { session_id } \" , \"job_id\" : job_id , \"component\" : component , \"stream_url\" : f \"/api/v1/gspr/stream/ { job_id } \" , } run_gspr_table_generation ( component , session_id , job_id , requirement_sections , all_sections ) async Asynchronously generates a GSPR table using the GSPRGraphRunner for production. This function processes all sections through the LangGraph workflow, using the GSPRGraphRunner to orchestrate AI-powered analysis of regulatory compliance requirements. Parameters: Name Type Description Default component_name str Name of the medical device component required session_id str Unique identifier for the user session required job_id str Unique identifier for the background job required all_sections list [ dict ] List of all section dictionaries to process required Source code in app/api/routes/v1/gspr_table/gspr_generate_router.py 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 async def run_gspr_table_generation ( component : str , session_id : str , job_id : str , requirement_sections : dict , all_sections : list [ dict ], ): \"\"\" Asynchronously generates a GSPR table using the GSPRGraphRunner for production. This function processes all sections through the LangGraph workflow, using the GSPRGraphRunner to orchestrate AI-powered analysis of regulatory compliance requirements. Args: component_name (str): Name of the medical device component session_id (str): Unique identifier for the user session job_id (str): Unique identifier for the background job all_sections (list[dict]): List of all section dictionaries to process \"\"\" session_manager : SessionManager = get_session_manager () job_manager : JobManager = get_job_manager () print ( f \"[Worker] Job { job_id } started at { time . ctime () } for session { session_id } for component { component } \" ) logger . info ( f \"[Worker] Starting GSPR generation job | job_id= { job_id } , session_id= { session_id } , component= { component } \" ) try : # Initialize the GSPRGraphRunner logger . info ( f \"[Worker] Initializing GSPRGraphRunner for job { job_id } ...\" ) runner = GSPRGraphRunner ( session_id = session_id , job_id = job_id , component_name = component , requirement_sections = requirement_sections , ) logger . info ( f \"[Worker] GSPRGraphRunner initialized, starting workflow for job { job_id } ...\" ) # Run the production workflow result = await runner . run_all_sections ( sections = all_sections ) logger . info ( f \"[Worker] Workflow completed for job { job_id } , success: { result . get ( 'success' , False ) } \" ) if result [ \"success\" ]: job_manager . mark_completed ( job_id ) logger . info ( f \"[Worker] Job { job_id } completed successfully at { time . ctime () } \" ) # Update Redis session with generated results session_manager . update_nested ( session_id , { \"gspr_results\" : { \"job_id\" : job_id , \"status\" : \"completed\" , \"total_sections\" : len ( all_sections ), \"failed_sections\" : 0 , \"sections\" : result [ \"results\" ], \"component_name\" : component , } }, ) else : job_manager . mark_completed ( job_id , failed = True ) logger . error ( f \"[Worker] Job { job_id } failed at { time . ctime () } : { result . get ( 'error' , 'Unknown error' ) } \" ) # Update session with error info session_manager . update_nested ( session_id , { \"gspr_results\" : { \"job_id\" : job_id , \"status\" : \"failed\" , \"error\" : result . get ( \"error\" , \"Unknown error\" ), \"component_name\" : component , } }, ) except Exception as e : logger . error ( f \"[Worker] Unexpected error in job { job_id } : { e } \" ) job_manager . mark_completed ( job_id , failed = True ) # Update session with error info session_manager . update_nested ( session_id , { \"gspr_results\" : { \"job_id\" : job_id , \"status\" : \"failed\" , \"error\" : str ( e ), \"component_name\" : component , } }, ) # Clean up memory del all_sections \ud83d\udcca GSPR Job Status API \u2014 Monitor Generation Progress Tracks the status of ongoing or completed GSPR generation jobs . Useful for polling job states, retrieving metadata, or confirming successful completion of background processes. get_job_status ( job_id = Path ( ... , description = 'Job ID to retrieve status for' ), job_manager = Depends ( get_job_manager )) Fetch the current job progress snapshot from Redis. Data source job:{job_id}:progress (Redis JSON key) Returns: Type Description completed, failed, pending counts percent progress status (running/completed/failed) timestamps (started_at, finished_at) Source code in app/api/routes/v1/gspr_table/gspr_job_status_router.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 @router . get ( path = \"/job/ {job_id} /status\" , summary = \"Get current job progress snapshot\" , status_code = status . HTTP_200_OK , response_description = \"Current job progress state stored in Redis.\" , ) def get_job_status ( job_id : str = Path ( ... , description = \"Job ID to retrieve status for\" ), job_manager : JobManager = Depends ( get_job_manager ), ): \"\"\" Fetch the current job progress snapshot from Redis. Data source: - job:{job_id}:progress (Redis JSON key) Returns: - completed, failed, pending counts - percent progress - status (running/completed/failed) - timestamps (started_at, finished_at) \"\"\" progress = job_manager . get_progress ( job_id ) if not progress : raise HTTPException ( status_code = status . HTTP_404_NOT_FOUND , detail = f \"Job { job_id } not found or expired in Redis.\" , ) return { \"job_id\" : job_id , \"status\" : progress . get ( \"status\" ), \"completed\" : progress . get ( \"completed\" ), \"failed\" : progress . get ( \"failed\" ), \"pending\" : progress . get ( \"pending\" ), \"percent\" : progress . get ( \"percent\" ), \"started_at\" : progress . get ( \"started_at\" ), \"finished_at\" : progress . get ( \"finished_at\" ), \"total_time\" : progress . get ( \"total_time\" ), } \ud83d\udd04 GSPR Stream API \u2014 Real-Time Updates Streams live progress updates and events for long-running GSPR table generation tasks. Ideal for dashboards or clients requiring real-time feedback on document creation pipelines. stream_job ( request , job_id = Path ( ... , description = 'Job ID to stream events for' ), redis = Depends ( lambda : get_redis ( async_mode = True ))) async Server-Sent Events (SSE) endpoint that streams live progress updates for a given GSPR generation job. Data Flow LangGraph Worker \u2192 JobManager.events._publish() \u2193 Redis Pub/Sub (event:{job_id}:stream) \u2193 FastAPI /gspr/stream/{job_id} \u2193 Node backend or browser (EventSource) Source code in app/api/routes/v1/gspr_table/gspr_stream_router.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 @router . get ( path = \"/stream/ {job_id} \" , summary = \"Stream real-time GSPR job progress via Server-Sent Events (SSE)\" , response_class = StreamingResponse , status_code = status . HTTP_200_OK , description = \"\"\" Subscribes to the Redis Pub/Sub channel `event: {job_id} :stream` and streams real-time job progress updates as Server-Sent Events (SSE). \"\"\" , ) async def stream_job ( request : Request , job_id : str = Path ( ... , description = \"Job ID to stream events for\" ), redis : AsyncRedisDB = Depends ( lambda : get_redis ( async_mode = True )), ): \"\"\" Server-Sent Events (SSE) endpoint that streams live progress updates for a given GSPR generation job. Data Flow: LangGraph Worker \u2192 JobManager.events._publish() \u2193 Redis Pub/Sub (event:{job_id}:stream) \u2193 FastAPI /gspr/stream/{job_id} \u2193 Node backend or browser (EventSource) \"\"\" channel_name = f \"event: { job_id } :stream\" async def event_generator (): logger . info ( f \"[SSE] Client connected to { channel_name } \" ) try : async for raw_message in redis . subscribe ( channel_name ): logger . info ( f \"[SSE] Received message from { channel_name } \" ) # Handle disconnects if await request . is_disconnected (): logger . info ( f \"[SSE] Client disconnected from { channel_name } \" ) break logger . info ( f \"[SSE] Publishing message from { channel_name } \" ) # Parse Redis message try : payload = json . loads ( raw_message ) event_type = payload . get ( \"event\" , \"message\" ) data = payload . get ( \"data\" , {}) except ( json . JSONDecodeError , TypeError ): event_type = \"message\" data = { \"raw\" : raw_message } # Format as SSE message yield f \"event: { event_type } \\n data: { json . dumps ( data ) } \\n\\n \" # \u2705 Stop streaming after job_completed if event_type == \"job_completed\" : logger . info ( f \"[SSE] Job completed for { job_id } , closing stream.\" ) break finally : logger . info ( f \"[SSE] Closed Redis connection for { channel_name } \" ) return StreamingResponse ( event_generator (), media_type = \"text/event-stream\" )","title":"GSPR Table API"},{"location":"api/gspr_table/gspr_table_api/#gspr-api-reference","text":"The GSPR (General Safety and Performance Requirements) APIs handle automated document generation, real-time job tracking, and streaming updates within the Regulatory AI system. Each endpoint below is designed for seamless integration with the design-template workflows.","title":"\u2699\ufe0f GSPR API Reference"},{"location":"api/gspr_table/gspr_table_api/#gspr-generate-api-create-compliance-tables","text":"Generates structured GSPR compliance tables based on device data, intended purpose, and regulatory mappings. This endpoint initiates the document generation workflow and returns a job reference ID.","title":"\ud83e\uddfe GSPR Generate API \u2014 Create Compliance Tables"},{"location":"api/gspr_table/gspr_table_api/#app.api.routes.v1.gspr_table.gspr_generate_router.generate_gspr_table","text":"Start a mock GSPR table generation job for a specific user-confirmed component.","title":"generate_gspr_table"},{"location":"api/gspr_table/gspr_table_api/#app.api.routes.v1.gspr_table.gspr_generate_router.generate_gspr_table--overview","text":"This endpoint is responsible for initiating a simulated GSPR generation process for one component at a time. It performs multiple validation steps to ensure that the session is active and that the requested component exists within the user's confirmed components list stored in Redis ( design_data.user_confirmed.components ). Once validated, the endpoint: 1. Loads GSPR mapping data ( grouped_sections.json ) from MongoDB. 2. Creates a unique background job entry using the Job Manager. 3. Triggers an asynchronous background task to simulate GSPR generation. 4. Returns job metadata immediately to the client.","title":"Overview"},{"location":"api/gspr_table/gspr_table_api/#app.api.routes.v1.gspr_table.gspr_generate_router.generate_gspr_table--parameters","text":"session_id ( str ): Unique identifier for the user session stored in Redis. component ( Optional[str] ): The specific component to process. Must exist in the user\u2019s confirmed components list. Example: ?component=PowerModule background_tasks ( BackgroundTasks ): FastAPI background task manager for non-blocking job execution. session_manager ( SessionManager ): Dependency that interfaces with the Redis-based session state. job_manager ( JobManager ): Dependency responsible for job creation, progress updates, and event publishing.","title":"Parameters"},{"location":"api/gspr_table/gspr_table_api/#app.api.routes.v1.gspr_table.gspr_generate_router.generate_gspr_table--validation","text":"Raises 404 if the session ID is not found in Redis. Raises 400 if no component is provided. Raises 400 if the component is not in the confirmed components list.","title":"Validation"},{"location":"api/gspr_table/gspr_table_api/#app.api.routes.v1.gspr_table.gspr_generate_router.generate_gspr_table--returns","text":"JSON response with: - message : Status message confirming job creation. - job_id : Unique identifier of the spawned background job. - component : The component being processed. - stream_url : SSE endpoint for listening to progress updates.","title":"Returns"},{"location":"api/gspr_table/gspr_table_api/#app.api.routes.v1.gspr_table.gspr_generate_router.generate_gspr_table--example-request","text":"POST /api/v1/gspr/generate/abc123?component=ECG_Module","title":"Example Request"},{"location":"api/gspr_table/gspr_table_api/#app.api.routes.v1.gspr_table.gspr_generate_router.generate_gspr_table--example-response","text":"{ \"message\": \"GSPR generation started successfully for component ECG_Module in session id abc123\", \"job_id\": \"2b1c4e8d-fb29-4b97-9b4e-cc8d3b42e76e\", \"component\": \"ECG_Module\", \"stream_url\": \"/api/v1/gspr/stream/2b1c4e8d-fb29-4b97-9b4e-cc8d3b42e76e\" } Source code in app/api/routes/v1/gspr_table/gspr_generate_router.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 @router . post ( path = \"/generate/ {session_id} \" , summary = \"Start a new GSPR generation job\" , status_code = status . HTTP_202_ACCEPTED , description = \"\"\" Create a new background job for GSPR (General Safety and Performance Requirements) table generation. This endpoint validates the provided session and ensures the specified component is one of the user's confirmed components (stored in Redis). Once validated, it spawns a background worker to simulate asynchronous GSPR table generation and immediately returns job metadata, including a stream URL for progress updates (SSE). \"\"\" , name = \"Start GSPR Generation Job\" , ) async def generate_gspr_table ( background_tasks : BackgroundTasks , session_id : str = Path ( ... , description = \"The unique session ID from Redis\" ), component : Optional [ str ] = Query ( None , description = \"Single component to generate sections for (must be user-confirmed).\" ), session_manager : SessionManager = Depends ( get_session_manager ), job_manager : JobManager = Depends ( get_job_manager ), ): \"\"\" Start a mock GSPR table generation job for a specific user-confirmed component. ### Overview This endpoint is responsible for initiating a simulated GSPR generation process for one component at a time. It performs multiple validation steps to ensure that the session is active and that the requested component exists within the user's confirmed components list stored in Redis (`design_data.user_confirmed.components`). Once validated, the endpoint: 1. Loads GSPR mapping data (`grouped_sections.json`) from MongoDB. 2. Creates a unique background job entry using the Job Manager. 3. Triggers an asynchronous background task to simulate GSPR generation. 4. Returns job metadata immediately to the client. ### Parameters - **session_id** (`str`): Unique identifier for the user session stored in Redis. - **component** (`Optional[str]`): The specific component to process. Must exist in the user\u2019s confirmed components list. Example: `?component=PowerModule` - **background_tasks** (`BackgroundTasks`): FastAPI background task manager for non-blocking job execution. - **session_manager** (`SessionManager`): Dependency that interfaces with the Redis-based session state. - **job_manager** (`JobManager`): Dependency responsible for job creation, progress updates, and event publishing. ### Validation - Raises `404` if the session ID is not found in Redis. - Raises `400` if no component is provided. - Raises `400` if the component is not in the confirmed components list. ### Returns JSON response with: - `message`: Status message confirming job creation. - `job_id`: Unique identifier of the spawned background job. - `component`: The component being processed. - `stream_url`: SSE endpoint for listening to progress updates. ### Example Request ```bash POST /api/v1/gspr/generate/abc123?component=ECG_Module ``` ### Example Response ```json { \"message\": \"GSPR generation started successfully for component ECG_Module in session id abc123\", \"job_id\": \"2b1c4e8d-fb29-4b97-9b4e-cc8d3b42e76e\", \"component\": \"ECG_Module\", \"stream_url\": \"/api/v1/gspr/stream/2b1c4e8d-fb29-4b97-9b4e-cc8d3b42e76e\" } ``` \"\"\" logger . info ( f \"[API] Incoming GSPR generation request | session_id= { session_id } , component= { component } \" ) # Validate session exists state : Optional [ dict ] = session_manager . get_session ( session_id ) if not state : logger . warning ( f \"[API] Session not found in Redis | session_id= { session_id } \" ) raise HTTPException ( status_code = status . HTTP_404_NOT_FOUND , detail = f \"Session { session_id } not found in Redis.\" , ) # Extract confirmed components confirmed_components : list [ str ] = state . get ( \"design_data\" , {}) . get ( \"user_confirmed\" , {}) . get ( \"components\" , []) logger . debug ( f \"[API] Confirmed components retrieved from session | session_id= { session_id } , confirmed= { confirmed_components } \" ) # Require a specific component if not component : logger . error ( f \"[API] No component provided in request | session_id= { session_id } \" ) raise HTTPException ( status_code = status . HTTP_400_BAD_REQUEST , detail = \"No component specified. Please provide ?component=<component_name>.\" , ) # Validate against confirmed components if component not in confirmed_components : logger . error ( f \"[API] Component not found in confirmed list | session_id= { session_id } , component= { component } \" ) raise HTTPException ( status_code = status . HTTP_400_BAD_REQUEST , detail = { \"message\" : f \"Component ' { component } ' not found in user's confirmed list.\" , \"confirmed_components\" : confirmed_components , }, ) # Create a new job ID job_id = str ( uuid4 ()) # Fetch grouped sections from MongoDB collection gspr_mapping try : requirement_sections = mongo_db . load_json_asset ( \"grouped_sections.json\" , collection_name = \"gspr_mapping\" ) logger . info ( f \"[API] Loaded grouped_sections from MongoDB | collection=gspr_mapping, count= { len ( requirement_sections ) } \" ) except ValueError as e : logger . error ( f \"[API] Failed to load grouped_sections | error= { str ( e ) } \" ) raise HTTPException ( status_code = status . HTTP_400_BAD_REQUEST , detail = str ( e )) total_sections = sum ( len ( sections ) for sections in requirement_sections . values ()) # Create a new job ID job_id = str ( uuid4 ()) job_manager . create_job ( job_id , total_sections ) print ( f \"[API] Created job { job_id } with { total_sections } sections for session { session_id } \" ) logger . info ( f \"[API] Created new GSPR job | job_id= { job_id } , session_id= { session_id } , component= { component } , total_sections= { total_sections } \" ) # Launch async background generation all_sections = [] for req_type , sections in requirement_sections . items (): for section in sections : section [ \"requirement_type\" ] = req_type all_sections . append ( section ) background_tasks . add_task ( run_gspr_table_generation , component , session_id , job_id , requirement_sections , all_sections , ) logger . info ( f \"[API] Background GSPR generation task scheduled | job_id= { job_id } \" ) del requirement_sections # free memory del total_sections # free memory del state # free memory return { \"message\" : f \"GSPR generation started successfully for component { component } in session id { session_id } \" , \"job_id\" : job_id , \"component\" : component , \"stream_url\" : f \"/api/v1/gspr/stream/ { job_id } \" , }","title":"Example Response"},{"location":"api/gspr_table/gspr_table_api/#app.api.routes.v1.gspr_table.gspr_generate_router.run_gspr_table_generation","text":"Asynchronously generates a GSPR table using the GSPRGraphRunner for production. This function processes all sections through the LangGraph workflow, using the GSPRGraphRunner to orchestrate AI-powered analysis of regulatory compliance requirements. Parameters: Name Type Description Default component_name str Name of the medical device component required session_id str Unique identifier for the user session required job_id str Unique identifier for the background job required all_sections list [ dict ] List of all section dictionaries to process required Source code in app/api/routes/v1/gspr_table/gspr_generate_router.py 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 async def run_gspr_table_generation ( component : str , session_id : str , job_id : str , requirement_sections : dict , all_sections : list [ dict ], ): \"\"\" Asynchronously generates a GSPR table using the GSPRGraphRunner for production. This function processes all sections through the LangGraph workflow, using the GSPRGraphRunner to orchestrate AI-powered analysis of regulatory compliance requirements. Args: component_name (str): Name of the medical device component session_id (str): Unique identifier for the user session job_id (str): Unique identifier for the background job all_sections (list[dict]): List of all section dictionaries to process \"\"\" session_manager : SessionManager = get_session_manager () job_manager : JobManager = get_job_manager () print ( f \"[Worker] Job { job_id } started at { time . ctime () } for session { session_id } for component { component } \" ) logger . info ( f \"[Worker] Starting GSPR generation job | job_id= { job_id } , session_id= { session_id } , component= { component } \" ) try : # Initialize the GSPRGraphRunner logger . info ( f \"[Worker] Initializing GSPRGraphRunner for job { job_id } ...\" ) runner = GSPRGraphRunner ( session_id = session_id , job_id = job_id , component_name = component , requirement_sections = requirement_sections , ) logger . info ( f \"[Worker] GSPRGraphRunner initialized, starting workflow for job { job_id } ...\" ) # Run the production workflow result = await runner . run_all_sections ( sections = all_sections ) logger . info ( f \"[Worker] Workflow completed for job { job_id } , success: { result . get ( 'success' , False ) } \" ) if result [ \"success\" ]: job_manager . mark_completed ( job_id ) logger . info ( f \"[Worker] Job { job_id } completed successfully at { time . ctime () } \" ) # Update Redis session with generated results session_manager . update_nested ( session_id , { \"gspr_results\" : { \"job_id\" : job_id , \"status\" : \"completed\" , \"total_sections\" : len ( all_sections ), \"failed_sections\" : 0 , \"sections\" : result [ \"results\" ], \"component_name\" : component , } }, ) else : job_manager . mark_completed ( job_id , failed = True ) logger . error ( f \"[Worker] Job { job_id } failed at { time . ctime () } : { result . get ( 'error' , 'Unknown error' ) } \" ) # Update session with error info session_manager . update_nested ( session_id , { \"gspr_results\" : { \"job_id\" : job_id , \"status\" : \"failed\" , \"error\" : result . get ( \"error\" , \"Unknown error\" ), \"component_name\" : component , } }, ) except Exception as e : logger . error ( f \"[Worker] Unexpected error in job { job_id } : { e } \" ) job_manager . mark_completed ( job_id , failed = True ) # Update session with error info session_manager . update_nested ( session_id , { \"gspr_results\" : { \"job_id\" : job_id , \"status\" : \"failed\" , \"error\" : str ( e ), \"component_name\" : component , } }, ) # Clean up memory del all_sections","title":"run_gspr_table_generation"},{"location":"api/gspr_table/gspr_table_api/#gspr-job-status-api-monitor-generation-progress","text":"Tracks the status of ongoing or completed GSPR generation jobs . Useful for polling job states, retrieving metadata, or confirming successful completion of background processes.","title":"\ud83d\udcca GSPR Job Status API \u2014 Monitor Generation Progress"},{"location":"api/gspr_table/gspr_table_api/#app.api.routes.v1.gspr_table.gspr_job_status_router.get_job_status","text":"Fetch the current job progress snapshot from Redis. Data source job:{job_id}:progress (Redis JSON key) Returns: Type Description completed, failed, pending counts percent progress status (running/completed/failed) timestamps (started_at, finished_at) Source code in app/api/routes/v1/gspr_table/gspr_job_status_router.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 @router . get ( path = \"/job/ {job_id} /status\" , summary = \"Get current job progress snapshot\" , status_code = status . HTTP_200_OK , response_description = \"Current job progress state stored in Redis.\" , ) def get_job_status ( job_id : str = Path ( ... , description = \"Job ID to retrieve status for\" ), job_manager : JobManager = Depends ( get_job_manager ), ): \"\"\" Fetch the current job progress snapshot from Redis. Data source: - job:{job_id}:progress (Redis JSON key) Returns: - completed, failed, pending counts - percent progress - status (running/completed/failed) - timestamps (started_at, finished_at) \"\"\" progress = job_manager . get_progress ( job_id ) if not progress : raise HTTPException ( status_code = status . HTTP_404_NOT_FOUND , detail = f \"Job { job_id } not found or expired in Redis.\" , ) return { \"job_id\" : job_id , \"status\" : progress . get ( \"status\" ), \"completed\" : progress . get ( \"completed\" ), \"failed\" : progress . get ( \"failed\" ), \"pending\" : progress . get ( \"pending\" ), \"percent\" : progress . get ( \"percent\" ), \"started_at\" : progress . get ( \"started_at\" ), \"finished_at\" : progress . get ( \"finished_at\" ), \"total_time\" : progress . get ( \"total_time\" ), }","title":"get_job_status"},{"location":"api/gspr_table/gspr_table_api/#gspr-stream-api-real-time-updates","text":"Streams live progress updates and events for long-running GSPR table generation tasks. Ideal for dashboards or clients requiring real-time feedback on document creation pipelines.","title":"\ud83d\udd04 GSPR Stream API \u2014 Real-Time Updates"},{"location":"api/gspr_table/gspr_table_api/#app.api.routes.v1.gspr_table.gspr_stream_router.stream_job","text":"Server-Sent Events (SSE) endpoint that streams live progress updates for a given GSPR generation job. Data Flow LangGraph Worker \u2192 JobManager.events._publish() \u2193 Redis Pub/Sub (event:{job_id}:stream) \u2193 FastAPI /gspr/stream/{job_id} \u2193 Node backend or browser (EventSource) Source code in app/api/routes/v1/gspr_table/gspr_stream_router.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 @router . get ( path = \"/stream/ {job_id} \" , summary = \"Stream real-time GSPR job progress via Server-Sent Events (SSE)\" , response_class = StreamingResponse , status_code = status . HTTP_200_OK , description = \"\"\" Subscribes to the Redis Pub/Sub channel `event: {job_id} :stream` and streams real-time job progress updates as Server-Sent Events (SSE). \"\"\" , ) async def stream_job ( request : Request , job_id : str = Path ( ... , description = \"Job ID to stream events for\" ), redis : AsyncRedisDB = Depends ( lambda : get_redis ( async_mode = True )), ): \"\"\" Server-Sent Events (SSE) endpoint that streams live progress updates for a given GSPR generation job. Data Flow: LangGraph Worker \u2192 JobManager.events._publish() \u2193 Redis Pub/Sub (event:{job_id}:stream) \u2193 FastAPI /gspr/stream/{job_id} \u2193 Node backend or browser (EventSource) \"\"\" channel_name = f \"event: { job_id } :stream\" async def event_generator (): logger . info ( f \"[SSE] Client connected to { channel_name } \" ) try : async for raw_message in redis . subscribe ( channel_name ): logger . info ( f \"[SSE] Received message from { channel_name } \" ) # Handle disconnects if await request . is_disconnected (): logger . info ( f \"[SSE] Client disconnected from { channel_name } \" ) break logger . info ( f \"[SSE] Publishing message from { channel_name } \" ) # Parse Redis message try : payload = json . loads ( raw_message ) event_type = payload . get ( \"event\" , \"message\" ) data = payload . get ( \"data\" , {}) except ( json . JSONDecodeError , TypeError ): event_type = \"message\" data = { \"raw\" : raw_message } # Format as SSE message yield f \"event: { event_type } \\n data: { json . dumps ( data ) } \\n\\n \" # \u2705 Stop streaming after job_completed if event_type == \"job_completed\" : logger . info ( f \"[SSE] Job completed for { job_id } , closing stream.\" ) break finally : logger . info ( f \"[SSE] Closed Redis connection for { channel_name } \" ) return StreamingResponse ( event_generator (), media_type = \"text/event-stream\" )","title":"stream_job"},{"location":"api/other_api/other_api/","text":"\u2699\ufe0f Core API Reference The Core API provides foundational endpoints that support the overall functioning, monitoring, and metadata access for the Regulatory AI platform. These endpoints are essential for system introspection, documentation access, and platform health checks. \ud83d\udcd8 Documentation API \u2014 Access Platform Docs & Metadata Expose internal or auto-generated documentation endpoints used by the platform. \ud83d\udd0e Health Check API \u2014 System Status & Liveness Provides lightweight endpoints to verify that the Regulatory AI backend is running, healthy, and ready to serve requests. Health-check endpoints. This module exposes endpoints to check the application's health and basic runtime metrics such as uptime and active session count. health ( mongo_db = Depends ( db . get_mongo_db ), redis = Depends ( db . get_redis ), neo4j_driver = Depends ( db . get_neo4j_driver ), milvus_conn = Depends ( db . get_milvus_status )) async Return application health information. status : always \"healthy\" if endpoint responds timestamp : current UTC time active_sessions : number of active sessions in DB version : app version from settings uptime_seconds : process uptime in seconds mongo_status : MongoDB connection status redis_status : Redis connection status neo4j_status : Neo4j connection status milvus_status : Milvus connection status Source code in app/api/routes/core/health.py 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 @router . get ( \"/health\" , response_model = HealthResponse , summary = \"Health check endpoint\" , name = \"health\" , ) async def health ( mongo_db = Depends ( db . get_mongo_db ), redis = Depends ( db . get_redis ), neo4j_driver = Depends ( db . get_neo4j_driver ), milvus_conn = Depends ( db . get_milvus_status ), ): \"\"\" Return application health information. - **status**: always `\"healthy\"` if endpoint responds - **timestamp**: current UTC time - **active_sessions**: number of active sessions in DB - **version**: app version from settings - **uptime_seconds**: process uptime in seconds - **mongo_status**: MongoDB connection status - **redis_status**: Redis connection status - **neo4j_status**: Neo4j connection status - **milvus_status**: Milvus connection status \"\"\" now = datetime . now ( timezone . utc ) uptime = ( now - _start_time ) . total_seconds () # Ping MongoDB try : mongo_db . command ( \"ping\" ) mongo_ok = True except Exception : mongo_ok = False # Ping Redis redis_ok = redis . client . ping () # Check Neo4j try : with neo4j_driver . session () as session : session . run ( \"RETURN 1\" ) session . close () neo4j_ok = True except Exception : neo4j_ok = False # Check Milvus milvus_ok = milvus_conn is not None return HealthResponse ( status = \"healthy\" , timestamp = now . isoformat (), version = settings . VERSION , uptime_seconds = uptime , mongo_status = \"ok\" if mongo_ok else \"down\" , redis_status = \"ok\" if redis_ok else \"down\" , neo4j_status = \"ok\" if neo4j_ok else \"down\" , milvus_status = \"ok\" if milvus_ok else \"down\" , ) \ud83e\uddec Metadata API \u2014 Platform Details & Runtime Info Returns information such as service version, environment, build data, or runtime configuration. get_metadata () async Returns project version, author, license, description. Source code in app/api/routes/core/meta.py 9 10 11 12 13 14 @router . get ( \"/meta\" , tags = [ \"Meta\" ], summary = \"Project metadata\" ) async def get_metadata (): \"\"\" Returns project version, author, license, description. \"\"\" return metadata_info \ud83c\udfc1 Root API \u2014 Base Entry Point Handles the platform\u2019s root route ( / ) providing a welcome message or base status payload. \ud83d\udca1 Model Switching API Handles dynamic switching between multiple LLM providers. Supports Grok, GPT-4o, Mistral, Gemini, and Claude models. get_models () async Get all available LLM models and the currently selected model. Returns: Name Type Description AvailableModelsResponse Available models with details and current selection Source code in app/api/routes/v1/models/models.py 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 @router . get ( \"/\" , response_model = AvailableModelsResponse , summary = \"Get available models\" , description = \"Returns a list of available LLM models and the currently selected model.\" , name = \"get_models\" ) async def get_models (): \"\"\" Get all available LLM models and the currently selected model. Returns: AvailableModelsResponse: Available models with details and current selection \"\"\" try : available = get_available_models () current = get_selected_model () logger . info ( f \"Returned { len ( available ) } available models, current: { current } \" ) return AvailableModelsResponse ( models = available , current_model = current ) except Exception as e : logger . error ( f \"Failed to get models: { e } \" ) raise HTTPException ( status_code = status . HTTP_500_INTERNAL_SERVER_ERROR , detail = \"Failed to retrieve available models\" ) set_model ( request ) async Set the selected LLM model. Parameters: Name Type Description Default request SetModelRequest SetModelRequest containing the model ID to select required Returns: Name Type Description SetModelResponse Confirmation of the selected model Raises: Type Description HTTPException If the model is not available Source code in app/api/routes/v1/models/models.py 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 @router . post ( \"/\" , response_model = SetModelResponse , summary = \"Set selected model\" , description = \"Sets the model to be used by the LLM service.\" , name = \"set_model\" ) async def set_model ( request : SetModelRequest ): \"\"\" Set the selected LLM model. Args: request: SetModelRequest containing the model ID to select Returns: SetModelResponse: Confirmation of the selected model Raises: HTTPException: If the model is not available \"\"\" try : available = get_available_models () if request . model not in available : raise HTTPException ( status_code = status . HTTP_400_BAD_REQUEST , detail = f \"Model ' { request . model } ' is not available. Available models: { available } \" ) set_selected_model ( request . model ) logger . info ( f \"Model selection changed to: { request . model } \" ) return SetModelResponse ( model = request . model , message = f \"Successfully selected model ' { request . model } '\" ) except HTTPException : raise except Exception as e : logger . error ( f \"Failed to set model: { e } \" ) raise HTTPException ( status_code = status . HTTP_500_INTERNAL_SERVER_ERROR , detail = \"Failed to set selected model\" )","title":"Other APIs"},{"location":"api/other_api/other_api/#core-api-reference","text":"The Core API provides foundational endpoints that support the overall functioning, monitoring, and metadata access for the Regulatory AI platform. These endpoints are essential for system introspection, documentation access, and platform health checks.","title":"\u2699\ufe0f Core API Reference"},{"location":"api/other_api/other_api/#documentation-api-access-platform-docs-metadata","text":"Expose internal or auto-generated documentation endpoints used by the platform.","title":"\ud83d\udcd8 Documentation API \u2014 Access Platform Docs &amp; Metadata"},{"location":"api/other_api/other_api/#health-check-api-system-status-liveness","text":"Provides lightweight endpoints to verify that the Regulatory AI backend is running, healthy, and ready to serve requests. Health-check endpoints. This module exposes endpoints to check the application's health and basic runtime metrics such as uptime and active session count.","title":"\ud83d\udd0e Health Check API \u2014 System Status &amp; Liveness"},{"location":"api/other_api/other_api/#app.api.routes.core.health.health","text":"Return application health information. status : always \"healthy\" if endpoint responds timestamp : current UTC time active_sessions : number of active sessions in DB version : app version from settings uptime_seconds : process uptime in seconds mongo_status : MongoDB connection status redis_status : Redis connection status neo4j_status : Neo4j connection status milvus_status : Milvus connection status Source code in app/api/routes/core/health.py 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 @router . get ( \"/health\" , response_model = HealthResponse , summary = \"Health check endpoint\" , name = \"health\" , ) async def health ( mongo_db = Depends ( db . get_mongo_db ), redis = Depends ( db . get_redis ), neo4j_driver = Depends ( db . get_neo4j_driver ), milvus_conn = Depends ( db . get_milvus_status ), ): \"\"\" Return application health information. - **status**: always `\"healthy\"` if endpoint responds - **timestamp**: current UTC time - **active_sessions**: number of active sessions in DB - **version**: app version from settings - **uptime_seconds**: process uptime in seconds - **mongo_status**: MongoDB connection status - **redis_status**: Redis connection status - **neo4j_status**: Neo4j connection status - **milvus_status**: Milvus connection status \"\"\" now = datetime . now ( timezone . utc ) uptime = ( now - _start_time ) . total_seconds () # Ping MongoDB try : mongo_db . command ( \"ping\" ) mongo_ok = True except Exception : mongo_ok = False # Ping Redis redis_ok = redis . client . ping () # Check Neo4j try : with neo4j_driver . session () as session : session . run ( \"RETURN 1\" ) session . close () neo4j_ok = True except Exception : neo4j_ok = False # Check Milvus milvus_ok = milvus_conn is not None return HealthResponse ( status = \"healthy\" , timestamp = now . isoformat (), version = settings . VERSION , uptime_seconds = uptime , mongo_status = \"ok\" if mongo_ok else \"down\" , redis_status = \"ok\" if redis_ok else \"down\" , neo4j_status = \"ok\" if neo4j_ok else \"down\" , milvus_status = \"ok\" if milvus_ok else \"down\" , )","title":"health"},{"location":"api/other_api/other_api/#metadata-api-platform-details-runtime-info","text":"Returns information such as service version, environment, build data, or runtime configuration.","title":"\ud83e\uddec Metadata API \u2014 Platform Details &amp; Runtime Info"},{"location":"api/other_api/other_api/#app.api.routes.core.meta.get_metadata","text":"Returns project version, author, license, description. Source code in app/api/routes/core/meta.py 9 10 11 12 13 14 @router . get ( \"/meta\" , tags = [ \"Meta\" ], summary = \"Project metadata\" ) async def get_metadata (): \"\"\" Returns project version, author, license, description. \"\"\" return metadata_info","title":"get_metadata"},{"location":"api/other_api/other_api/#root-api-base-entry-point","text":"Handles the platform\u2019s root route ( / ) providing a welcome message or base status payload.","title":"\ud83c\udfc1 Root API \u2014 Base Entry Point"},{"location":"api/other_api/other_api/#model-switching-api","text":"Handles dynamic switching between multiple LLM providers. Supports Grok, GPT-4o, Mistral, Gemini, and Claude models.","title":"\ud83d\udca1 Model Switching API"},{"location":"api/other_api/other_api/#app.api.routes.v1.models.models.get_models","text":"Get all available LLM models and the currently selected model. Returns: Name Type Description AvailableModelsResponse Available models with details and current selection Source code in app/api/routes/v1/models/models.py 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 @router . get ( \"/\" , response_model = AvailableModelsResponse , summary = \"Get available models\" , description = \"Returns a list of available LLM models and the currently selected model.\" , name = \"get_models\" ) async def get_models (): \"\"\" Get all available LLM models and the currently selected model. Returns: AvailableModelsResponse: Available models with details and current selection \"\"\" try : available = get_available_models () current = get_selected_model () logger . info ( f \"Returned { len ( available ) } available models, current: { current } \" ) return AvailableModelsResponse ( models = available , current_model = current ) except Exception as e : logger . error ( f \"Failed to get models: { e } \" ) raise HTTPException ( status_code = status . HTTP_500_INTERNAL_SERVER_ERROR , detail = \"Failed to retrieve available models\" )","title":"get_models"},{"location":"api/other_api/other_api/#app.api.routes.v1.models.models.set_model","text":"Set the selected LLM model. Parameters: Name Type Description Default request SetModelRequest SetModelRequest containing the model ID to select required Returns: Name Type Description SetModelResponse Confirmation of the selected model Raises: Type Description HTTPException If the model is not available Source code in app/api/routes/v1/models/models.py 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 @router . post ( \"/\" , response_model = SetModelResponse , summary = \"Set selected model\" , description = \"Sets the model to be used by the LLM service.\" , name = \"set_model\" ) async def set_model ( request : SetModelRequest ): \"\"\" Set the selected LLM model. Args: request: SetModelRequest containing the model ID to select Returns: SetModelResponse: Confirmation of the selected model Raises: HTTPException: If the model is not available \"\"\" try : available = get_available_models () if request . model not in available : raise HTTPException ( status_code = status . HTTP_400_BAD_REQUEST , detail = f \"Model ' { request . model } ' is not available. Available models: { available } \" ) set_selected_model ( request . model ) logger . info ( f \"Model selection changed to: { request . model } \" ) return SetModelResponse ( model = request . model , message = f \"Successfully selected model ' { request . model } '\" ) except HTTPException : raise except Exception as e : logger . error ( f \"Failed to set model: { e } \" ) raise HTTPException ( status_code = status . HTTP_500_INTERNAL_SERVER_ERROR , detail = \"Failed to set selected model\" )","title":"set_model"},{"location":"api/projects/projects_api/","text":"\ud83d\udcc1 Projects API Reference The Projects API manages project creation, validation, and lifecycle operations inside the Regulatory AI system. Use these endpoints to check project existence, retrieve project metadata, or manage project-level workflows. \ud83d\udd0d Project Check API \u2014 Validate & Retrieve Project Information Verifies whether a project exists, checks ownership, and fetches associated metadata. Useful before triggering workflows tied to a specific project. check_project_details ( request , session_id = Path ( ... , description = 'The unique session ID from Redis' ), manager = Depends ( get_session_manager )) async Validate and store project details for medical device context. This endpoint cleans, validates, and stores project details such as name and description in the Redis session and MongoDB. It ensures the project details are relevant to medical device use cases. Parameters: Name Type Description Default request ProjectDetailsRequest Contains project ID, name, and description. required session_id str The unique identifier for the session. Path (..., description='The unique session ID from Redis') manager Dependency-injected session manager for state operations. Depends ( get_session_manager ) Returns: Name Type Description ProjectDetailsResponse Contains the project ID, cleaned name and description, validation status, and a message indicating the result. Raises: Type Description HTTPException 404 if the session is not found, 500 if Redis or MongoDB update fails. Example POST /projects/check/{session_id} { \"project_id\": \"12345\", \"project_name\": \"Cardiac Monitor\", \"project_description\": \"A device for monitoring heart activity.\" } Response: { \"project_id\": \"12345\", \"checked_name\": \"Cardiac Monitor\", \"checked_description\": \"A device for monitoring heart activity.\", \"is_valid\": true, \"message\": \"Project details appear valid for a medical device project.\" } Source code in app/api/routes/v1/projects/project_check.py 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 @router . post ( \"/check/ {session_id} \" , response_model = ProjectDetailsResponse , summary = \"Validate and store project details for medical device context\" , description = ( \"Cleans, validates, and stores project name and description in Redis session and MongoDB if valid for medical device use cases.\" ), ) async def check_project_details ( request : ProjectDetailsRequest , session_id : str = Path ( ... , description = \"The unique session ID from Redis\" ), manager = Depends ( get_session_manager ), ): \"\"\" Validate and store project details for medical device context. This endpoint cleans, validates, and stores project details such as name and description in the Redis session and MongoDB. It ensures the project details are relevant to medical device use cases. Args: request (ProjectDetailsRequest): Contains project ID, name, and description. session_id (str): The unique identifier for the session. manager: Dependency-injected session manager for state operations. Returns: ProjectDetailsResponse: Contains the project ID, cleaned name and description, validation status, and a message indicating the result. Raises: HTTPException: 404 if the session is not found, 500 if Redis or MongoDB update fails. Example: POST /projects/check/{session_id} { \"project_id\": \"12345\", \"project_name\": \"Cardiac Monitor\", \"project_description\": \"A device for monitoring heart activity.\" } Response: { \"project_id\": \"12345\", \"checked_name\": \"Cardiac Monitor\", \"checked_description\": \"A device for monitoring heart activity.\", \"is_valid\": true, \"message\": \"Project details appear valid for a medical device project.\" } \"\"\" # ---------------- Step 1: Validate session existence ---------------- state = manager . get_session ( session_id ) if state is None : raise HTTPException ( status_code = status . HTTP_404_NOT_FOUND , detail = f \"Session ' { session_id } ' not found or expired.\" , ) # ---------------- Step 2: Clean text ---------------- cleaned_name = clean_text ( request . project_name ) cleaned_description = clean_text ( request . project_description ) # ---------------- Step 3: Validate ---------------- valid = True if cleaned_name and cleaned_description else False # ---------------- Step 4: Prepare update payload ---------------- update_payload = { \"project_info\" : { \"project_id\" : request . project_id , \"project_name\" : cleaned_name , \"project_description\" : cleaned_description , \"is_valid\" : valid , } } # ---------------- Step 5: Deep update Redis state ---------------- success = manager . update_nested ( session_id , update_payload ) if not success : raise HTTPException ( status_code = status . HTTP_500_INTERNAL_SERVER_ERROR , detail = \"Failed to update session in Redis.\" , ) # ---------------- Step 6: Persist to MongoDB ---------------- mongo_db . save_session ( session_id , state ) if mongo_db . get_session ( session_id ) is None : raise HTTPException ( status_code = status . HTTP_500_INTERNAL_SERVER_ERROR , detail = \"Failed to update session in MongoDB.\" , ) # ---------------- Step 7: Prepare response ---------------- if valid : message = \"Project details appear valid for a medical device project.\" else : message = \"Project name/description do not appear related to medical devices. Please include relevant medical or healthcare context.\" return ProjectDetailsResponse ( project_id = request . project_id , checked_name = cleaned_name , checked_description = cleaned_description , is_valid = valid , message = message , ) clean_text ( text ) Performs basic cleanup on input text to remove extra spaces and unsafe characters. Parameters: Name Type Description Default text str The input text to be cleaned. required Returns: Name Type Description str str The cleaned text with normalized whitespace and filtered characters. Source code in app/api/routes/v1/projects/project_check.py 16 17 18 19 20 21 22 23 24 25 26 27 28 def clean_text ( text : str ) -> str : \"\"\" Performs basic cleanup on input text to remove extra spaces and unsafe characters. Args: text (str): The input text to be cleaned. Returns: str: The cleaned text with normalized whitespace and filtered characters. \"\"\" text = re . sub ( r \"\\s+\" , \" \" , text ) . strip () text = re . sub ( r \"[^a-zA-Z0-9 .,;:!@#()/-]\" , \"\" , text ) return text \ud83d\udcc2 Projects Management API \u2014 Create & Manage Projects Handles core project operations such as creating new projects, listing existing ones, and maintaining organizational structure. load_project ( project_id , session_manager = Depends ( get_session_manager )) async Load a project from MongoDB into a Redis session. This endpoint retrieves a project from the MongoDB ai_projects collection and loads its data into a new Redis session. The new session ID is returned for further operations. Parameters: Name Type Description Default project_id str The unique identifier for the project in MongoDB. required session_manager SessionManager Dependency-injected session manager for state operations. Depends ( get_session_manager ) Returns: Name Type Description dict Contains a success message, the project ID, and the new session ID. Raises: Type Description HTTPException 404 if the project is not found in MongoDB. Example POST /projects/load/{project_id} Response: { \"message\": \"AI project restored successfully\", \"project_id\": \"12345\", \"session_id\": \"new_session_67890\" } Source code in app/api/routes/v1/projects/projects_router.py 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 @router . post ( \"/load/ {project_id} \" ) async def load_project ( project_id : str , session_manager : SessionManager = Depends ( get_session_manager ), ): \"\"\" Load a project from MongoDB into a Redis session. This endpoint retrieves a project from the MongoDB `ai_projects` collection and loads its data into a new Redis session. The new session ID is returned for further operations. Args: project_id (str): The unique identifier for the project in MongoDB. session_manager (SessionManager): Dependency-injected session manager for state operations. Returns: dict: Contains a success message, the project ID, and the new session ID. Raises: HTTPException: 404 if the project is not found in MongoDB. Example: POST /projects/load/{project_id} Response: { \"message\": \"AI project restored successfully\", \"project_id\": \"12345\", \"session_id\": \"new_session_67890\" } \"\"\" doc = mongo_db . load_project ( project_id ) if not doc : raise HTTPException ( status_code = status . HTTP_404_NOT_FOUND , detail = \"AI project not found in MongoDB\" , ) new_session_id = session_manager . clone_to_new_session ( doc [ \"session_data\" ]) return { \"message\" : \"AI project restored successfully\" , \"project_id\" : project_id , \"session_id\" : new_session_id , } save_project ( session_id , session_manager = Depends ( get_session_manager )) async Persist an active Redis session into MongoDB. This endpoint saves the current session data from Redis into the MongoDB ai_projects collection. The session data is associated with the project ID for future retrieval. Parameters: Name Type Description Default session_id str The unique identifier for the Redis session. required session_manager SessionManager Dependency-injected session manager for state operations. Depends ( get_session_manager ) Returns: Name Type Description dict Result of the MongoDB save operation. Raises: Type Description HTTPException 404 if the session is not found in Redis. Example POST /projects/save/{session_id} Response: { \"message\": \"Project saved successfully\", \"project_id\": \"12345\" } Source code in app/api/routes/v1/projects/projects_router.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 @router . post ( \"/save/ {session_id} \" ) async def save_project ( session_id : str , session_manager : SessionManager = Depends ( get_session_manager ), ): \"\"\" Persist an active Redis session into MongoDB. This endpoint saves the current session data from Redis into the MongoDB `ai_projects` collection. The session data is associated with the project ID for future retrieval. Args: session_id (str): The unique identifier for the Redis session. session_manager (SessionManager): Dependency-injected session manager for state operations. Returns: dict: Result of the MongoDB save operation. Raises: HTTPException: 404 if the session is not found in Redis. Example: POST /projects/save/{session_id} Response: { \"message\": \"Project saved successfully\", \"project_id\": \"12345\" } \"\"\" session_data = session_manager . get_session ( session_id ) if not session_data : raise HTTPException ( status_code = status . HTTP_404_NOT_FOUND , detail = \"Session not found in Redis\" , ) project_id = session_data . get ( \"project_info\" , {}) . get ( \"project_id\" ) result = mongo_db . save_project ( project_id , session_data ) return result","title":"Projects API"},{"location":"api/projects/projects_api/#projects-api-reference","text":"The Projects API manages project creation, validation, and lifecycle operations inside the Regulatory AI system. Use these endpoints to check project existence, retrieve project metadata, or manage project-level workflows.","title":"\ud83d\udcc1 Projects API Reference"},{"location":"api/projects/projects_api/#project-check-api-validate-retrieve-project-information","text":"Verifies whether a project exists, checks ownership, and fetches associated metadata. Useful before triggering workflows tied to a specific project.","title":"\ud83d\udd0d Project Check API \u2014 Validate &amp; Retrieve Project Information"},{"location":"api/projects/projects_api/#app.api.routes.v1.projects.project_check.check_project_details","text":"Validate and store project details for medical device context. This endpoint cleans, validates, and stores project details such as name and description in the Redis session and MongoDB. It ensures the project details are relevant to medical device use cases. Parameters: Name Type Description Default request ProjectDetailsRequest Contains project ID, name, and description. required session_id str The unique identifier for the session. Path (..., description='The unique session ID from Redis') manager Dependency-injected session manager for state operations. Depends ( get_session_manager ) Returns: Name Type Description ProjectDetailsResponse Contains the project ID, cleaned name and description, validation status, and a message indicating the result. Raises: Type Description HTTPException 404 if the session is not found, 500 if Redis or MongoDB update fails. Example POST /projects/check/{session_id} { \"project_id\": \"12345\", \"project_name\": \"Cardiac Monitor\", \"project_description\": \"A device for monitoring heart activity.\" } Response: { \"project_id\": \"12345\", \"checked_name\": \"Cardiac Monitor\", \"checked_description\": \"A device for monitoring heart activity.\", \"is_valid\": true, \"message\": \"Project details appear valid for a medical device project.\" } Source code in app/api/routes/v1/projects/project_check.py 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 @router . post ( \"/check/ {session_id} \" , response_model = ProjectDetailsResponse , summary = \"Validate and store project details for medical device context\" , description = ( \"Cleans, validates, and stores project name and description in Redis session and MongoDB if valid for medical device use cases.\" ), ) async def check_project_details ( request : ProjectDetailsRequest , session_id : str = Path ( ... , description = \"The unique session ID from Redis\" ), manager = Depends ( get_session_manager ), ): \"\"\" Validate and store project details for medical device context. This endpoint cleans, validates, and stores project details such as name and description in the Redis session and MongoDB. It ensures the project details are relevant to medical device use cases. Args: request (ProjectDetailsRequest): Contains project ID, name, and description. session_id (str): The unique identifier for the session. manager: Dependency-injected session manager for state operations. Returns: ProjectDetailsResponse: Contains the project ID, cleaned name and description, validation status, and a message indicating the result. Raises: HTTPException: 404 if the session is not found, 500 if Redis or MongoDB update fails. Example: POST /projects/check/{session_id} { \"project_id\": \"12345\", \"project_name\": \"Cardiac Monitor\", \"project_description\": \"A device for monitoring heart activity.\" } Response: { \"project_id\": \"12345\", \"checked_name\": \"Cardiac Monitor\", \"checked_description\": \"A device for monitoring heart activity.\", \"is_valid\": true, \"message\": \"Project details appear valid for a medical device project.\" } \"\"\" # ---------------- Step 1: Validate session existence ---------------- state = manager . get_session ( session_id ) if state is None : raise HTTPException ( status_code = status . HTTP_404_NOT_FOUND , detail = f \"Session ' { session_id } ' not found or expired.\" , ) # ---------------- Step 2: Clean text ---------------- cleaned_name = clean_text ( request . project_name ) cleaned_description = clean_text ( request . project_description ) # ---------------- Step 3: Validate ---------------- valid = True if cleaned_name and cleaned_description else False # ---------------- Step 4: Prepare update payload ---------------- update_payload = { \"project_info\" : { \"project_id\" : request . project_id , \"project_name\" : cleaned_name , \"project_description\" : cleaned_description , \"is_valid\" : valid , } } # ---------------- Step 5: Deep update Redis state ---------------- success = manager . update_nested ( session_id , update_payload ) if not success : raise HTTPException ( status_code = status . HTTP_500_INTERNAL_SERVER_ERROR , detail = \"Failed to update session in Redis.\" , ) # ---------------- Step 6: Persist to MongoDB ---------------- mongo_db . save_session ( session_id , state ) if mongo_db . get_session ( session_id ) is None : raise HTTPException ( status_code = status . HTTP_500_INTERNAL_SERVER_ERROR , detail = \"Failed to update session in MongoDB.\" , ) # ---------------- Step 7: Prepare response ---------------- if valid : message = \"Project details appear valid for a medical device project.\" else : message = \"Project name/description do not appear related to medical devices. Please include relevant medical or healthcare context.\" return ProjectDetailsResponse ( project_id = request . project_id , checked_name = cleaned_name , checked_description = cleaned_description , is_valid = valid , message = message , )","title":"check_project_details"},{"location":"api/projects/projects_api/#app.api.routes.v1.projects.project_check.clean_text","text":"Performs basic cleanup on input text to remove extra spaces and unsafe characters. Parameters: Name Type Description Default text str The input text to be cleaned. required Returns: Name Type Description str str The cleaned text with normalized whitespace and filtered characters. Source code in app/api/routes/v1/projects/project_check.py 16 17 18 19 20 21 22 23 24 25 26 27 28 def clean_text ( text : str ) -> str : \"\"\" Performs basic cleanup on input text to remove extra spaces and unsafe characters. Args: text (str): The input text to be cleaned. Returns: str: The cleaned text with normalized whitespace and filtered characters. \"\"\" text = re . sub ( r \"\\s+\" , \" \" , text ) . strip () text = re . sub ( r \"[^a-zA-Z0-9 .,;:!@#()/-]\" , \"\" , text ) return text","title":"clean_text"},{"location":"api/projects/projects_api/#projects-management-api-create-manage-projects","text":"Handles core project operations such as creating new projects, listing existing ones, and maintaining organizational structure.","title":"\ud83d\udcc2 Projects Management API \u2014 Create &amp; Manage Projects"},{"location":"api/projects/projects_api/#app.api.routes.v1.projects.projects_router.load_project","text":"Load a project from MongoDB into a Redis session. This endpoint retrieves a project from the MongoDB ai_projects collection and loads its data into a new Redis session. The new session ID is returned for further operations. Parameters: Name Type Description Default project_id str The unique identifier for the project in MongoDB. required session_manager SessionManager Dependency-injected session manager for state operations. Depends ( get_session_manager ) Returns: Name Type Description dict Contains a success message, the project ID, and the new session ID. Raises: Type Description HTTPException 404 if the project is not found in MongoDB. Example POST /projects/load/{project_id} Response: { \"message\": \"AI project restored successfully\", \"project_id\": \"12345\", \"session_id\": \"new_session_67890\" } Source code in app/api/routes/v1/projects/projects_router.py 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 @router . post ( \"/load/ {project_id} \" ) async def load_project ( project_id : str , session_manager : SessionManager = Depends ( get_session_manager ), ): \"\"\" Load a project from MongoDB into a Redis session. This endpoint retrieves a project from the MongoDB `ai_projects` collection and loads its data into a new Redis session. The new session ID is returned for further operations. Args: project_id (str): The unique identifier for the project in MongoDB. session_manager (SessionManager): Dependency-injected session manager for state operations. Returns: dict: Contains a success message, the project ID, and the new session ID. Raises: HTTPException: 404 if the project is not found in MongoDB. Example: POST /projects/load/{project_id} Response: { \"message\": \"AI project restored successfully\", \"project_id\": \"12345\", \"session_id\": \"new_session_67890\" } \"\"\" doc = mongo_db . load_project ( project_id ) if not doc : raise HTTPException ( status_code = status . HTTP_404_NOT_FOUND , detail = \"AI project not found in MongoDB\" , ) new_session_id = session_manager . clone_to_new_session ( doc [ \"session_data\" ]) return { \"message\" : \"AI project restored successfully\" , \"project_id\" : project_id , \"session_id\" : new_session_id , }","title":"load_project"},{"location":"api/projects/projects_api/#app.api.routes.v1.projects.projects_router.save_project","text":"Persist an active Redis session into MongoDB. This endpoint saves the current session data from Redis into the MongoDB ai_projects collection. The session data is associated with the project ID for future retrieval. Parameters: Name Type Description Default session_id str The unique identifier for the Redis session. required session_manager SessionManager Dependency-injected session manager for state operations. Depends ( get_session_manager ) Returns: Name Type Description dict Result of the MongoDB save operation. Raises: Type Description HTTPException 404 if the session is not found in Redis. Example POST /projects/save/{session_id} Response: { \"message\": \"Project saved successfully\", \"project_id\": \"12345\" } Source code in app/api/routes/v1/projects/projects_router.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 @router . post ( \"/save/ {session_id} \" ) async def save_project ( session_id : str , session_manager : SessionManager = Depends ( get_session_manager ), ): \"\"\" Persist an active Redis session into MongoDB. This endpoint saves the current session data from Redis into the MongoDB `ai_projects` collection. The session data is associated with the project ID for future retrieval. Args: session_id (str): The unique identifier for the Redis session. session_manager (SessionManager): Dependency-injected session manager for state operations. Returns: dict: Result of the MongoDB save operation. Raises: HTTPException: 404 if the session is not found in Redis. Example: POST /projects/save/{session_id} Response: { \"message\": \"Project saved successfully\", \"project_id\": \"12345\" } \"\"\" session_data = session_manager . get_session ( session_id ) if not session_data : raise HTTPException ( status_code = status . HTTP_404_NOT_FOUND , detail = \"Session not found in Redis\" , ) project_id = session_data . get ( \"project_info\" , {}) . get ( \"project_id\" ) result = mongo_db . save_project ( project_id , session_data ) return result","title":"save_project"},{"location":"api/session/session_api/","text":"\ud83e\udde9 Sessions API Reference The Sessions API powers session lifecycle management within Regulatory AI. It handles creating, restoring, updating, and deleting session states that your workflows rely on. \ud83d\udd27 Session Management API \u2014 Create, Restore & Control Sessions Provides endpoints to initialize new sessions, retrieve existing session data, extend session lifetimes, or clean up expired entries. Use these endpoints whenever a workflow depends on session-based state handling. create_session ( manager = Depends ( get_session_manager )) async Create a new session. This endpoint creates a new empty session with an initial state. No request body is required. Parameters: Name Type Description Default manager Dependency-injected session manager for state operations. Depends ( get_session_manager ) Returns: Name Type Description dict Contains the new session ID and a success message. Example POST /sessions/create Response: { \"session_id\": \"new_session_12345\", \"message\": \"Session created successfully\" } Source code in app/api/routes/v1/sessions/sessions_router.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 @router . post ( path = \"/create\" , summary = \"Create a new session\" , description = \"Automatically creates a new session (no request body needed).\" , response_model = CreateSessionResponse , name = \"create_session\" , ) async def create_session ( manager = Depends ( get_session_manager )): \"\"\" Create a new session. This endpoint creates a new empty session with an initial state. No request body is required. Args: manager: Dependency-injected session manager for state operations. Returns: dict: Contains the new session ID and a success message. Example: POST /sessions/create Response: { \"session_id\": \"new_session_12345\", \"message\": \"Session created successfully\" } \"\"\" session_id = manager . create_session ( initial_state = {}) return { \"session_id\" : session_id , \"message\" : \"Session created successfully\" , } delete_session ( session_id , manager = Depends ( get_session_manager )) async Delete a session by its ID. This endpoint deletes a session identified by its unique session ID. If the session does not exist, it raises a 404 error. Parameters: Name Type Description Default session_id str The unique identifier for the session. required manager Dependency-injected session manager for state operations. Depends ( get_session_manager ) Returns: Name Type Description dict A success message indicating the session was deleted. Raises: Type Description HTTPException 404 if the session is not found. Example DELETE /sessions/{session_id} Response: { \"message\": \"Session {session_id} deleted successfully\" } Source code in app/api/routes/v1/sessions/sessions_router.py 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 @router . delete ( path = \"/ {session_id} \" , summary = \"Delete a session\" , description = \"**Deletes a session by its ID.**\" , response_model = DeleteSessionResponse , name = \"delete_session\" , ) async def delete_session ( session_id : str , manager = Depends ( get_session_manager )): \"\"\" Delete a session by its ID. This endpoint deletes a session identified by its unique session ID. If the session does not exist, it raises a 404 error. Args: session_id (str): The unique identifier for the session. manager: Dependency-injected session manager for state operations. Returns: dict: A success message indicating the session was deleted. Raises: HTTPException: 404 if the session is not found. Example: DELETE /sessions/{session_id} Response: { \"message\": \"Session {session_id} deleted successfully\" } \"\"\" if not manager . session_exists ( session_id ): raise HTTPException ( status_code = status . HTTP_404_NOT_FOUND , detail = \"Session not found\" ) manager . delete_session ( session_id ) return { \"message\" : f \"Session { session_id } deleted successfully\" } get_latest_session_id ( manager = Depends ( get_session_manager )) async Get the most recently created session ID. This endpoint retrieves the ID of the latest session created. If no sessions exist, it raises a 404 error. Parameters: Name Type Description Default manager Dependency-injected session manager for state operations. Depends ( get_session_manager ) Returns: Name Type Description dict Contains the latest session ID. Raises: Type Description HTTPException 404 if no sessions have been created yet. Example GET /sessions/latest Response: { \"latest_session_id\": \"latest_session_67890\" } Source code in app/api/routes/v1/sessions/sessions_router.py 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 @router . get ( path = \"/latest\" , summary = \"Get latest session ID\" , description = \"**Returns the most recently created session ID.**\" , name = \"get_latest_session_id\" , ) async def get_latest_session_id ( manager = Depends ( get_session_manager )): \"\"\" Get the most recently created session ID. This endpoint retrieves the ID of the latest session created. If no sessions exist, it raises a 404 error. Args: manager: Dependency-injected session manager for state operations. Returns: dict: Contains the latest session ID. Raises: HTTPException: 404 if no sessions have been created yet. Example: GET /sessions/latest Response: { \"latest_session_id\": \"latest_session_67890\" } \"\"\" session_id = manager . get_latest_session_id () if not session_id : raise HTTPException ( status_code = status . HTTP_404_NOT_FOUND , detail = \"No session has been created yet\" ) return { \"latest_session_id\" : session_id } get_session_state ( session_id = Path ( ... , description = 'The unique session ID from Redis' ), manager = Depends ( get_session_manager )) async Fetch the state of a specific session. This endpoint retrieves the state of a session identified by its unique session ID. Parameters: Name Type Description Default session_id str The unique identifier for the session. Path (..., description='The unique session ID from Redis') manager Dependency-injected session manager for state operations. Depends ( get_session_manager ) Returns: Name Type Description dict The state of the specified session. Raises: Type Description HTTPException 404 if the session is not found. Example GET /sessions/{session_id} Response: { \"state\": { ... } } Source code in app/api/routes/v1/sessions/sessions_router.py 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 @router . get ( path = \"/ {session_id} \" , summary = \"Get session state\" , description = \"**Fetch the state of a specific session.**\" , name = \"get_session_state\" , ) async def get_session_state ( session_id : str = Path ( ... , description = \"The unique session ID from Redis\" ), manager = Depends ( get_session_manager ), ): \"\"\" Fetch the state of a specific session. This endpoint retrieves the state of a session identified by its unique session ID. Args: session_id (str): The unique identifier for the session. manager: Dependency-injected session manager for state operations. Returns: dict: The state of the specified session. Raises: HTTPException: 404 if the session is not found. Example: GET /sessions/{session_id} Response: { \"state\": { ... } } \"\"\" session = manager . get_session ( session_id ) if not session : raise HTTPException ( status_code = status . HTTP_404_NOT_FOUND , detail = \"Session not found\" ) return session get_sessions ( manager = Depends ( get_session_manager )) async Get a list of all active sessions. This endpoint retrieves a list of all active session IDs and the total count of active sessions. Parameters: Name Type Description Default manager Dependency-injected session manager for state operations. Depends ( get_session_manager ) Returns: Name Type Description dict Contains a list of active session IDs and the total count. Example GET /sessions Response: { \"active_sessions\": [\"session_1\", \"session_2\"], \"total_sessions\": 2 } Source code in app/api/routes/v1/sessions/sessions_router.py 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 @router . get ( path = \"\" , summary = \"Get active sessions\" , description = \"**Returns a list of active session IDs.**\" , response_model = SessionsResponse , name = \"get_sessions\" , ) async def get_sessions ( manager = Depends ( get_session_manager )): \"\"\" Get a list of all active sessions. This endpoint retrieves a list of all active session IDs and the total count of active sessions. Args: manager: Dependency-injected session manager for state operations. Returns: dict: Contains a list of active session IDs and the total count. Example: GET /sessions Response: { \"active_sessions\": [\"session_1\", \"session_2\"], \"total_sessions\": 2 } \"\"\" all_sessions = manager . get_all_sessions () return { \"active_sessions\" : all_sessions , \"total_sessions\" : len ( all_sessions ), }","title":"Sessions API"},{"location":"api/session/session_api/#sessions-api-reference","text":"The Sessions API powers session lifecycle management within Regulatory AI. It handles creating, restoring, updating, and deleting session states that your workflows rely on.","title":"\ud83e\udde9 Sessions API Reference"},{"location":"api/session/session_api/#session-management-api-create-restore-control-sessions","text":"Provides endpoints to initialize new sessions, retrieve existing session data, extend session lifetimes, or clean up expired entries. Use these endpoints whenever a workflow depends on session-based state handling.","title":"\ud83d\udd27 Session Management API \u2014 Create, Restore &amp; Control Sessions"},{"location":"api/session/session_api/#app.api.routes.v1.sessions.sessions_router.create_session","text":"Create a new session. This endpoint creates a new empty session with an initial state. No request body is required. Parameters: Name Type Description Default manager Dependency-injected session manager for state operations. Depends ( get_session_manager ) Returns: Name Type Description dict Contains the new session ID and a success message. Example POST /sessions/create Response: { \"session_id\": \"new_session_12345\", \"message\": \"Session created successfully\" } Source code in app/api/routes/v1/sessions/sessions_router.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 @router . post ( path = \"/create\" , summary = \"Create a new session\" , description = \"Automatically creates a new session (no request body needed).\" , response_model = CreateSessionResponse , name = \"create_session\" , ) async def create_session ( manager = Depends ( get_session_manager )): \"\"\" Create a new session. This endpoint creates a new empty session with an initial state. No request body is required. Args: manager: Dependency-injected session manager for state operations. Returns: dict: Contains the new session ID and a success message. Example: POST /sessions/create Response: { \"session_id\": \"new_session_12345\", \"message\": \"Session created successfully\" } \"\"\" session_id = manager . create_session ( initial_state = {}) return { \"session_id\" : session_id , \"message\" : \"Session created successfully\" , }","title":"create_session"},{"location":"api/session/session_api/#app.api.routes.v1.sessions.sessions_router.delete_session","text":"Delete a session by its ID. This endpoint deletes a session identified by its unique session ID. If the session does not exist, it raises a 404 error. Parameters: Name Type Description Default session_id str The unique identifier for the session. required manager Dependency-injected session manager for state operations. Depends ( get_session_manager ) Returns: Name Type Description dict A success message indicating the session was deleted. Raises: Type Description HTTPException 404 if the session is not found. Example DELETE /sessions/{session_id} Response: { \"message\": \"Session {session_id} deleted successfully\" } Source code in app/api/routes/v1/sessions/sessions_router.py 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 @router . delete ( path = \"/ {session_id} \" , summary = \"Delete a session\" , description = \"**Deletes a session by its ID.**\" , response_model = DeleteSessionResponse , name = \"delete_session\" , ) async def delete_session ( session_id : str , manager = Depends ( get_session_manager )): \"\"\" Delete a session by its ID. This endpoint deletes a session identified by its unique session ID. If the session does not exist, it raises a 404 error. Args: session_id (str): The unique identifier for the session. manager: Dependency-injected session manager for state operations. Returns: dict: A success message indicating the session was deleted. Raises: HTTPException: 404 if the session is not found. Example: DELETE /sessions/{session_id} Response: { \"message\": \"Session {session_id} deleted successfully\" } \"\"\" if not manager . session_exists ( session_id ): raise HTTPException ( status_code = status . HTTP_404_NOT_FOUND , detail = \"Session not found\" ) manager . delete_session ( session_id ) return { \"message\" : f \"Session { session_id } deleted successfully\" }","title":"delete_session"},{"location":"api/session/session_api/#app.api.routes.v1.sessions.sessions_router.get_latest_session_id","text":"Get the most recently created session ID. This endpoint retrieves the ID of the latest session created. If no sessions exist, it raises a 404 error. Parameters: Name Type Description Default manager Dependency-injected session manager for state operations. Depends ( get_session_manager ) Returns: Name Type Description dict Contains the latest session ID. Raises: Type Description HTTPException 404 if no sessions have been created yet. Example GET /sessions/latest Response: { \"latest_session_id\": \"latest_session_67890\" } Source code in app/api/routes/v1/sessions/sessions_router.py 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 @router . get ( path = \"/latest\" , summary = \"Get latest session ID\" , description = \"**Returns the most recently created session ID.**\" , name = \"get_latest_session_id\" , ) async def get_latest_session_id ( manager = Depends ( get_session_manager )): \"\"\" Get the most recently created session ID. This endpoint retrieves the ID of the latest session created. If no sessions exist, it raises a 404 error. Args: manager: Dependency-injected session manager for state operations. Returns: dict: Contains the latest session ID. Raises: HTTPException: 404 if no sessions have been created yet. Example: GET /sessions/latest Response: { \"latest_session_id\": \"latest_session_67890\" } \"\"\" session_id = manager . get_latest_session_id () if not session_id : raise HTTPException ( status_code = status . HTTP_404_NOT_FOUND , detail = \"No session has been created yet\" ) return { \"latest_session_id\" : session_id }","title":"get_latest_session_id"},{"location":"api/session/session_api/#app.api.routes.v1.sessions.sessions_router.get_session_state","text":"Fetch the state of a specific session. This endpoint retrieves the state of a session identified by its unique session ID. Parameters: Name Type Description Default session_id str The unique identifier for the session. Path (..., description='The unique session ID from Redis') manager Dependency-injected session manager for state operations. Depends ( get_session_manager ) Returns: Name Type Description dict The state of the specified session. Raises: Type Description HTTPException 404 if the session is not found. Example GET /sessions/{session_id} Response: { \"state\": { ... } } Source code in app/api/routes/v1/sessions/sessions_router.py 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 @router . get ( path = \"/ {session_id} \" , summary = \"Get session state\" , description = \"**Fetch the state of a specific session.**\" , name = \"get_session_state\" , ) async def get_session_state ( session_id : str = Path ( ... , description = \"The unique session ID from Redis\" ), manager = Depends ( get_session_manager ), ): \"\"\" Fetch the state of a specific session. This endpoint retrieves the state of a session identified by its unique session ID. Args: session_id (str): The unique identifier for the session. manager: Dependency-injected session manager for state operations. Returns: dict: The state of the specified session. Raises: HTTPException: 404 if the session is not found. Example: GET /sessions/{session_id} Response: { \"state\": { ... } } \"\"\" session = manager . get_session ( session_id ) if not session : raise HTTPException ( status_code = status . HTTP_404_NOT_FOUND , detail = \"Session not found\" ) return session","title":"get_session_state"},{"location":"api/session/session_api/#app.api.routes.v1.sessions.sessions_router.get_sessions","text":"Get a list of all active sessions. This endpoint retrieves a list of all active session IDs and the total count of active sessions. Parameters: Name Type Description Default manager Dependency-injected session manager for state operations. Depends ( get_session_manager ) Returns: Name Type Description dict Contains a list of active session IDs and the total count. Example GET /sessions Response: { \"active_sessions\": [\"session_1\", \"session_2\"], \"total_sessions\": 2 } Source code in app/api/routes/v1/sessions/sessions_router.py 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 @router . get ( path = \"\" , summary = \"Get active sessions\" , description = \"**Returns a list of active session IDs.**\" , response_model = SessionsResponse , name = \"get_sessions\" , ) async def get_sessions ( manager = Depends ( get_session_manager )): \"\"\" Get a list of all active sessions. This endpoint retrieves a list of all active session IDs and the total count of active sessions. Args: manager: Dependency-injected session manager for state operations. Returns: dict: Contains a list of active session IDs and the total count. Example: GET /sessions Response: { \"active_sessions\": [\"session_1\", \"session_2\"], \"total_sessions\": 2 } \"\"\" all_sessions = manager . get_all_sessions () return { \"active_sessions\" : all_sessions , \"total_sessions\" : len ( all_sessions ), }","title":"get_sessions"},{"location":"database_and_schemas/databases_overview/","text":"\ud83e\udde0 Milvus Vector Database \u2014 Scalable Embedding Index & Semantic Retrieval High-performance vector storage optimized for similarity search and embedding-based retrieval across Regulatory AI modules. get_milvus_status () FastAPI dependency to inject Milvus status (True/False). Source code in app/core/db/db_milvus.py 15 16 17 def get_milvus_status (): \"\"\"FastAPI dependency to inject Milvus status (True/False).\"\"\" return connections . has_connection ( alias = \"default\" ) \ud83d\uddc4\ufe0f MongoDB Persistence Layer \u2014 Long-Term Storage for Sessions & Projects Document-based storage engine responsible for persisting session snapshots, project data, and regulatory artifacts. MongoDB session storage and utilities. MongoDB Centralized MongoDB handler for all collections and operations. Source code in app/core/db/db_mongo.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 class MongoDB : \"\"\"Centralized MongoDB handler for all collections and operations.\"\"\" def __init__ ( self ): self . _client = MongoClient ( settings . mongodb_uri , server_api = ServerApi ( \"1\" )) self . _db = self . _client [ settings . MONGO_DB ] # Predefined collections self . sessions = self . _db [ \"sessions\" ] self . users = self . _db [ \"users\" ] self . projects = self . _db [ \"ai_projects\" ] # ------------------------- Utility ------------------------- def to_serializable ( self , obj : Any ) -> Any : \"\"\"Recursively convert Pydantic models and nested objects to serializable dicts.\"\"\" if isinstance ( obj , BaseModel ): return obj . model_dump () if isinstance ( obj , dict ): return { k : self . to_serializable ( v ) for k , v in obj . items ()} if isinstance ( obj , list ): return [ self . to_serializable ( i ) for i in obj ] return obj # ------------------------- Session Operations ------------------------- def save_session ( self , session_id : str , state : Any ) -> None : \"\"\"Insert or update a session state document.\"\"\" state = self . to_serializable ( state ) self . sessions . update_one ( { \"_id\" : session_id }, { \"$set\" : { \"state\" : state }}, upsert = True , ) def get_session ( self , session_id : str ) -> Optional [ dict [ str , Any ]]: \"\"\"Retrieve session state by ID.\"\"\" doc = self . sessions . find_one ({ \"_id\" : session_id }) return doc [ \"state\" ] if doc else None def delete_session ( self , session_id : str ) -> None : \"\"\"Delete a session document.\"\"\" self . sessions . delete_one ({ \"_id\" : session_id }) def list_sessions ( self ): \"\"\"Return all session IDs.\"\"\" return self . sessions . find ({}, { \"_id\" : 1 }) # ------------------------- AI Project Operations ------------------------- def save_project ( self , project_id : str , session_data : dict [ str , Any ]) -> dict [ str , Any ]: \"\"\"Upsert a project snapshot from Redis into ai_projects.\"\"\" session_data = self . to_serializable ( session_data ) timestamp = datetime . now ( timezone . utc ) self . projects . update_one ( { \"_id\" : project_id }, { \"$set\" : { \"session_data\" : session_data , \"updated_at\" : timestamp , }, \"$setOnInsert\" : { \"created_at\" : timestamp , }, }, upsert = True , ) return { \"project_id\" : project_id , \"updated_at\" : timestamp . isoformat (), \"message\" : \"AI project saved successfully\" , } def load_project ( self , project_id : str ) -> Optional [ dict [ str , Any ]]: \"\"\"Fetch a project document by ID from ai_projects.\"\"\" return self . projects . find_one ({ \"_id\" : project_id }) # ------------------------- Access Helpers ------------------------- def get_db ( self ): \"\"\"Return the underlying MongoDB database handle.\"\"\" return self . _db def get_collection ( self , name : str ): \"\"\"Return a specific collection handle dynamically.\"\"\" return self . _db [ name ] def upsert_json_file ( self , collection_name : str , file_name : str , json_data : dict , extra : dict | None = None , ) -> None : \"\"\" Upsert one JSON file into a collection where _id == file_name. \"\"\" coll = self . _db [ collection_name ] now = datetime . now ( timezone . utc ) # optional checksum for change detection/debugging digest = sha256 ( str ( json_data ) . encode ( \"utf-8\" )) . hexdigest () doc = { \"_id\" : file_name , # <- your requirement \"name\" : file_name , \"content\" : json_data , # raw JSON goes here \"checksum\" : digest , \"updated_at\" : now , } if extra : doc |= { \"meta\" : self . to_serializable ( extra )} coll . update_one ( { \"_id\" : file_name }, { \"$set\" : { k : v for k , v in doc . items () if k != \"_id\" }, \"$setOnInsert\" : { \"created_at\" : now }, }, upsert = True , ) # ------------------------- JSON Asset Helpers ------------------------- def load_json_asset ( self , file_name : str , collection_name : str ) -> dict : \"\"\" Fetch a stored JSON file (by _id) from MongoDB and return its content. Args: file_name (str): The _id / filename of the JSON file, e.g., 'grouped_sections.json'. collection_name (str): The collection where JSON files are stored. Default: 'gspr_assets'. Returns: dict: Parsed JSON content stored under 'content'. Raises: ValueError: If the file is not found or has no 'content' field. \"\"\" coll = self . _db [ collection_name ] doc = coll . find_one ({ \"_id\" : file_name }) if not doc : raise ValueError ( f \"JSON asset ' { file_name } ' not found in MongoDB collection ' { collection_name } '.\" ) if \"content\" not in doc : raise ValueError ( f \"Document ' { file_name } ' has no 'content' field.\" ) return doc [ \"content\" ] delete_session ( session_id ) Delete a session document. Source code in app/core/db/db_mongo.py 53 54 55 def delete_session ( self , session_id : str ) -> None : \"\"\"Delete a session document.\"\"\" self . sessions . delete_one ({ \"_id\" : session_id }) get_collection ( name ) Return a specific collection handle dynamically. Source code in app/core/db/db_mongo.py 97 98 99 def get_collection ( self , name : str ): \"\"\"Return a specific collection handle dynamically.\"\"\" return self . _db [ name ] get_db () Return the underlying MongoDB database handle. Source code in app/core/db/db_mongo.py 93 94 95 def get_db ( self ): \"\"\"Return the underlying MongoDB database handle.\"\"\" return self . _db get_session ( session_id ) Retrieve session state by ID. Source code in app/core/db/db_mongo.py 48 49 50 51 def get_session ( self , session_id : str ) -> Optional [ dict [ str , Any ]]: \"\"\"Retrieve session state by ID.\"\"\" doc = self . sessions . find_one ({ \"_id\" : session_id }) return doc [ \"state\" ] if doc else None list_sessions () Return all session IDs. Source code in app/core/db/db_mongo.py 57 58 59 def list_sessions ( self ): \"\"\"Return all session IDs.\"\"\" return self . sessions . find ({}, { \"_id\" : 1 }) load_json_asset ( file_name , collection_name ) Fetch a stored JSON file (by _id) from MongoDB and return its content. Parameters: Name Type Description Default file_name str The _id / filename of the JSON file, e.g., 'grouped_sections.json'. required collection_name str The collection where JSON files are stored. Default: 'gspr_assets'. required Returns: Name Type Description dict dict Parsed JSON content stored under 'content'. Raises: Type Description ValueError If the file is not found or has no 'content' field. Source code in app/core/db/db_mongo.py 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 def load_json_asset ( self , file_name : str , collection_name : str ) -> dict : \"\"\" Fetch a stored JSON file (by _id) from MongoDB and return its content. Args: file_name (str): The _id / filename of the JSON file, e.g., 'grouped_sections.json'. collection_name (str): The collection where JSON files are stored. Default: 'gspr_assets'. Returns: dict: Parsed JSON content stored under 'content'. Raises: ValueError: If the file is not found or has no 'content' field. \"\"\" coll = self . _db [ collection_name ] doc = coll . find_one ({ \"_id\" : file_name }) if not doc : raise ValueError ( f \"JSON asset ' { file_name } ' not found in MongoDB collection ' { collection_name } '.\" ) if \"content\" not in doc : raise ValueError ( f \"Document ' { file_name } ' has no 'content' field.\" ) return doc [ \"content\" ] load_project ( project_id ) Fetch a project document by ID from ai_projects. Source code in app/core/db/db_mongo.py 88 89 90 def load_project ( self , project_id : str ) -> Optional [ dict [ str , Any ]]: \"\"\"Fetch a project document by ID from ai_projects.\"\"\" return self . projects . find_one ({ \"_id\" : project_id }) save_project ( project_id , session_data ) Upsert a project snapshot from Redis into ai_projects. Source code in app/core/db/db_mongo.py 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 def save_project ( self , project_id : str , session_data : dict [ str , Any ]) -> dict [ str , Any ]: \"\"\"Upsert a project snapshot from Redis into ai_projects.\"\"\" session_data = self . to_serializable ( session_data ) timestamp = datetime . now ( timezone . utc ) self . projects . update_one ( { \"_id\" : project_id }, { \"$set\" : { \"session_data\" : session_data , \"updated_at\" : timestamp , }, \"$setOnInsert\" : { \"created_at\" : timestamp , }, }, upsert = True , ) return { \"project_id\" : project_id , \"updated_at\" : timestamp . isoformat (), \"message\" : \"AI project saved successfully\" , } save_session ( session_id , state ) Insert or update a session state document. Source code in app/core/db/db_mongo.py 39 40 41 42 43 44 45 46 def save_session ( self , session_id : str , state : Any ) -> None : \"\"\"Insert or update a session state document.\"\"\" state = self . to_serializable ( state ) self . sessions . update_one ( { \"_id\" : session_id }, { \"$set\" : { \"state\" : state }}, upsert = True , ) to_serializable ( obj ) Recursively convert Pydantic models and nested objects to serializable dicts. Source code in app/core/db/db_mongo.py 28 29 30 31 32 33 34 35 36 def to_serializable ( self , obj : Any ) -> Any : \"\"\"Recursively convert Pydantic models and nested objects to serializable dicts.\"\"\" if isinstance ( obj , BaseModel ): return obj . model_dump () if isinstance ( obj , dict ): return { k : self . to_serializable ( v ) for k , v in obj . items ()} if isinstance ( obj , list ): return [ self . to_serializable ( i ) for i in obj ] return obj upsert_json_file ( collection_name , file_name , json_data , extra = None ) Upsert one JSON file into a collection where _id == file_name. Source code in app/core/db/db_mongo.py 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 def upsert_json_file ( self , collection_name : str , file_name : str , json_data : dict , extra : dict | None = None , ) -> None : \"\"\" Upsert one JSON file into a collection where _id == file_name. \"\"\" coll = self . _db [ collection_name ] now = datetime . now ( timezone . utc ) # optional checksum for change detection/debugging digest = sha256 ( str ( json_data ) . encode ( \"utf-8\" )) . hexdigest () doc = { \"_id\" : file_name , # <- your requirement \"name\" : file_name , \"content\" : json_data , # raw JSON goes here \"checksum\" : digest , \"updated_at\" : now , } if extra : doc |= { \"meta\" : self . to_serializable ( extra )} coll . update_one ( { \"_id\" : file_name }, { \"$set\" : { k : v for k , v in doc . items () if k != \"_id\" }, \"$setOnInsert\" : { \"created_at\" : now }, }, upsert = True , ) get_mongo_db () FastAPI dependency to inject MongoDB database handle. Source code in app/core/db/db_mongo.py 166 167 168 def get_mongo_db (): \"\"\"FastAPI dependency to inject MongoDB database handle.\"\"\" return mongo_db . get_db () get_projects_collection () FastAPI dependency to inject the ai_projects collection. Source code in app/core/db/db_mongo.py 181 182 183 def get_projects_collection (): \"\"\"FastAPI dependency to inject the ai_projects collection.\"\"\" return mongo_db . projects get_sessions_collection () FastAPI dependency to inject the sessions collection. Source code in app/core/db/db_mongo.py 171 172 173 def get_sessions_collection (): \"\"\"FastAPI dependency to inject the sessions collection.\"\"\" return mongo_db . sessions get_users_collection () FastAPI dependency to inject the users collection. Source code in app/core/db/db_mongo.py 176 177 178 def get_users_collection (): \"\"\"FastAPI dependency to inject the users collection.\"\"\" return mongo_db . users \ud83d\udd17 Neo4j Graph Engine \u2014 Knowledge Graph for Regulatory Mapping Graph database powering relationship modeling between device components, classifications, and regulatory dependencies. close_neo4j_driver () async Gracefully close the driver on shutdown. Source code in app/core/db/db_neo4j.py 24 25 26 27 28 29 async def close_neo4j_driver (): \"\"\"Gracefully close the driver on shutdown.\"\"\" global _neo4j_driver if _neo4j_driver : _neo4j_driver . close () _neo4j_driver = None get_neo4j_driver () Return a shared Neo4j driver instance, lazy-loaded on first access. Source code in app/core/db/db_neo4j.py 13 14 15 16 17 18 19 20 21 def get_neo4j_driver () -> Driver : \"\"\"Return a shared Neo4j driver instance, lazy-loaded on first access.\"\"\" global _neo4j_driver if _neo4j_driver is None : _neo4j_driver = GraphDatabase . driver ( settings . neo4j_bolt_url , auth = ( settings . NEO4J_USER , settings . NEO4J_PASSWORD ), ) return _neo4j_driver \u26a1 Redis Session Store \u2014 Ultra-Fast In-Memory Workflow State High-speed cache used for active session management, temporary workflow state, and rapid data retrieval. AsyncRedisDB Bases: BaseRedisDB Async Redis client for streaming and background tasks (Pub/Sub). Source code in app/core/db/db_redis.py 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 class AsyncRedisDB ( BaseRedisDB ): \"\"\"Async Redis client for streaming and background tasks (Pub/Sub).\"\"\" async_mode : bool = True def __init__ ( self ): self . client = aioredis . from_url ( settings . redis_url , decode_responses = True , # ensures str instead of bytes ) # --------------------- Async JSON helpers --------------------- async def set_json ( self , key : str , value : dict [ str , Any ], expire : int | None = None ): data = json . dumps ( value ) if expire : await self . client . setex ( key , expire , data ) else : await self . client . set ( key , data ) async def get_json ( self , key : str ) -> Optional [ dict [ str , Any ]]: data = await self . client . get ( key ) if data is None : return None try : return json . loads ( data ) except json . JSONDecodeError : return None async def delete_key ( self , key : str ) -> bool : result = await self . client . delete ( key ) return result > 0 async def key_exists ( self , key : str ) -> bool : return await self . client . exists ( key ) == 1 async def scan_keys ( self , pattern : str ): \"\"\"Async iterator over matching keys.\"\"\" async for key in self . client . scan_iter ( match = pattern ): yield key # --------------------- Pub/Sub for SSE --------------------- async def subscribe ( self , channel_name : str ) -> AsyncGenerator [ str , None ]: \"\"\"Async generator yielding messages from a Redis channel.\"\"\" pubsub = self . client . pubsub () await pubsub . subscribe ( channel_name ) try : async for message in pubsub . listen (): if message [ \"type\" ] == \"message\" : yield message [ \"data\" ] except GeneratorExit : # \u2705 This happens when the consumer (SSE) stops iteration \u2014 normal shutdown. pass except Exception as e : # \u2705 Ignore expected connection closures if \"Connection lost\" not in str ( e ): print ( f \"[Redis Subscribe] Unexpected error: { e } \" ) finally : try : await pubsub . unsubscribe ( channel_name ) await pubsub . aclose () except ConnectionError : # \u2705 Ignore close errors after connection lost pass async def _close ( self ): await self . client . aclose () scan_keys ( pattern ) async Async iterator over matching keys. Source code in app/core/db/db_redis.py 117 118 119 120 async def scan_keys ( self , pattern : str ): \"\"\"Async iterator over matching keys.\"\"\" async for key in self . client . scan_iter ( match = pattern ): yield key subscribe ( channel_name ) async Async generator yielding messages from a Redis channel. Source code in app/core/db/db_redis.py 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 async def subscribe ( self , channel_name : str ) -> AsyncGenerator [ str , None ]: \"\"\"Async generator yielding messages from a Redis channel.\"\"\" pubsub = self . client . pubsub () await pubsub . subscribe ( channel_name ) try : async for message in pubsub . listen (): if message [ \"type\" ] == \"message\" : yield message [ \"data\" ] except GeneratorExit : # \u2705 This happens when the consumer (SSE) stops iteration \u2014 normal shutdown. pass except Exception as e : # \u2705 Ignore expected connection closures if \"Connection lost\" not in str ( e ): print ( f \"[Redis Subscribe] Unexpected error: { e } \" ) finally : try : await pubsub . unsubscribe ( channel_name ) await pubsub . aclose () except ConnectionError : # \u2705 Ignore close errors after connection lost pass BaseRedisDB Common interface for Redis operations (sync or async). Source code in app/core/db/db_redis.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 class BaseRedisDB : \"\"\"Common interface for Redis operations (sync or async).\"\"\" async_mode : bool = False def set_json ( self , key : str , value : dict [ str , Any ], expire : int | None = None ): raise NotImplementedError def get_json ( self , key : str ): raise NotImplementedError def delete_key ( self , key : str ): raise NotImplementedError def key_exists ( self , key : str ): raise NotImplementedError def scan_keys ( self , pattern : str ): raise NotImplementedError SyncRedisDB Bases: BaseRedisDB Wrapper class for Redis operations used in the app. Source code in app/core/db/db_redis.py 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 class SyncRedisDB ( BaseRedisDB ): \"\"\"Wrapper class for Redis operations used in the app.\"\"\" async_mode : bool = False def __init__ ( self ): self . client = redis . Redis . from_url ( settings . redis_url , decode_responses = True , # ensures strings, not bytes ) def set_json ( self , key : str , value : dict [ str , Any ], expire : int | None = None ): data = json . dumps ( value ) if expire : self . client . setex ( key , expire , data ) else : self . client . set ( key , data ) def get_json ( self , key : str ) -> Optional [ dict [ str , Any ]]: data = self . client . get ( key ) data = cast ( Optional [ str ], data ) if data is None : return None try : return json . loads ( data ) except json . JSONDecodeError : return None def delete_key ( self , key : str ) -> bool : result = self . client . delete ( key ) result = cast ( int , result ) return result > 0 def key_exists ( self , key : str ) -> bool : return self . client . exists ( key ) == 1 def scan_keys ( self , pattern : str ): yield from self . client . scan_iter ( match = pattern ) def _close ( self ): self . client . close () print ( \"[Redis] Sync client closed.\" ) get_redis ( async_mode = False ) FastAPI dependency for injecting Redis connection wrapper. Example get_redis() \u2192 sync Redis client get_redis(async_mode=True) \u2192 async Redis client (aioredis) Usage in FastAPI routes @router.get(\"/stream/{job_id}\") async def stream_job(job_id: str, redis: AsyncRedisDB = Depends(lambda: get_redis(async_mode=True))): ... @router.post(\"/session/{id}\") def update_session(id: str, redis: RedisDB = Depends(get_redis)): ... Source code in app/core/db/db_redis.py 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 def get_redis ( async_mode : bool = False ) -> BaseRedisDB : \"\"\" FastAPI dependency for injecting Redis connection wrapper. Example: - get_redis() \u2192 sync Redis client - get_redis(async_mode=True) \u2192 async Redis client (aioredis) Usage in FastAPI routes: @router.get(\"/stream/{job_id}\") async def stream_job(job_id: str, redis: AsyncRedisDB = Depends(lambda: get_redis(async_mode=True))): ... @router.post(\"/session/{id}\") def update_session(id: str, redis: RedisDB = Depends(get_redis)): ... \"\"\" return async_redis_db if async_mode else sync_redis_db","title":"Databases Overview"},{"location":"database_and_schemas/databases_overview/#milvus-vector-database-scalable-embedding-index-semantic-retrieval","text":"High-performance vector storage optimized for similarity search and embedding-based retrieval across Regulatory AI modules.","title":"\ud83e\udde0 Milvus Vector Database \u2014 Scalable Embedding Index &amp; Semantic Retrieval"},{"location":"database_and_schemas/databases_overview/#app.core.db.db_milvus.get_milvus_status","text":"FastAPI dependency to inject Milvus status (True/False). Source code in app/core/db/db_milvus.py 15 16 17 def get_milvus_status (): \"\"\"FastAPI dependency to inject Milvus status (True/False).\"\"\" return connections . has_connection ( alias = \"default\" )","title":"get_milvus_status"},{"location":"database_and_schemas/databases_overview/#mongodb-persistence-layer-long-term-storage-for-sessions-projects","text":"Document-based storage engine responsible for persisting session snapshots, project data, and regulatory artifacts. MongoDB session storage and utilities.","title":"\ud83d\uddc4\ufe0f MongoDB Persistence Layer \u2014 Long-Term Storage for Sessions &amp; Projects"},{"location":"database_and_schemas/databases_overview/#app.core.db.db_mongo.MongoDB","text":"Centralized MongoDB handler for all collections and operations. Source code in app/core/db/db_mongo.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 class MongoDB : \"\"\"Centralized MongoDB handler for all collections and operations.\"\"\" def __init__ ( self ): self . _client = MongoClient ( settings . mongodb_uri , server_api = ServerApi ( \"1\" )) self . _db = self . _client [ settings . MONGO_DB ] # Predefined collections self . sessions = self . _db [ \"sessions\" ] self . users = self . _db [ \"users\" ] self . projects = self . _db [ \"ai_projects\" ] # ------------------------- Utility ------------------------- def to_serializable ( self , obj : Any ) -> Any : \"\"\"Recursively convert Pydantic models and nested objects to serializable dicts.\"\"\" if isinstance ( obj , BaseModel ): return obj . model_dump () if isinstance ( obj , dict ): return { k : self . to_serializable ( v ) for k , v in obj . items ()} if isinstance ( obj , list ): return [ self . to_serializable ( i ) for i in obj ] return obj # ------------------------- Session Operations ------------------------- def save_session ( self , session_id : str , state : Any ) -> None : \"\"\"Insert or update a session state document.\"\"\" state = self . to_serializable ( state ) self . sessions . update_one ( { \"_id\" : session_id }, { \"$set\" : { \"state\" : state }}, upsert = True , ) def get_session ( self , session_id : str ) -> Optional [ dict [ str , Any ]]: \"\"\"Retrieve session state by ID.\"\"\" doc = self . sessions . find_one ({ \"_id\" : session_id }) return doc [ \"state\" ] if doc else None def delete_session ( self , session_id : str ) -> None : \"\"\"Delete a session document.\"\"\" self . sessions . delete_one ({ \"_id\" : session_id }) def list_sessions ( self ): \"\"\"Return all session IDs.\"\"\" return self . sessions . find ({}, { \"_id\" : 1 }) # ------------------------- AI Project Operations ------------------------- def save_project ( self , project_id : str , session_data : dict [ str , Any ]) -> dict [ str , Any ]: \"\"\"Upsert a project snapshot from Redis into ai_projects.\"\"\" session_data = self . to_serializable ( session_data ) timestamp = datetime . now ( timezone . utc ) self . projects . update_one ( { \"_id\" : project_id }, { \"$set\" : { \"session_data\" : session_data , \"updated_at\" : timestamp , }, \"$setOnInsert\" : { \"created_at\" : timestamp , }, }, upsert = True , ) return { \"project_id\" : project_id , \"updated_at\" : timestamp . isoformat (), \"message\" : \"AI project saved successfully\" , } def load_project ( self , project_id : str ) -> Optional [ dict [ str , Any ]]: \"\"\"Fetch a project document by ID from ai_projects.\"\"\" return self . projects . find_one ({ \"_id\" : project_id }) # ------------------------- Access Helpers ------------------------- def get_db ( self ): \"\"\"Return the underlying MongoDB database handle.\"\"\" return self . _db def get_collection ( self , name : str ): \"\"\"Return a specific collection handle dynamically.\"\"\" return self . _db [ name ] def upsert_json_file ( self , collection_name : str , file_name : str , json_data : dict , extra : dict | None = None , ) -> None : \"\"\" Upsert one JSON file into a collection where _id == file_name. \"\"\" coll = self . _db [ collection_name ] now = datetime . now ( timezone . utc ) # optional checksum for change detection/debugging digest = sha256 ( str ( json_data ) . encode ( \"utf-8\" )) . hexdigest () doc = { \"_id\" : file_name , # <- your requirement \"name\" : file_name , \"content\" : json_data , # raw JSON goes here \"checksum\" : digest , \"updated_at\" : now , } if extra : doc |= { \"meta\" : self . to_serializable ( extra )} coll . update_one ( { \"_id\" : file_name }, { \"$set\" : { k : v for k , v in doc . items () if k != \"_id\" }, \"$setOnInsert\" : { \"created_at\" : now }, }, upsert = True , ) # ------------------------- JSON Asset Helpers ------------------------- def load_json_asset ( self , file_name : str , collection_name : str ) -> dict : \"\"\" Fetch a stored JSON file (by _id) from MongoDB and return its content. Args: file_name (str): The _id / filename of the JSON file, e.g., 'grouped_sections.json'. collection_name (str): The collection where JSON files are stored. Default: 'gspr_assets'. Returns: dict: Parsed JSON content stored under 'content'. Raises: ValueError: If the file is not found or has no 'content' field. \"\"\" coll = self . _db [ collection_name ] doc = coll . find_one ({ \"_id\" : file_name }) if not doc : raise ValueError ( f \"JSON asset ' { file_name } ' not found in MongoDB collection ' { collection_name } '.\" ) if \"content\" not in doc : raise ValueError ( f \"Document ' { file_name } ' has no 'content' field.\" ) return doc [ \"content\" ]","title":"MongoDB"},{"location":"database_and_schemas/databases_overview/#app.core.db.db_mongo.MongoDB.delete_session","text":"Delete a session document. Source code in app/core/db/db_mongo.py 53 54 55 def delete_session ( self , session_id : str ) -> None : \"\"\"Delete a session document.\"\"\" self . sessions . delete_one ({ \"_id\" : session_id })","title":"delete_session"},{"location":"database_and_schemas/databases_overview/#app.core.db.db_mongo.MongoDB.get_collection","text":"Return a specific collection handle dynamically. Source code in app/core/db/db_mongo.py 97 98 99 def get_collection ( self , name : str ): \"\"\"Return a specific collection handle dynamically.\"\"\" return self . _db [ name ]","title":"get_collection"},{"location":"database_and_schemas/databases_overview/#app.core.db.db_mongo.MongoDB.get_db","text":"Return the underlying MongoDB database handle. Source code in app/core/db/db_mongo.py 93 94 95 def get_db ( self ): \"\"\"Return the underlying MongoDB database handle.\"\"\" return self . _db","title":"get_db"},{"location":"database_and_schemas/databases_overview/#app.core.db.db_mongo.MongoDB.get_session","text":"Retrieve session state by ID. Source code in app/core/db/db_mongo.py 48 49 50 51 def get_session ( self , session_id : str ) -> Optional [ dict [ str , Any ]]: \"\"\"Retrieve session state by ID.\"\"\" doc = self . sessions . find_one ({ \"_id\" : session_id }) return doc [ \"state\" ] if doc else None","title":"get_session"},{"location":"database_and_schemas/databases_overview/#app.core.db.db_mongo.MongoDB.list_sessions","text":"Return all session IDs. Source code in app/core/db/db_mongo.py 57 58 59 def list_sessions ( self ): \"\"\"Return all session IDs.\"\"\" return self . sessions . find ({}, { \"_id\" : 1 })","title":"list_sessions"},{"location":"database_and_schemas/databases_overview/#app.core.db.db_mongo.MongoDB.load_json_asset","text":"Fetch a stored JSON file (by _id) from MongoDB and return its content. Parameters: Name Type Description Default file_name str The _id / filename of the JSON file, e.g., 'grouped_sections.json'. required collection_name str The collection where JSON files are stored. Default: 'gspr_assets'. required Returns: Name Type Description dict dict Parsed JSON content stored under 'content'. Raises: Type Description ValueError If the file is not found or has no 'content' field. Source code in app/core/db/db_mongo.py 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 def load_json_asset ( self , file_name : str , collection_name : str ) -> dict : \"\"\" Fetch a stored JSON file (by _id) from MongoDB and return its content. Args: file_name (str): The _id / filename of the JSON file, e.g., 'grouped_sections.json'. collection_name (str): The collection where JSON files are stored. Default: 'gspr_assets'. Returns: dict: Parsed JSON content stored under 'content'. Raises: ValueError: If the file is not found or has no 'content' field. \"\"\" coll = self . _db [ collection_name ] doc = coll . find_one ({ \"_id\" : file_name }) if not doc : raise ValueError ( f \"JSON asset ' { file_name } ' not found in MongoDB collection ' { collection_name } '.\" ) if \"content\" not in doc : raise ValueError ( f \"Document ' { file_name } ' has no 'content' field.\" ) return doc [ \"content\" ]","title":"load_json_asset"},{"location":"database_and_schemas/databases_overview/#app.core.db.db_mongo.MongoDB.load_project","text":"Fetch a project document by ID from ai_projects. Source code in app/core/db/db_mongo.py 88 89 90 def load_project ( self , project_id : str ) -> Optional [ dict [ str , Any ]]: \"\"\"Fetch a project document by ID from ai_projects.\"\"\" return self . projects . find_one ({ \"_id\" : project_id })","title":"load_project"},{"location":"database_and_schemas/databases_overview/#app.core.db.db_mongo.MongoDB.save_project","text":"Upsert a project snapshot from Redis into ai_projects. Source code in app/core/db/db_mongo.py 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 def save_project ( self , project_id : str , session_data : dict [ str , Any ]) -> dict [ str , Any ]: \"\"\"Upsert a project snapshot from Redis into ai_projects.\"\"\" session_data = self . to_serializable ( session_data ) timestamp = datetime . now ( timezone . utc ) self . projects . update_one ( { \"_id\" : project_id }, { \"$set\" : { \"session_data\" : session_data , \"updated_at\" : timestamp , }, \"$setOnInsert\" : { \"created_at\" : timestamp , }, }, upsert = True , ) return { \"project_id\" : project_id , \"updated_at\" : timestamp . isoformat (), \"message\" : \"AI project saved successfully\" , }","title":"save_project"},{"location":"database_and_schemas/databases_overview/#app.core.db.db_mongo.MongoDB.save_session","text":"Insert or update a session state document. Source code in app/core/db/db_mongo.py 39 40 41 42 43 44 45 46 def save_session ( self , session_id : str , state : Any ) -> None : \"\"\"Insert or update a session state document.\"\"\" state = self . to_serializable ( state ) self . sessions . update_one ( { \"_id\" : session_id }, { \"$set\" : { \"state\" : state }}, upsert = True , )","title":"save_session"},{"location":"database_and_schemas/databases_overview/#app.core.db.db_mongo.MongoDB.to_serializable","text":"Recursively convert Pydantic models and nested objects to serializable dicts. Source code in app/core/db/db_mongo.py 28 29 30 31 32 33 34 35 36 def to_serializable ( self , obj : Any ) -> Any : \"\"\"Recursively convert Pydantic models and nested objects to serializable dicts.\"\"\" if isinstance ( obj , BaseModel ): return obj . model_dump () if isinstance ( obj , dict ): return { k : self . to_serializable ( v ) for k , v in obj . items ()} if isinstance ( obj , list ): return [ self . to_serializable ( i ) for i in obj ] return obj","title":"to_serializable"},{"location":"database_and_schemas/databases_overview/#app.core.db.db_mongo.MongoDB.upsert_json_file","text":"Upsert one JSON file into a collection where _id == file_name. Source code in app/core/db/db_mongo.py 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 def upsert_json_file ( self , collection_name : str , file_name : str , json_data : dict , extra : dict | None = None , ) -> None : \"\"\" Upsert one JSON file into a collection where _id == file_name. \"\"\" coll = self . _db [ collection_name ] now = datetime . now ( timezone . utc ) # optional checksum for change detection/debugging digest = sha256 ( str ( json_data ) . encode ( \"utf-8\" )) . hexdigest () doc = { \"_id\" : file_name , # <- your requirement \"name\" : file_name , \"content\" : json_data , # raw JSON goes here \"checksum\" : digest , \"updated_at\" : now , } if extra : doc |= { \"meta\" : self . to_serializable ( extra )} coll . update_one ( { \"_id\" : file_name }, { \"$set\" : { k : v for k , v in doc . items () if k != \"_id\" }, \"$setOnInsert\" : { \"created_at\" : now }, }, upsert = True , )","title":"upsert_json_file"},{"location":"database_and_schemas/databases_overview/#app.core.db.db_mongo.get_mongo_db","text":"FastAPI dependency to inject MongoDB database handle. Source code in app/core/db/db_mongo.py 166 167 168 def get_mongo_db (): \"\"\"FastAPI dependency to inject MongoDB database handle.\"\"\" return mongo_db . get_db ()","title":"get_mongo_db"},{"location":"database_and_schemas/databases_overview/#app.core.db.db_mongo.get_projects_collection","text":"FastAPI dependency to inject the ai_projects collection. Source code in app/core/db/db_mongo.py 181 182 183 def get_projects_collection (): \"\"\"FastAPI dependency to inject the ai_projects collection.\"\"\" return mongo_db . projects","title":"get_projects_collection"},{"location":"database_and_schemas/databases_overview/#app.core.db.db_mongo.get_sessions_collection","text":"FastAPI dependency to inject the sessions collection. Source code in app/core/db/db_mongo.py 171 172 173 def get_sessions_collection (): \"\"\"FastAPI dependency to inject the sessions collection.\"\"\" return mongo_db . sessions","title":"get_sessions_collection"},{"location":"database_and_schemas/databases_overview/#app.core.db.db_mongo.get_users_collection","text":"FastAPI dependency to inject the users collection. Source code in app/core/db/db_mongo.py 176 177 178 def get_users_collection (): \"\"\"FastAPI dependency to inject the users collection.\"\"\" return mongo_db . users","title":"get_users_collection"},{"location":"database_and_schemas/databases_overview/#neo4j-graph-engine-knowledge-graph-for-regulatory-mapping","text":"Graph database powering relationship modeling between device components, classifications, and regulatory dependencies.","title":"\ud83d\udd17 Neo4j Graph Engine \u2014 Knowledge Graph for Regulatory Mapping"},{"location":"database_and_schemas/databases_overview/#app.core.db.db_neo4j.close_neo4j_driver","text":"Gracefully close the driver on shutdown. Source code in app/core/db/db_neo4j.py 24 25 26 27 28 29 async def close_neo4j_driver (): \"\"\"Gracefully close the driver on shutdown.\"\"\" global _neo4j_driver if _neo4j_driver : _neo4j_driver . close () _neo4j_driver = None","title":"close_neo4j_driver"},{"location":"database_and_schemas/databases_overview/#app.core.db.db_neo4j.get_neo4j_driver","text":"Return a shared Neo4j driver instance, lazy-loaded on first access. Source code in app/core/db/db_neo4j.py 13 14 15 16 17 18 19 20 21 def get_neo4j_driver () -> Driver : \"\"\"Return a shared Neo4j driver instance, lazy-loaded on first access.\"\"\" global _neo4j_driver if _neo4j_driver is None : _neo4j_driver = GraphDatabase . driver ( settings . neo4j_bolt_url , auth = ( settings . NEO4J_USER , settings . NEO4J_PASSWORD ), ) return _neo4j_driver","title":"get_neo4j_driver"},{"location":"database_and_schemas/databases_overview/#redis-session-store-ultra-fast-in-memory-workflow-state","text":"High-speed cache used for active session management, temporary workflow state, and rapid data retrieval.","title":"\u26a1 Redis Session Store \u2014 Ultra-Fast In-Memory Workflow State"},{"location":"database_and_schemas/databases_overview/#app.core.db.db_redis.AsyncRedisDB","text":"Bases: BaseRedisDB Async Redis client for streaming and background tasks (Pub/Sub). Source code in app/core/db/db_redis.py 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 class AsyncRedisDB ( BaseRedisDB ): \"\"\"Async Redis client for streaming and background tasks (Pub/Sub).\"\"\" async_mode : bool = True def __init__ ( self ): self . client = aioredis . from_url ( settings . redis_url , decode_responses = True , # ensures str instead of bytes ) # --------------------- Async JSON helpers --------------------- async def set_json ( self , key : str , value : dict [ str , Any ], expire : int | None = None ): data = json . dumps ( value ) if expire : await self . client . setex ( key , expire , data ) else : await self . client . set ( key , data ) async def get_json ( self , key : str ) -> Optional [ dict [ str , Any ]]: data = await self . client . get ( key ) if data is None : return None try : return json . loads ( data ) except json . JSONDecodeError : return None async def delete_key ( self , key : str ) -> bool : result = await self . client . delete ( key ) return result > 0 async def key_exists ( self , key : str ) -> bool : return await self . client . exists ( key ) == 1 async def scan_keys ( self , pattern : str ): \"\"\"Async iterator over matching keys.\"\"\" async for key in self . client . scan_iter ( match = pattern ): yield key # --------------------- Pub/Sub for SSE --------------------- async def subscribe ( self , channel_name : str ) -> AsyncGenerator [ str , None ]: \"\"\"Async generator yielding messages from a Redis channel.\"\"\" pubsub = self . client . pubsub () await pubsub . subscribe ( channel_name ) try : async for message in pubsub . listen (): if message [ \"type\" ] == \"message\" : yield message [ \"data\" ] except GeneratorExit : # \u2705 This happens when the consumer (SSE) stops iteration \u2014 normal shutdown. pass except Exception as e : # \u2705 Ignore expected connection closures if \"Connection lost\" not in str ( e ): print ( f \"[Redis Subscribe] Unexpected error: { e } \" ) finally : try : await pubsub . unsubscribe ( channel_name ) await pubsub . aclose () except ConnectionError : # \u2705 Ignore close errors after connection lost pass async def _close ( self ): await self . client . aclose ()","title":"AsyncRedisDB"},{"location":"database_and_schemas/databases_overview/#app.core.db.db_redis.AsyncRedisDB.scan_keys","text":"Async iterator over matching keys. Source code in app/core/db/db_redis.py 117 118 119 120 async def scan_keys ( self , pattern : str ): \"\"\"Async iterator over matching keys.\"\"\" async for key in self . client . scan_iter ( match = pattern ): yield key","title":"scan_keys"},{"location":"database_and_schemas/databases_overview/#app.core.db.db_redis.AsyncRedisDB.subscribe","text":"Async generator yielding messages from a Redis channel. Source code in app/core/db/db_redis.py 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 async def subscribe ( self , channel_name : str ) -> AsyncGenerator [ str , None ]: \"\"\"Async generator yielding messages from a Redis channel.\"\"\" pubsub = self . client . pubsub () await pubsub . subscribe ( channel_name ) try : async for message in pubsub . listen (): if message [ \"type\" ] == \"message\" : yield message [ \"data\" ] except GeneratorExit : # \u2705 This happens when the consumer (SSE) stops iteration \u2014 normal shutdown. pass except Exception as e : # \u2705 Ignore expected connection closures if \"Connection lost\" not in str ( e ): print ( f \"[Redis Subscribe] Unexpected error: { e } \" ) finally : try : await pubsub . unsubscribe ( channel_name ) await pubsub . aclose () except ConnectionError : # \u2705 Ignore close errors after connection lost pass","title":"subscribe"},{"location":"database_and_schemas/databases_overview/#app.core.db.db_redis.BaseRedisDB","text":"Common interface for Redis operations (sync or async). Source code in app/core/db/db_redis.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 class BaseRedisDB : \"\"\"Common interface for Redis operations (sync or async).\"\"\" async_mode : bool = False def set_json ( self , key : str , value : dict [ str , Any ], expire : int | None = None ): raise NotImplementedError def get_json ( self , key : str ): raise NotImplementedError def delete_key ( self , key : str ): raise NotImplementedError def key_exists ( self , key : str ): raise NotImplementedError def scan_keys ( self , pattern : str ): raise NotImplementedError","title":"BaseRedisDB"},{"location":"database_and_schemas/databases_overview/#app.core.db.db_redis.SyncRedisDB","text":"Bases: BaseRedisDB Wrapper class for Redis operations used in the app. Source code in app/core/db/db_redis.py 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 class SyncRedisDB ( BaseRedisDB ): \"\"\"Wrapper class for Redis operations used in the app.\"\"\" async_mode : bool = False def __init__ ( self ): self . client = redis . Redis . from_url ( settings . redis_url , decode_responses = True , # ensures strings, not bytes ) def set_json ( self , key : str , value : dict [ str , Any ], expire : int | None = None ): data = json . dumps ( value ) if expire : self . client . setex ( key , expire , data ) else : self . client . set ( key , data ) def get_json ( self , key : str ) -> Optional [ dict [ str , Any ]]: data = self . client . get ( key ) data = cast ( Optional [ str ], data ) if data is None : return None try : return json . loads ( data ) except json . JSONDecodeError : return None def delete_key ( self , key : str ) -> bool : result = self . client . delete ( key ) result = cast ( int , result ) return result > 0 def key_exists ( self , key : str ) -> bool : return self . client . exists ( key ) == 1 def scan_keys ( self , pattern : str ): yield from self . client . scan_iter ( match = pattern ) def _close ( self ): self . client . close () print ( \"[Redis] Sync client closed.\" )","title":"SyncRedisDB"},{"location":"database_and_schemas/databases_overview/#app.core.db.db_redis.get_redis","text":"FastAPI dependency for injecting Redis connection wrapper. Example get_redis() \u2192 sync Redis client get_redis(async_mode=True) \u2192 async Redis client (aioredis) Usage in FastAPI routes @router.get(\"/stream/{job_id}\") async def stream_job(job_id: str, redis: AsyncRedisDB = Depends(lambda: get_redis(async_mode=True))): ... @router.post(\"/session/{id}\") def update_session(id: str, redis: RedisDB = Depends(get_redis)): ... Source code in app/core/db/db_redis.py 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 def get_redis ( async_mode : bool = False ) -> BaseRedisDB : \"\"\" FastAPI dependency for injecting Redis connection wrapper. Example: - get_redis() \u2192 sync Redis client - get_redis(async_mode=True) \u2192 async Redis client (aioredis) Usage in FastAPI routes: @router.get(\"/stream/{job_id}\") async def stream_job(job_id: str, redis: AsyncRedisDB = Depends(lambda: get_redis(async_mode=True))): ... @router.post(\"/session/{id}\") def update_session(id: str, redis: RedisDB = Depends(get_redis)): ... \"\"\" return async_redis_db if async_mode else sync_redis_db","title":"get_redis"},{"location":"database_and_schemas/other/","text":"\u2699\ufe0f Core System & Utilities Reference A structured and enhanced overview of key internal modules powering the Regulatory AI backend. \ud83e\udde0 Job Manager \u2014 Task Orchestration & Background Processing Handles asynchronous job execution, tracking, and lifecycle management. JobManager Tracks job progress and publishes real-time events via Redis Pub/Sub. Redis usage job:{id}:progress \u2192 JSON (TTL 6h) \u2192 job state counters event:{id}:stream \u2192 Pub/Sub channel \u2192 live progress messages Source code in app/core/state/job_manager.py 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 class JobManager : \"\"\"Tracks job progress and publishes real-time events via Redis Pub/Sub. Redis usage: - job:{id}:progress \u2192 JSON (TTL 6h) \u2192 job state counters - event:{id}:stream \u2192 Pub/Sub channel \u2192 live progress messages \"\"\" JOB_PREFIX = \"job:\" JOB_SUFFIX = \":progress\" EVENT_PREFIX = \"event:\" EVENT_SUFFIX = \":stream\" PROGRESS_TTL_SECONDS = 3 * 60 * 60 # 3 hours def __init__ ( self , redis_db : RedisDB | None = None ): self . redis = redis_db or RedisDB () self . progress = self . _ProgressStore ( self . redis ) self . events = self . _EventPublisher ( self . redis ) # ========================== # Inner class: Progress Store # ========================== class _ProgressStore : def __init__ ( self , redis : RedisDB ): self . redis = redis def _key ( self , job_id : str ) -> str : return f \" { JobManager . JOB_PREFIX }{ job_id }{ JobManager . JOB_SUFFIX } \" def create ( self , job_id : str , total_sections : int ) -> JobProgress : progress = JobProgress ( job_id = job_id , total = total_sections , status = \"running\" , started_at = time . time (), ) self . redis . set_json ( self . _key ( job_id ), progress . to_dict (), expire = JobManager . PROGRESS_TTL_SECONDS , ) return progress def get ( self , job_id : str ) -> dict [ str , Any ] | None : return self . redis . get_json ( self . _key ( job_id )) def update ( self , job_id : str , * , inc_completed : int = 0 , inc_failed : int = 0 , ) -> dict [ str , Any ]: key = self . _key ( job_id ) data = self . redis . get_json ( key ) or {} completed = int ( data . get ( \"completed\" , 0 )) + inc_completed failed = int ( data . get ( \"failed\" , 0 )) + inc_failed total = int ( data . get ( \"total\" , 0 )) status : ProgressStatus = data . get ( \"status\" , \"running\" ) started_at = data . get ( \"started_at\" ) finished_at = data . get ( \"finished_at\" ) pending = max ( total - completed - failed , 0 ) percent = round (( completed / total ) * 100 , 2 ) if total > 0 else 0.0 total_time = None if started_at and finished_at : total_time = round ( float ( finished_at ) - float ( started_at ), 2 ) new_doc = { \"job_id\" : job_id , \"total\" : total , \"completed\" : completed , \"failed\" : failed , \"pending\" : pending , \"percent\" : percent , \"status\" : status , \"started_at\" : started_at , \"finished_at\" : finished_at , \"total_time\" : total_time , } self . redis . set_json ( key , new_doc , expire = JobManager . PROGRESS_TTL_SECONDS ) return new_doc def mark_completed ( self , job_id : str , * , failed : bool = False ) -> dict [ str , Any ]: key = self . _key ( job_id ) data = self . redis . get_json ( key ) or {} finished_at = time . time () started_at = data . get ( \"started_at\" ) total_time = None if started_at : total_time = round ( float ( finished_at ) - float ( started_at ), 2 ) data . update ( { \"status\" : \"failed\" if failed else \"completed\" , \"finished_at\" : finished_at , \"total_time\" : total_time , } ) self . redis . set_json ( key , data , expire = JobManager . PROGRESS_TTL_SECONDS ) return data def delete ( self , job_id : str ) -> None : \"\"\"Optional manual cleanup (TTL handles auto-expiry).\"\"\" self . redis . delete_key ( self . _key ( job_id )) # ========================== # Inner class: Event Publisher # ========================== class _EventPublisher : def __init__ ( self , redis : RedisDB ): self . redis = redis def channel ( self , job_id : str ) -> str : return f \" { JobManager . EVENT_PREFIX }{ job_id }{ JobManager . EVENT_SUFFIX } \" def _publish ( self , job_id : str , event_type : str , payload : dict [ str , Any ]) -> None : message = json . dumps ( { \"event\" : event_type , \"job_id\" : job_id , \"data\" : payload , \"ts\" : time . time (), } ) self . redis . client . publish ( self . channel ( job_id ), message ) # Convenience emitters for common event types def job_started ( self , job_id : str , total : int ) -> None : self . _publish ( job_id , \"job_started\" , { \"total\" : total }) def job_progress ( self , job_id : str , snapshot : dict [ str , Any ]) -> None : self . _publish ( job_id , \"job_progress\" , snapshot ) def job_completed ( self , job_id : str , summary : dict [ str , Any ]) -> None : self . _publish ( job_id , \"job_completed\" , { \"status\" : summary . get ( \"status\" ), \"summary\" : summary }) def section_started ( self , job_id : str , section_no : int , section_id : Any , requirement_type : str , title : str ) -> None : self . _publish ( job_id , \"section_started\" , { \"section_no\" : section_no , \"section_id\" : section_id , \"title\" : title , \"requirement_type\" : requirement_type , }, ) def section_completed ( self , job_id : str , section_no : int , title : str , requirement_type : str , section_id : Any , applicable : bool , requirement_justification : str , standard : Any ) -> None : self . _publish ( job_id , \"section_completed\" , { \"section_no\" : section_no , \"section_id\" : section_id , \"title\" : title , \"requirement_type\" : requirement_type , \"applicable\" : applicable , \"requirement_justification\" : requirement_justification , \"standard\" : standard , }, ) def section_failed ( self , job_id : str , section_no : int , error : str , attempts : int ) -> None : self . _publish ( job_id , \"section_failed\" , { \"section_no\" : section_no , \"error\" : error , \"attempts\" : attempts }, ) # ========================== # Public unified API wrappers # ========================== def create_job ( self , job_id : str , total_sections : int ) -> JobProgress : progress = self . progress . create ( job_id , total_sections ) self . events . job_started ( job_id , total_sections ) return progress def get_progress ( self , job_id : str ) -> dict [ str , Any ] | None : return self . progress . get ( job_id ) def update_progress ( self , job_id : str , * , inc_completed : int = 0 , inc_failed : int = 0 ) -> dict [ str , Any ]: snapshot = self . progress . update ( job_id , inc_completed = inc_completed , inc_failed = inc_failed ) self . events . job_progress ( job_id , snapshot ) return snapshot def mark_completed ( self , job_id : str , * , failed : bool = False ) -> dict [ str , Any ]: summary = self . progress . mark_completed ( job_id , failed = failed ) self . events . job_completed ( job_id , summary ) return summary def delete_job ( self , job_id : str ) -> None : self . progress . delete ( job_id ) JobProgress dataclass Represents the current progress of a job stored in Redis JSON. Source code in app/core/state/job_manager.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 @dataclass class JobProgress : \"\"\"Represents the current progress of a job stored in Redis JSON.\"\"\" job_id : str total : int completed : int = 0 failed : int = 0 status : ProgressStatus = \"pending\" started_at : float | None = None finished_at : float | None = None total_time : float | None = None @property def pending ( self ) -> int : return max ( self . total - self . completed - self . failed , 0 ) @property def percent ( self ) -> float : if self . total <= 0 : return 0.0 return round (( self . completed / self . total ) * 100 , 2 ) def to_dict ( self ) -> dict [ str , Any ]: started = float ( self . started_at ) if self . started_at is not None else None finished = float ( self . finished_at ) if self . finished_at is not None else None total_time = None if started is not None and finished is not None : total_time = round ( finished - started , 2 ) return { \"job_id\" : self . job_id , \"total\" : self . total , \"completed\" : self . completed , \"failed\" : self . failed , \"pending\" : self . pending , \"percent\" : self . percent , \"status\" : self . status , \"started_at\" : started , \"finished_at\" : finished , \"total_time\" : total_time , } \ud83d\uddc2\ufe0f Session Manager \u2014 Redis Session Handling Manages session lifecycle, nested updates, and persistent in-memory state. SessionManager Handles session creation, retrieval, and persistence in Redis. Source code in app/core/state/session_manager.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 class SessionManager : \"\"\"Handles session creation, retrieval, and persistence in Redis.\"\"\" REDIS_KEY_PREFIX = \"session:\" EXPIRATION_SECONDS = 2 * 24 * 3600 # 2 days LOCAL_CACHE_TTL = 600 # 10 minutes (in-memory cache) MAX_CACHE_SIZE = 1000 # max 1000 sessions in local cache def __init__ ( self ): self . redis_db = get_redis () self . session_cache = TTLCache ( maxsize = self . MAX_CACHE_SIZE , ttl = self . LOCAL_CACHE_TTL ) # short-lived in-process cache (max 1000 active sessions) self . latest_session_id : Optional [ str ] = None def _build_key ( self , session_id : str ) -> str : return f \" { self . REDIS_KEY_PREFIX }{ session_id } \" # --------------------- CREATE --------------------- def create_session ( self , initial_state : dict [ str , Any ], expire : int | None = EXPIRATION_SECONDS ) -> str : \"\"\"Create a new session with initial state and store in Redis.\"\"\" session_id = str ( uuid . uuid4 ()) redis_key = self . _build_key ( session_id ) # store in Redis (with optional expiry) self . redis_db . set_json ( redis_key , initial_state , expire = expire ) # Cache locally (fast access) self . session_cache [ session_id ] = initial_state self . latest_session_id = session_id return session_id # --------------------- READ --------------------- def get_session ( self , session_id : str ) -> Optional [ dict [ str , Any ]]: \"\"\"Get session from local cache first; fallback to Redis.\"\"\" # Try cache if session_id in self . session_cache : return self . session_cache [ session_id ] # Fallback to Redis redis_key = self . _build_key ( session_id ) data = self . redis_db . get_json ( redis_key ) if data : # Store in cache for future quick access self . session_cache [ session_id ] = data return data # --------------------- UPDATE --------------------- def update_session ( self , session_id : str , new_state : dict [ str , Any ]) -> bool : \"\"\"Update session in Redis and refresh local cache.\"\"\" redis_key = self . _build_key ( session_id ) # Fetch current state (cache or Redis) current_state = self . get_session ( session_id ) if current_state is None : return False # Merge updates current_state . update ( new_state ) # Save updated data back to Redis self . redis_db . set_json ( redis_key , current_state , expire = self . EXPIRATION_SECONDS ) # Refresh local cache self . session_cache [ session_id ] = current_state return True # --------------------- DELETE --------------------- def delete_session ( self , session_id : str ) -> bool : \"\"\"Delete session from Redis.\"\"\" redis_key = self . _build_key ( session_id ) result = self . redis_db . delete_key ( redis_key ) # Remove from local cache if it exists self . session_cache . pop ( session_id , None ) return result def session_exists ( self , session_id : str ) -> bool : \"\"\"Check if session exists (cache or Redis).\"\"\" if session_id in self . session_cache : return True redis_key = self . _build_key ( session_id ) return self . redis_db . key_exists ( redis_key ) def get_all_sessions ( self ) -> list [ str ]: \"\"\"Return all active session IDs (based on key scan).\"\"\" pattern = f \" { self . REDIS_KEY_PREFIX } *\" keys = list ( self . redis_db . scan_keys ( pattern )) return [ key . replace ( self . REDIS_KEY_PREFIX , \"\" ) for key in keys ] def get_latest_session_id ( self ) -> Optional [ str ]: return self . latest_session_id def set_session ( self , session_id : str , state : dict [ str , Any ], ttl : int | None = None ) -> None : \"\"\"Directly set or overwrite a session in Redis and local cache.\"\"\" redis_key = self . _build_key ( session_id ) self . redis_db . set_json ( redis_key , state , expire = ttl or self . EXPIRATION_SECONDS ) self . session_cache [ session_id ] = state self . latest_session_id = session_id def clone_to_new_session ( self , session_data : dict ) -> str : \"\"\"Create a new Redis session from an existing project snapshot.\"\"\" new_id = str ( uuid . uuid4 ()) cloned_data = session_data . copy () # avoid mutating the original cloned_data [ \"restored_at\" ] = time . time () self . set_session ( new_id , cloned_data ) return new_id # --------------------- NESTED UPDATE --------------------- def deep_update ( self , original : dict , updates : dict ) -> dict : \"\"\"Recursively update a nested dictionary.\"\"\" for key , value in updates . items (): if isinstance ( value , dict ) and isinstance ( original . get ( key ), dict ): self . deep_update ( original [ key ], value ) else : original [ key ] = value return original def update_nested ( self , session_id : str , updates : dict [ str , Any ]) -> bool : state = self . get_session ( session_id ) if state is None : return False self . update_session ( session_id , self . deep_update ( state , updates )) return True clone_to_new_session ( session_data ) Create a new Redis session from an existing project snapshot. Source code in app/core/state/session_manager.py 112 113 114 115 116 117 118 def clone_to_new_session ( self , session_data : dict ) -> str : \"\"\"Create a new Redis session from an existing project snapshot.\"\"\" new_id = str ( uuid . uuid4 ()) cloned_data = session_data . copy () # avoid mutating the original cloned_data [ \"restored_at\" ] = time . time () self . set_session ( new_id , cloned_data ) return new_id create_session ( initial_state , expire = EXPIRATION_SECONDS ) Create a new session with initial state and store in Redis. Source code in app/core/state/session_manager.py 30 31 32 33 34 35 36 37 38 39 40 41 def create_session ( self , initial_state : dict [ str , Any ], expire : int | None = EXPIRATION_SECONDS ) -> str : \"\"\"Create a new session with initial state and store in Redis.\"\"\" session_id = str ( uuid . uuid4 ()) redis_key = self . _build_key ( session_id ) # store in Redis (with optional expiry) self . redis_db . set_json ( redis_key , initial_state , expire = expire ) # Cache locally (fast access) self . session_cache [ session_id ] = initial_state self . latest_session_id = session_id return session_id deep_update ( original , updates ) Recursively update a nested dictionary. Source code in app/core/state/session_manager.py 121 122 123 124 125 126 127 128 def deep_update ( self , original : dict , updates : dict ) -> dict : \"\"\"Recursively update a nested dictionary.\"\"\" for key , value in updates . items (): if isinstance ( value , dict ) and isinstance ( original . get ( key ), dict ): self . deep_update ( original [ key ], value ) else : original [ key ] = value return original delete_session ( session_id ) Delete session from Redis. Source code in app/core/state/session_manager.py 79 80 81 82 83 84 85 86 87 def delete_session ( self , session_id : str ) -> bool : \"\"\"Delete session from Redis.\"\"\" redis_key = self . _build_key ( session_id ) result = self . redis_db . delete_key ( redis_key ) # Remove from local cache if it exists self . session_cache . pop ( session_id , None ) return result get_all_sessions () Return all active session IDs (based on key scan). Source code in app/core/state/session_manager.py 96 97 98 99 100 def get_all_sessions ( self ) -> list [ str ]: \"\"\"Return all active session IDs (based on key scan).\"\"\" pattern = f \" { self . REDIS_KEY_PREFIX } *\" keys = list ( self . redis_db . scan_keys ( pattern )) return [ key . replace ( self . REDIS_KEY_PREFIX , \"\" ) for key in keys ] get_session ( session_id ) Get session from local cache first; fallback to Redis. Source code in app/core/state/session_manager.py 44 45 46 47 48 49 50 51 52 53 54 55 56 def get_session ( self , session_id : str ) -> Optional [ dict [ str , Any ]]: \"\"\"Get session from local cache first; fallback to Redis.\"\"\" # Try cache if session_id in self . session_cache : return self . session_cache [ session_id ] # Fallback to Redis redis_key = self . _build_key ( session_id ) data = self . redis_db . get_json ( redis_key ) if data : # Store in cache for future quick access self . session_cache [ session_id ] = data return data session_exists ( session_id ) Check if session exists (cache or Redis). Source code in app/core/state/session_manager.py 89 90 91 92 93 94 def session_exists ( self , session_id : str ) -> bool : \"\"\"Check if session exists (cache or Redis).\"\"\" if session_id in self . session_cache : return True redis_key = self . _build_key ( session_id ) return self . redis_db . key_exists ( redis_key ) set_session ( session_id , state , ttl = None ) Directly set or overwrite a session in Redis and local cache. Source code in app/core/state/session_manager.py 105 106 107 108 109 110 def set_session ( self , session_id : str , state : dict [ str , Any ], ttl : int | None = None ) -> None : \"\"\"Directly set or overwrite a session in Redis and local cache.\"\"\" redis_key = self . _build_key ( session_id ) self . redis_db . set_json ( redis_key , state , expire = ttl or self . EXPIRATION_SECONDS ) self . session_cache [ session_id ] = state self . latest_session_id = session_id update_session ( session_id , new_state ) Update session in Redis and refresh local cache. Source code in app/core/state/session_manager.py 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 def update_session ( self , session_id : str , new_state : dict [ str , Any ]) -> bool : \"\"\"Update session in Redis and refresh local cache.\"\"\" redis_key = self . _build_key ( session_id ) # Fetch current state (cache or Redis) current_state = self . get_session ( session_id ) if current_state is None : return False # Merge updates current_state . update ( new_state ) # Save updated data back to Redis self . redis_db . set_json ( redis_key , current_state , expire = self . EXPIRATION_SECONDS ) # Refresh local cache self . session_cache [ session_id ] = current_state return True \ud83e\udde9 State Utilities \u2014 Internal Helpers Utility functions used for cleaning, merging, and structuring backend state. deep_update ( original , updates ) Recursively update a nested dictionary. Source code in app/core/state/utils/state_utils.py 5 6 7 8 9 10 11 12 def deep_update ( original : dict , updates : dict ) -> dict : \"\"\"Recursively update a nested dictionary.\"\"\" for key , value in updates . items (): if isinstance ( value , dict ) and isinstance ( original . get ( key ), dict ): deep_update ( original [ key ], value ) else : original [ key ] = value return original \ud83d\udd27 App Configuration Centralized configuration loader for environment variables, constants, and system-wide settings. \ud83d\udea8 Error Handlers \u2014 Unified Error Responses Custom exception handlers that ensure consistent error payloads across all APIs. \ud83d\ude80 Startup Utilities \u2014 Initialization Logic Handles boot-time actions such as DB connections, cache initialization, and worker startup. \ud83c\udfc1 Application Entry Point \u2014 FastAPI App Loader Main FastAPI instance, router registry, middleware loading, and lifecycle events. main () CLI entrypoint for running the FastAPI app via uv run app . Source code in app/main.py 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 def main (): \"\"\"CLI entrypoint for running the FastAPI app via `uv run app`.\"\"\" from regulatory.utils.logger import log_config , logger_service as logger import uvicorn logger . info ( \"Starting Regulatory AI FastAPI Backend with uvicorn...\" ) uvicorn . run ( \"regulatory.app.main:app\" , host = \"0.0.0.0\" , port = 8765 , reload = True , log_config = log_config , log_level = \"info\" , )","title":"Other"},{"location":"database_and_schemas/other/#core-system-utilities-reference","text":"A structured and enhanced overview of key internal modules powering the Regulatory AI backend.","title":"\u2699\ufe0f Core System &amp; Utilities Reference"},{"location":"database_and_schemas/other/#job-manager-task-orchestration-background-processing","text":"Handles asynchronous job execution, tracking, and lifecycle management.","title":"\ud83e\udde0 Job Manager \u2014 Task Orchestration &amp; Background Processing"},{"location":"database_and_schemas/other/#app.core.state.job_manager.JobManager","text":"Tracks job progress and publishes real-time events via Redis Pub/Sub. Redis usage job:{id}:progress \u2192 JSON (TTL 6h) \u2192 job state counters event:{id}:stream \u2192 Pub/Sub channel \u2192 live progress messages Source code in app/core/state/job_manager.py 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 class JobManager : \"\"\"Tracks job progress and publishes real-time events via Redis Pub/Sub. Redis usage: - job:{id}:progress \u2192 JSON (TTL 6h) \u2192 job state counters - event:{id}:stream \u2192 Pub/Sub channel \u2192 live progress messages \"\"\" JOB_PREFIX = \"job:\" JOB_SUFFIX = \":progress\" EVENT_PREFIX = \"event:\" EVENT_SUFFIX = \":stream\" PROGRESS_TTL_SECONDS = 3 * 60 * 60 # 3 hours def __init__ ( self , redis_db : RedisDB | None = None ): self . redis = redis_db or RedisDB () self . progress = self . _ProgressStore ( self . redis ) self . events = self . _EventPublisher ( self . redis ) # ========================== # Inner class: Progress Store # ========================== class _ProgressStore : def __init__ ( self , redis : RedisDB ): self . redis = redis def _key ( self , job_id : str ) -> str : return f \" { JobManager . JOB_PREFIX }{ job_id }{ JobManager . JOB_SUFFIX } \" def create ( self , job_id : str , total_sections : int ) -> JobProgress : progress = JobProgress ( job_id = job_id , total = total_sections , status = \"running\" , started_at = time . time (), ) self . redis . set_json ( self . _key ( job_id ), progress . to_dict (), expire = JobManager . PROGRESS_TTL_SECONDS , ) return progress def get ( self , job_id : str ) -> dict [ str , Any ] | None : return self . redis . get_json ( self . _key ( job_id )) def update ( self , job_id : str , * , inc_completed : int = 0 , inc_failed : int = 0 , ) -> dict [ str , Any ]: key = self . _key ( job_id ) data = self . redis . get_json ( key ) or {} completed = int ( data . get ( \"completed\" , 0 )) + inc_completed failed = int ( data . get ( \"failed\" , 0 )) + inc_failed total = int ( data . get ( \"total\" , 0 )) status : ProgressStatus = data . get ( \"status\" , \"running\" ) started_at = data . get ( \"started_at\" ) finished_at = data . get ( \"finished_at\" ) pending = max ( total - completed - failed , 0 ) percent = round (( completed / total ) * 100 , 2 ) if total > 0 else 0.0 total_time = None if started_at and finished_at : total_time = round ( float ( finished_at ) - float ( started_at ), 2 ) new_doc = { \"job_id\" : job_id , \"total\" : total , \"completed\" : completed , \"failed\" : failed , \"pending\" : pending , \"percent\" : percent , \"status\" : status , \"started_at\" : started_at , \"finished_at\" : finished_at , \"total_time\" : total_time , } self . redis . set_json ( key , new_doc , expire = JobManager . PROGRESS_TTL_SECONDS ) return new_doc def mark_completed ( self , job_id : str , * , failed : bool = False ) -> dict [ str , Any ]: key = self . _key ( job_id ) data = self . redis . get_json ( key ) or {} finished_at = time . time () started_at = data . get ( \"started_at\" ) total_time = None if started_at : total_time = round ( float ( finished_at ) - float ( started_at ), 2 ) data . update ( { \"status\" : \"failed\" if failed else \"completed\" , \"finished_at\" : finished_at , \"total_time\" : total_time , } ) self . redis . set_json ( key , data , expire = JobManager . PROGRESS_TTL_SECONDS ) return data def delete ( self , job_id : str ) -> None : \"\"\"Optional manual cleanup (TTL handles auto-expiry).\"\"\" self . redis . delete_key ( self . _key ( job_id )) # ========================== # Inner class: Event Publisher # ========================== class _EventPublisher : def __init__ ( self , redis : RedisDB ): self . redis = redis def channel ( self , job_id : str ) -> str : return f \" { JobManager . EVENT_PREFIX }{ job_id }{ JobManager . EVENT_SUFFIX } \" def _publish ( self , job_id : str , event_type : str , payload : dict [ str , Any ]) -> None : message = json . dumps ( { \"event\" : event_type , \"job_id\" : job_id , \"data\" : payload , \"ts\" : time . time (), } ) self . redis . client . publish ( self . channel ( job_id ), message ) # Convenience emitters for common event types def job_started ( self , job_id : str , total : int ) -> None : self . _publish ( job_id , \"job_started\" , { \"total\" : total }) def job_progress ( self , job_id : str , snapshot : dict [ str , Any ]) -> None : self . _publish ( job_id , \"job_progress\" , snapshot ) def job_completed ( self , job_id : str , summary : dict [ str , Any ]) -> None : self . _publish ( job_id , \"job_completed\" , { \"status\" : summary . get ( \"status\" ), \"summary\" : summary }) def section_started ( self , job_id : str , section_no : int , section_id : Any , requirement_type : str , title : str ) -> None : self . _publish ( job_id , \"section_started\" , { \"section_no\" : section_no , \"section_id\" : section_id , \"title\" : title , \"requirement_type\" : requirement_type , }, ) def section_completed ( self , job_id : str , section_no : int , title : str , requirement_type : str , section_id : Any , applicable : bool , requirement_justification : str , standard : Any ) -> None : self . _publish ( job_id , \"section_completed\" , { \"section_no\" : section_no , \"section_id\" : section_id , \"title\" : title , \"requirement_type\" : requirement_type , \"applicable\" : applicable , \"requirement_justification\" : requirement_justification , \"standard\" : standard , }, ) def section_failed ( self , job_id : str , section_no : int , error : str , attempts : int ) -> None : self . _publish ( job_id , \"section_failed\" , { \"section_no\" : section_no , \"error\" : error , \"attempts\" : attempts }, ) # ========================== # Public unified API wrappers # ========================== def create_job ( self , job_id : str , total_sections : int ) -> JobProgress : progress = self . progress . create ( job_id , total_sections ) self . events . job_started ( job_id , total_sections ) return progress def get_progress ( self , job_id : str ) -> dict [ str , Any ] | None : return self . progress . get ( job_id ) def update_progress ( self , job_id : str , * , inc_completed : int = 0 , inc_failed : int = 0 ) -> dict [ str , Any ]: snapshot = self . progress . update ( job_id , inc_completed = inc_completed , inc_failed = inc_failed ) self . events . job_progress ( job_id , snapshot ) return snapshot def mark_completed ( self , job_id : str , * , failed : bool = False ) -> dict [ str , Any ]: summary = self . progress . mark_completed ( job_id , failed = failed ) self . events . job_completed ( job_id , summary ) return summary def delete_job ( self , job_id : str ) -> None : self . progress . delete ( job_id )","title":"JobManager"},{"location":"database_and_schemas/other/#app.core.state.job_manager.JobProgress","text":"Represents the current progress of a job stored in Redis JSON. Source code in app/core/state/job_manager.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 @dataclass class JobProgress : \"\"\"Represents the current progress of a job stored in Redis JSON.\"\"\" job_id : str total : int completed : int = 0 failed : int = 0 status : ProgressStatus = \"pending\" started_at : float | None = None finished_at : float | None = None total_time : float | None = None @property def pending ( self ) -> int : return max ( self . total - self . completed - self . failed , 0 ) @property def percent ( self ) -> float : if self . total <= 0 : return 0.0 return round (( self . completed / self . total ) * 100 , 2 ) def to_dict ( self ) -> dict [ str , Any ]: started = float ( self . started_at ) if self . started_at is not None else None finished = float ( self . finished_at ) if self . finished_at is not None else None total_time = None if started is not None and finished is not None : total_time = round ( finished - started , 2 ) return { \"job_id\" : self . job_id , \"total\" : self . total , \"completed\" : self . completed , \"failed\" : self . failed , \"pending\" : self . pending , \"percent\" : self . percent , \"status\" : self . status , \"started_at\" : started , \"finished_at\" : finished , \"total_time\" : total_time , }","title":"JobProgress"},{"location":"database_and_schemas/other/#session-manager-redis-session-handling","text":"Manages session lifecycle, nested updates, and persistent in-memory state.","title":"\ud83d\uddc2\ufe0f Session Manager \u2014 Redis Session Handling"},{"location":"database_and_schemas/other/#app.core.state.session_manager.SessionManager","text":"Handles session creation, retrieval, and persistence in Redis. Source code in app/core/state/session_manager.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 class SessionManager : \"\"\"Handles session creation, retrieval, and persistence in Redis.\"\"\" REDIS_KEY_PREFIX = \"session:\" EXPIRATION_SECONDS = 2 * 24 * 3600 # 2 days LOCAL_CACHE_TTL = 600 # 10 minutes (in-memory cache) MAX_CACHE_SIZE = 1000 # max 1000 sessions in local cache def __init__ ( self ): self . redis_db = get_redis () self . session_cache = TTLCache ( maxsize = self . MAX_CACHE_SIZE , ttl = self . LOCAL_CACHE_TTL ) # short-lived in-process cache (max 1000 active sessions) self . latest_session_id : Optional [ str ] = None def _build_key ( self , session_id : str ) -> str : return f \" { self . REDIS_KEY_PREFIX }{ session_id } \" # --------------------- CREATE --------------------- def create_session ( self , initial_state : dict [ str , Any ], expire : int | None = EXPIRATION_SECONDS ) -> str : \"\"\"Create a new session with initial state and store in Redis.\"\"\" session_id = str ( uuid . uuid4 ()) redis_key = self . _build_key ( session_id ) # store in Redis (with optional expiry) self . redis_db . set_json ( redis_key , initial_state , expire = expire ) # Cache locally (fast access) self . session_cache [ session_id ] = initial_state self . latest_session_id = session_id return session_id # --------------------- READ --------------------- def get_session ( self , session_id : str ) -> Optional [ dict [ str , Any ]]: \"\"\"Get session from local cache first; fallback to Redis.\"\"\" # Try cache if session_id in self . session_cache : return self . session_cache [ session_id ] # Fallback to Redis redis_key = self . _build_key ( session_id ) data = self . redis_db . get_json ( redis_key ) if data : # Store in cache for future quick access self . session_cache [ session_id ] = data return data # --------------------- UPDATE --------------------- def update_session ( self , session_id : str , new_state : dict [ str , Any ]) -> bool : \"\"\"Update session in Redis and refresh local cache.\"\"\" redis_key = self . _build_key ( session_id ) # Fetch current state (cache or Redis) current_state = self . get_session ( session_id ) if current_state is None : return False # Merge updates current_state . update ( new_state ) # Save updated data back to Redis self . redis_db . set_json ( redis_key , current_state , expire = self . EXPIRATION_SECONDS ) # Refresh local cache self . session_cache [ session_id ] = current_state return True # --------------------- DELETE --------------------- def delete_session ( self , session_id : str ) -> bool : \"\"\"Delete session from Redis.\"\"\" redis_key = self . _build_key ( session_id ) result = self . redis_db . delete_key ( redis_key ) # Remove from local cache if it exists self . session_cache . pop ( session_id , None ) return result def session_exists ( self , session_id : str ) -> bool : \"\"\"Check if session exists (cache or Redis).\"\"\" if session_id in self . session_cache : return True redis_key = self . _build_key ( session_id ) return self . redis_db . key_exists ( redis_key ) def get_all_sessions ( self ) -> list [ str ]: \"\"\"Return all active session IDs (based on key scan).\"\"\" pattern = f \" { self . REDIS_KEY_PREFIX } *\" keys = list ( self . redis_db . scan_keys ( pattern )) return [ key . replace ( self . REDIS_KEY_PREFIX , \"\" ) for key in keys ] def get_latest_session_id ( self ) -> Optional [ str ]: return self . latest_session_id def set_session ( self , session_id : str , state : dict [ str , Any ], ttl : int | None = None ) -> None : \"\"\"Directly set or overwrite a session in Redis and local cache.\"\"\" redis_key = self . _build_key ( session_id ) self . redis_db . set_json ( redis_key , state , expire = ttl or self . EXPIRATION_SECONDS ) self . session_cache [ session_id ] = state self . latest_session_id = session_id def clone_to_new_session ( self , session_data : dict ) -> str : \"\"\"Create a new Redis session from an existing project snapshot.\"\"\" new_id = str ( uuid . uuid4 ()) cloned_data = session_data . copy () # avoid mutating the original cloned_data [ \"restored_at\" ] = time . time () self . set_session ( new_id , cloned_data ) return new_id # --------------------- NESTED UPDATE --------------------- def deep_update ( self , original : dict , updates : dict ) -> dict : \"\"\"Recursively update a nested dictionary.\"\"\" for key , value in updates . items (): if isinstance ( value , dict ) and isinstance ( original . get ( key ), dict ): self . deep_update ( original [ key ], value ) else : original [ key ] = value return original def update_nested ( self , session_id : str , updates : dict [ str , Any ]) -> bool : state = self . get_session ( session_id ) if state is None : return False self . update_session ( session_id , self . deep_update ( state , updates )) return True","title":"SessionManager"},{"location":"database_and_schemas/other/#app.core.state.session_manager.SessionManager.clone_to_new_session","text":"Create a new Redis session from an existing project snapshot. Source code in app/core/state/session_manager.py 112 113 114 115 116 117 118 def clone_to_new_session ( self , session_data : dict ) -> str : \"\"\"Create a new Redis session from an existing project snapshot.\"\"\" new_id = str ( uuid . uuid4 ()) cloned_data = session_data . copy () # avoid mutating the original cloned_data [ \"restored_at\" ] = time . time () self . set_session ( new_id , cloned_data ) return new_id","title":"clone_to_new_session"},{"location":"database_and_schemas/other/#app.core.state.session_manager.SessionManager.create_session","text":"Create a new session with initial state and store in Redis. Source code in app/core/state/session_manager.py 30 31 32 33 34 35 36 37 38 39 40 41 def create_session ( self , initial_state : dict [ str , Any ], expire : int | None = EXPIRATION_SECONDS ) -> str : \"\"\"Create a new session with initial state and store in Redis.\"\"\" session_id = str ( uuid . uuid4 ()) redis_key = self . _build_key ( session_id ) # store in Redis (with optional expiry) self . redis_db . set_json ( redis_key , initial_state , expire = expire ) # Cache locally (fast access) self . session_cache [ session_id ] = initial_state self . latest_session_id = session_id return session_id","title":"create_session"},{"location":"database_and_schemas/other/#app.core.state.session_manager.SessionManager.deep_update","text":"Recursively update a nested dictionary. Source code in app/core/state/session_manager.py 121 122 123 124 125 126 127 128 def deep_update ( self , original : dict , updates : dict ) -> dict : \"\"\"Recursively update a nested dictionary.\"\"\" for key , value in updates . items (): if isinstance ( value , dict ) and isinstance ( original . get ( key ), dict ): self . deep_update ( original [ key ], value ) else : original [ key ] = value return original","title":"deep_update"},{"location":"database_and_schemas/other/#app.core.state.session_manager.SessionManager.delete_session","text":"Delete session from Redis. Source code in app/core/state/session_manager.py 79 80 81 82 83 84 85 86 87 def delete_session ( self , session_id : str ) -> bool : \"\"\"Delete session from Redis.\"\"\" redis_key = self . _build_key ( session_id ) result = self . redis_db . delete_key ( redis_key ) # Remove from local cache if it exists self . session_cache . pop ( session_id , None ) return result","title":"delete_session"},{"location":"database_and_schemas/other/#app.core.state.session_manager.SessionManager.get_all_sessions","text":"Return all active session IDs (based on key scan). Source code in app/core/state/session_manager.py 96 97 98 99 100 def get_all_sessions ( self ) -> list [ str ]: \"\"\"Return all active session IDs (based on key scan).\"\"\" pattern = f \" { self . REDIS_KEY_PREFIX } *\" keys = list ( self . redis_db . scan_keys ( pattern )) return [ key . replace ( self . REDIS_KEY_PREFIX , \"\" ) for key in keys ]","title":"get_all_sessions"},{"location":"database_and_schemas/other/#app.core.state.session_manager.SessionManager.get_session","text":"Get session from local cache first; fallback to Redis. Source code in app/core/state/session_manager.py 44 45 46 47 48 49 50 51 52 53 54 55 56 def get_session ( self , session_id : str ) -> Optional [ dict [ str , Any ]]: \"\"\"Get session from local cache first; fallback to Redis.\"\"\" # Try cache if session_id in self . session_cache : return self . session_cache [ session_id ] # Fallback to Redis redis_key = self . _build_key ( session_id ) data = self . redis_db . get_json ( redis_key ) if data : # Store in cache for future quick access self . session_cache [ session_id ] = data return data","title":"get_session"},{"location":"database_and_schemas/other/#app.core.state.session_manager.SessionManager.session_exists","text":"Check if session exists (cache or Redis). Source code in app/core/state/session_manager.py 89 90 91 92 93 94 def session_exists ( self , session_id : str ) -> bool : \"\"\"Check if session exists (cache or Redis).\"\"\" if session_id in self . session_cache : return True redis_key = self . _build_key ( session_id ) return self . redis_db . key_exists ( redis_key )","title":"session_exists"},{"location":"database_and_schemas/other/#app.core.state.session_manager.SessionManager.set_session","text":"Directly set or overwrite a session in Redis and local cache. Source code in app/core/state/session_manager.py 105 106 107 108 109 110 def set_session ( self , session_id : str , state : dict [ str , Any ], ttl : int | None = None ) -> None : \"\"\"Directly set or overwrite a session in Redis and local cache.\"\"\" redis_key = self . _build_key ( session_id ) self . redis_db . set_json ( redis_key , state , expire = ttl or self . EXPIRATION_SECONDS ) self . session_cache [ session_id ] = state self . latest_session_id = session_id","title":"set_session"},{"location":"database_and_schemas/other/#app.core.state.session_manager.SessionManager.update_session","text":"Update session in Redis and refresh local cache. Source code in app/core/state/session_manager.py 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 def update_session ( self , session_id : str , new_state : dict [ str , Any ]) -> bool : \"\"\"Update session in Redis and refresh local cache.\"\"\" redis_key = self . _build_key ( session_id ) # Fetch current state (cache or Redis) current_state = self . get_session ( session_id ) if current_state is None : return False # Merge updates current_state . update ( new_state ) # Save updated data back to Redis self . redis_db . set_json ( redis_key , current_state , expire = self . EXPIRATION_SECONDS ) # Refresh local cache self . session_cache [ session_id ] = current_state return True","title":"update_session"},{"location":"database_and_schemas/other/#state-utilities-internal-helpers","text":"Utility functions used for cleaning, merging, and structuring backend state.","title":"\ud83e\udde9 State Utilities \u2014 Internal Helpers"},{"location":"database_and_schemas/other/#app.core.state.utils.state_utils.deep_update","text":"Recursively update a nested dictionary. Source code in app/core/state/utils/state_utils.py 5 6 7 8 9 10 11 12 def deep_update ( original : dict , updates : dict ) -> dict : \"\"\"Recursively update a nested dictionary.\"\"\" for key , value in updates . items (): if isinstance ( value , dict ) and isinstance ( original . get ( key ), dict ): deep_update ( original [ key ], value ) else : original [ key ] = value return original","title":"deep_update"},{"location":"database_and_schemas/other/#app-configuration","text":"Centralized configuration loader for environment variables, constants, and system-wide settings.","title":"\ud83d\udd27 App Configuration"},{"location":"database_and_schemas/other/#error-handlers-unified-error-responses","text":"Custom exception handlers that ensure consistent error payloads across all APIs.","title":"\ud83d\udea8 Error Handlers \u2014 Unified Error Responses"},{"location":"database_and_schemas/other/#startup-utilities-initialization-logic","text":"Handles boot-time actions such as DB connections, cache initialization, and worker startup.","title":"\ud83d\ude80 Startup Utilities \u2014 Initialization Logic"},{"location":"database_and_schemas/other/#application-entry-point-fastapi-app-loader","text":"Main FastAPI instance, router registry, middleware loading, and lifecycle events.","title":"\ud83c\udfc1 Application Entry Point \u2014 FastAPI App Loader"},{"location":"database_and_schemas/other/#app.main.main","text":"CLI entrypoint for running the FastAPI app via uv run app . Source code in app/main.py 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 def main (): \"\"\"CLI entrypoint for running the FastAPI app via `uv run app`.\"\"\" from regulatory.utils.logger import log_config , logger_service as logger import uvicorn logger . info ( \"Starting Regulatory AI FastAPI Backend with uvicorn...\" ) uvicorn . run ( \"regulatory.app.main:app\" , host = \"0.0.0.0\" , port = 8765 , reload = True , log_config = log_config , log_level = \"info\" , )","title":"main"},{"location":"database_and_schemas/schemas/","text":"Models Reference This page lists all data models inside 'app.models' the package. \ud83e\udde9 Base Models BaseRequestModel Bases: BaseModel Common base for all request models. Source code in app/models/base.py 9 10 11 12 13 14 15 16 17 class BaseRequestModel ( BaseModel ): \"\"\"Common base for all request models.\"\"\" model_config = ConfigDict ( arbitrary_types_allowed = True , str_strip_whitespace = True , validate_assignment = True , json_schema_extra = { \"example\" : {}}, ) BaseResponseModel Bases: BaseModel Common base for all response models. Source code in app/models/base.py 20 21 22 23 24 25 class BaseResponseModel ( BaseModel ): \"\"\"Common base for all response models.\"\"\" model_config = ConfigDict ( json_schema_extra = { \"example\" : {}}, ) \ud83e\uddf1 Component Model ComponentSelectionRequest Bases: BaseRequestModel Request model for user component selections and additions. Cleans whitespace, validates duplicates, and enforces proper structure. Source code in app/models/component.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 class ComponentSelectionRequest ( BaseRequestModel ): \"\"\" Request model for user component selections and additions. Cleans whitespace, validates duplicates, and enforces proper structure. \"\"\" user_selected_components : list [ str ] = Field ( default_factory = list , description = \"Components selected from system recommendations\" , ) user_added_components : list [ str ] = Field ( default_factory = list , description = \"New user-added components not from system recommendations\" , ) # Clean each component name @field_validator ( \"user_selected_components\" , \"user_added_components\" , mode = \"before\" ) @classmethod def strip_and_validate ( cls , v ): if isinstance ( v , list ): cleaned = [] for item in v : if not isinstance ( item , str ): raise ValueError ( \"Each component must be a string.\" ) item = item . strip () if not item : raise ValueError ( \"Component name cannot be empty or whitespace.\" ) cleaned . append ( item ) return cleaned raise ValueError ( \"Expected a list of strings for components.\" ) # Ensure no duplicates across both fields @model_validator ( mode = \"after\" ) def ensure_no_duplicates ( self ): selected = set ( self . user_selected_components ) added = set ( self . user_added_components ) overlap = selected . intersection ( added ) if overlap : raise ValueError ( f \"Duplicate components found across selected and added: { ', ' . join ( overlap ) } \" ) # Optional: deduplicate within each list object . __setattr__ ( self , \"user_selected_components\" , list ( selected )) object . __setattr__ ( self , \"user_added_components\" , list ( added )) return self model_config = ConfigDict ( json_schema_extra = { \"example\" : { \"user_selected_components\" : [ \"Component A\" , \"Component B\" ], \"user_added_components\" : [ \"Component C\" ], } } ) \ud83d\udcdd Design Input Model DesignInputRequest Bases: BaseRequestModel Response model for getting available models. Source code in app/models/design_input.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 class DesignInputRequest ( BaseRequestModel ): \"\"\"Response model for getting available models.\"\"\" component_name : str = Field ( ... , description = \"Component name\" ) gspr_no : str = Field ( ... , description = \"GSPR clause number\" ) model_config = { \"json_schema_extra\" : { \"example\" : { \"component_name\" : \"ECG Module\" , \"gspr_no\" : \"23.2.d\" } } } DesignInputResponse Bases: BaseResponseModel Response model for design input data. Source code in app/models/design_input.py 23 24 25 26 27 28 29 30 class DesignInputResponse ( BaseResponseModel ): \"\"\"Response model for design input data.\"\"\" session_id : str = Field ( ... , description = \"Session ID\" ) component : str = Field ( ... , description = \"Component name\" ) requirement : str = Field ( ... , description = \"Requirement name associated with the GSPR clause\" ) gspr_text : str = Field ( ... , description = \"Text from GSPR clause\" ) standards : List [ StandardItem ] = Field ( ... , description = \"List of standards with justifications\" ) \ud83d\udcc4 Design Output Model DesignOutputRequest Bases: BaseRequestModel Request model for generating the Design Output Report. The system automatically uses design input data stored in the session. Users can optionally select specific components (or clauses, in future) to generate focused design outputs for those selections only. Source code in app/models/design_output.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 class DesignOutputRequest ( BaseRequestModel ): \"\"\" Request model for generating the Design Output Report. The system automatically uses design input data stored in the session. Users can optionally select specific components (or clauses, in future) to generate focused design outputs for those selections only. \"\"\" selected_components : Optional [ List [ str ]] = Field ( None , description = ( \"List of component names or identifiers selected by the user \" \"for Design Output generation. If not provided, all components \" \"in the session's design_input will be processed.\" ) ) DesignOutputResponse Bases: BaseResponseModel Response model containing the generated structured Design Output Reports. Source code in app/models/design_output.py 26 27 28 29 30 31 32 33 34 35 36 37 38 class DesignOutputResponse ( BaseResponseModel ): \"\"\" Response model containing the generated structured Design Output Reports. \"\"\" session_id : str = Field ( ... , description = \"Unique session identifier for which outputs were generated.\" ) output : Optional [ Dict [ str , Any ]] = Field ( None , description = ( \"Dictionary containing generated design outputs for each selected component. \" \"Each value includes the structured Design Output Report text or data aligned \" \"with ISO/IEC standards, GSPR traceability, and rationale.\" ) ) \ud83d\udce5 Device Input Model DeviceInputRequest Bases: BaseRequestModel Docstring for DeviceInputRequest Source code in app/models/device_input.py 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 class DeviceInputRequest ( BaseRequestModel ): \"\"\" Docstring for DeviceInputRequest \"\"\" medical_device : str = Field ( ... , description = \"Name of the medical device\" , ) intended_purpose : str = Field ( ... , description = \"Intended purpose of the device\" , ) material_type : list [ str ] = Field ( description = \"Materials used in the device (e.g. Plastic, Metal, Electronic Components, etc.),\" ) device_type : list [ str ] = Field ( description = \"Type of medical device (e.g. Non-active, Active, Implantable, IVD, etc.)\" ) model_config = ConfigDict ( json_schema_extra = { \"example\" : { \"medical_device\" : \"Blood Glucose Meter\" , \"intended_purpose\" : \"A device intended to measure blood glucose levels in diabetic patients.\" , \"material_type\" : [ \"Plastic\" , \"Electronic Components\" ], \"device_type\" : [ \"Non-active\" , \"IVD\" ], } } ) \ud83e\udded FDA Device Suggestions Model DeviceSuggestionRequest Bases: BaseRequestModel FDA Device Suggestion Request Model Source code in app/models/fda_device_suggestions.py 8 9 10 11 12 13 14 15 16 17 18 19 20 class DeviceSuggestionRequest ( BaseRequestModel ): \"\"\"FDA Device Suggestion Request Model\"\"\" device_name : str = Field ( ... , description = \"User input for device name search\" ) intended_purpose : str = Field ( ... , description = \"User input for intended purpose\" ) model_config = ConfigDict ( json_schema_extra = { \"example\" : { \"device_name\" : \"Stent\" , \"intended_purpose\" : \"Used to open narrowed blood vessels\" , } } ) \ud83c\udfd7\ufe0f GSPR Generator Model \ud83d\udcca GSPR Table Model \u2764\ufe0f Health Model \ud83d\udc64 Intended User Model IntendedUserResponse Bases: BaseResponseModel Response model for retrieving intended users for a given session. Source code in app/models/intended_user.py 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 class IntendedUserResponse ( BaseResponseModel ): \"\"\" Response model for retrieving intended users for a given session. \"\"\" session_id : str = Field ( ... , description = \"Unique session identifier\" ) intended_users : list [ str ] = Field ( default_factory = list , description = \"List of intended users retrieved from session\" , ) status : str = Field ( default = \"success\" , description = \"Status of the retrieval operation\" ) model_config = ConfigDict ( json_schema_extra = { \"example\" : { \"session_id\" : \"123e4567-e89b-12d3-a456-426614174000\" , \"intended_users\" : [ \"Healthcare Professionals\" , \"Patients\" ], \"status\" : \"success\" , } } ) IntendedUserUpdateRequest Bases: BaseRequestModel Request model for updating or submitting intended users. Validates string values and ensures unique entries. Source code in app/models/intended_user.py 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 class IntendedUserUpdateRequest ( BaseRequestModel ): \"\"\" Request model for updating or submitting intended users. Validates string values and ensures unique entries. \"\"\" intended_users : list [ str ] = Field ( default_factory = list , description = \"List of intended users for the device or product\" , ) # \ud83e\uddf9 Step 1: Clean whitespace and validate non-empty strings @field_validator ( \"intended_users\" , mode = \"before\" ) @classmethod def clean_and_validate_users ( cls , v ): if not isinstance ( v , list ): raise ValueError ( \"intended_users must be a list of strings.\" ) cleaned = [] for item in v : if not isinstance ( item , str ): raise ValueError ( \"Each intended user must be a string.\" ) item = item . strip () if not item : raise ValueError ( \"Intended user cannot be empty or whitespace.\" ) cleaned . append ( item ) return cleaned # \ud83d\udeab Step 2: Ensure no duplicates (case-insensitive) @model_validator ( mode = \"after\" ) def ensure_unique_users ( self ): normalized = [ u . lower () for u in self . intended_users ] if len ( normalized ) != len ( set ( normalized )): raise ValueError ( \"Duplicate intended users detected (case-insensitive).\" ) return self model_config = ConfigDict ( json_schema_extra = { \"example\" : { \"intended_users\" : [ \"Healthcare Professionals\" , \"Patients\" ], } } ) IntendedUserUpdateResponse Bases: BaseResponseModel Response after successfully updating intended users. Source code in app/models/intended_user.py 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 class IntendedUserUpdateResponse ( BaseResponseModel ): \"\"\" Response after successfully updating intended users. \"\"\" session_id : str = Field ( ... , description = \"Unique session identifier\" ) message : str = Field ( default = \"Intended users updated successfully.\" , description = \"Status message for the operation\" , ) model_config = ConfigDict ( json_schema_extra = { \"example\" : { \"session_id\" : \"123e4567-e89b-12d3-a456-426614174000\" , \"message\" : \"Intended users updated successfully.\" , } } ) \ud83e\udd16 LLM Models AvailableModelsResponse Bases: BaseResponseModel Response model for getting available models. Source code in app/models/llm_models.py 8 9 10 11 class AvailableModelsResponse ( BaseResponseModel ): \"\"\"Response model for getting available models.\"\"\" models : List [ str ] = Field ( ... , description = \"Available models\" ) current_model : str = Field ( ... , description = \"Currently selected model\" ) SetModelRequest Bases: BaseModel Request model for setting the selected model. Source code in app/models/llm_models.py 14 15 16 class SetModelRequest ( BaseModel ): \"\"\"Request model for setting the selected model.\"\"\" model : str = Field ( ... , description = \"Model ID to select\" ) SetModelResponse Bases: BaseResponseModel Response model for setting the selected model. Source code in app/models/llm_models.py 19 20 21 22 class SetModelResponse ( BaseResponseModel ): \"\"\"Response model for setting the selected model.\"\"\" model : str = Field ( ... , description = \"The model that was selected\" ) message : str = Field ( ... , description = \"Success message\" ) \ud83d\udccb Project Check Model \u26a0\ufe0f Risk Model RiskClassificationResponse Bases: BaseResponseModel Response model for retrieving full region-wise risk classifications. Includes both class and justification fields. Source code in app/models/risk.py 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 class RiskClassificationResponse ( BaseResponseModel ): \"\"\" Response model for retrieving full region-wise risk classifications. Includes both class and justification fields. \"\"\" session_id : str = Field ( ... , description = \"Unique session identifier\" ) risk_classification : dict [ str , dict [ str , str ]] = Field ( default_factory = dict , description = \"Region-wise risk classification (class + justification).\" , ) model_config = ConfigDict ( json_schema_extra = { \"example\" : { \"session_id\" : \"123e4567-e89b-12d3-a456-426614174000\" , \"risk_classification\" : { \"EU MDR\" : { \"class\" : \"Class IIa\" , \"justification\" : \"Based on intended use and duration of contact.\" , }, \"US FDA\" : { \"class\" : \"Class II\" , \"justification\" : \"Based on predicate devices and risk profile.\" , }, \"Indian MDR\" : { \"class\" : \"Class B\" , \"justification\" : \"Based on risk assessment criteria.\" , }, }, } } ) RiskClassificationUpdateRequest Bases: BaseRequestModel Request model for updating or submitting risk classifications. Each region maps to a classification string (e.g., 'Class IIa'). Source code in app/models/risk.py 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 class RiskClassificationUpdateRequest ( BaseRequestModel ): \"\"\" Request model for updating or submitting risk classifications. Each region maps to a classification string (e.g., 'Class IIa'). \"\"\" risk_classification : dict [ str , dict [ str , str ]] = Field ( default_factory = dict , description = \"Updated risk classification (region \u2192 {class} )\" , ) # \ud83e\uddf9 Step 1: Clean and validate input @field_validator ( \"risk_classification\" , mode = \"before\" ) @classmethod def validate_and_clean ( cls , v ): if not isinstance ( v , dict ): raise ValueError ( \"risk_classification must be a dictionary.\" ) cleaned = {} for region , data in v . items (): if not isinstance ( region , str ): raise ValueError ( \"Region names must be strings.\" ) if not isinstance ( data , dict ): raise ValueError ( \"Each region's value must be a dictionary.\" ) region_clean = region . strip () classification = data . get ( \"class\" , \"\" ) . strip () if not classification : raise ValueError ( f \"Missing or empty 'class' for region ' { region_clean } '.\" ) cleaned [ region_clean ] = { \"class\" : classification } return cleaned # \ud83d\udeab Step 2: Ensure unique regions (case-insensitive) @model_validator ( mode = \"after\" ) def ensure_unique_regions ( self ): lower_keys = [ r . lower () for r in self . risk_classification . keys ()] if len ( lower_keys ) != len ( set ( lower_keys )): raise ValueError ( \"Duplicate region names detected (case-insensitive).\" ) return self model_config = ConfigDict ( json_schema_extra = { \"example\" : { \"risk_classification\" : { \"EU MDR\" : { \"class\" : \"Class IIa\" }, \"US FDA\" : { \"class\" : \"Class II\" }, \"Indian MDR\" : { \"class\" : \"Class B\" }, } } } ) RiskClassificationUpdateResponse Bases: BaseResponseModel Response after successfully updating risk classifications. Source code in app/models/risk.py 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 class RiskClassificationUpdateResponse ( BaseResponseModel ): \"\"\" Response after successfully updating risk classifications. \"\"\" session_id : str = Field ( ... , description = \"Unique session identifier\" ) message : str = Field ( default = \"Risk classifications updated successfully.\" , description = \"Status message for update operation\" , ) model_config = ConfigDict ( json_schema_extra = { \"example\" : { \"session_id\" : \"123e4567-e89b-12d3-a456-426614174000\" , \"message\" : \"Risk classifications updated successfully.\" , } } ) \ud83d\uddc2\ufe0f Session Model","title":"APIs Response Schemas"},{"location":"database_and_schemas/schemas/#models-reference","text":"This page lists all data models inside 'app.models' the package.","title":"Models Reference"},{"location":"database_and_schemas/schemas/#base-models","text":"","title":"\ud83e\udde9 Base Models"},{"location":"database_and_schemas/schemas/#app.models.base.BaseRequestModel","text":"Bases: BaseModel Common base for all request models. Source code in app/models/base.py 9 10 11 12 13 14 15 16 17 class BaseRequestModel ( BaseModel ): \"\"\"Common base for all request models.\"\"\" model_config = ConfigDict ( arbitrary_types_allowed = True , str_strip_whitespace = True , validate_assignment = True , json_schema_extra = { \"example\" : {}}, )","title":"BaseRequestModel"},{"location":"database_and_schemas/schemas/#app.models.base.BaseResponseModel","text":"Bases: BaseModel Common base for all response models. Source code in app/models/base.py 20 21 22 23 24 25 class BaseResponseModel ( BaseModel ): \"\"\"Common base for all response models.\"\"\" model_config = ConfigDict ( json_schema_extra = { \"example\" : {}}, )","title":"BaseResponseModel"},{"location":"database_and_schemas/schemas/#component-model","text":"","title":"\ud83e\uddf1 Component Model"},{"location":"database_and_schemas/schemas/#app.models.component.ComponentSelectionRequest","text":"Bases: BaseRequestModel Request model for user component selections and additions. Cleans whitespace, validates duplicates, and enforces proper structure. Source code in app/models/component.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 class ComponentSelectionRequest ( BaseRequestModel ): \"\"\" Request model for user component selections and additions. Cleans whitespace, validates duplicates, and enforces proper structure. \"\"\" user_selected_components : list [ str ] = Field ( default_factory = list , description = \"Components selected from system recommendations\" , ) user_added_components : list [ str ] = Field ( default_factory = list , description = \"New user-added components not from system recommendations\" , ) # Clean each component name @field_validator ( \"user_selected_components\" , \"user_added_components\" , mode = \"before\" ) @classmethod def strip_and_validate ( cls , v ): if isinstance ( v , list ): cleaned = [] for item in v : if not isinstance ( item , str ): raise ValueError ( \"Each component must be a string.\" ) item = item . strip () if not item : raise ValueError ( \"Component name cannot be empty or whitespace.\" ) cleaned . append ( item ) return cleaned raise ValueError ( \"Expected a list of strings for components.\" ) # Ensure no duplicates across both fields @model_validator ( mode = \"after\" ) def ensure_no_duplicates ( self ): selected = set ( self . user_selected_components ) added = set ( self . user_added_components ) overlap = selected . intersection ( added ) if overlap : raise ValueError ( f \"Duplicate components found across selected and added: { ', ' . join ( overlap ) } \" ) # Optional: deduplicate within each list object . __setattr__ ( self , \"user_selected_components\" , list ( selected )) object . __setattr__ ( self , \"user_added_components\" , list ( added )) return self model_config = ConfigDict ( json_schema_extra = { \"example\" : { \"user_selected_components\" : [ \"Component A\" , \"Component B\" ], \"user_added_components\" : [ \"Component C\" ], } } )","title":"ComponentSelectionRequest"},{"location":"database_and_schemas/schemas/#design-input-model","text":"","title":"\ud83d\udcdd Design Input Model"},{"location":"database_and_schemas/schemas/#app.models.design_input.DesignInputRequest","text":"Bases: BaseRequestModel Response model for getting available models. Source code in app/models/design_input.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 class DesignInputRequest ( BaseRequestModel ): \"\"\"Response model for getting available models.\"\"\" component_name : str = Field ( ... , description = \"Component name\" ) gspr_no : str = Field ( ... , description = \"GSPR clause number\" ) model_config = { \"json_schema_extra\" : { \"example\" : { \"component_name\" : \"ECG Module\" , \"gspr_no\" : \"23.2.d\" } } }","title":"DesignInputRequest"},{"location":"database_and_schemas/schemas/#app.models.design_input.DesignInputResponse","text":"Bases: BaseResponseModel Response model for design input data. Source code in app/models/design_input.py 23 24 25 26 27 28 29 30 class DesignInputResponse ( BaseResponseModel ): \"\"\"Response model for design input data.\"\"\" session_id : str = Field ( ... , description = \"Session ID\" ) component : str = Field ( ... , description = \"Component name\" ) requirement : str = Field ( ... , description = \"Requirement name associated with the GSPR clause\" ) gspr_text : str = Field ( ... , description = \"Text from GSPR clause\" ) standards : List [ StandardItem ] = Field ( ... , description = \"List of standards with justifications\" )","title":"DesignInputResponse"},{"location":"database_and_schemas/schemas/#design-output-model","text":"","title":"\ud83d\udcc4 Design Output Model"},{"location":"database_and_schemas/schemas/#app.models.design_output.DesignOutputRequest","text":"Bases: BaseRequestModel Request model for generating the Design Output Report. The system automatically uses design input data stored in the session. Users can optionally select specific components (or clauses, in future) to generate focused design outputs for those selections only. Source code in app/models/design_output.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 class DesignOutputRequest ( BaseRequestModel ): \"\"\" Request model for generating the Design Output Report. The system automatically uses design input data stored in the session. Users can optionally select specific components (or clauses, in future) to generate focused design outputs for those selections only. \"\"\" selected_components : Optional [ List [ str ]] = Field ( None , description = ( \"List of component names or identifiers selected by the user \" \"for Design Output generation. If not provided, all components \" \"in the session's design_input will be processed.\" ) )","title":"DesignOutputRequest"},{"location":"database_and_schemas/schemas/#app.models.design_output.DesignOutputResponse","text":"Bases: BaseResponseModel Response model containing the generated structured Design Output Reports. Source code in app/models/design_output.py 26 27 28 29 30 31 32 33 34 35 36 37 38 class DesignOutputResponse ( BaseResponseModel ): \"\"\" Response model containing the generated structured Design Output Reports. \"\"\" session_id : str = Field ( ... , description = \"Unique session identifier for which outputs were generated.\" ) output : Optional [ Dict [ str , Any ]] = Field ( None , description = ( \"Dictionary containing generated design outputs for each selected component. \" \"Each value includes the structured Design Output Report text or data aligned \" \"with ISO/IEC standards, GSPR traceability, and rationale.\" ) )","title":"DesignOutputResponse"},{"location":"database_and_schemas/schemas/#device-input-model","text":"","title":"\ud83d\udce5 Device Input Model"},{"location":"database_and_schemas/schemas/#app.models.device_input.DeviceInputRequest","text":"Bases: BaseRequestModel Docstring for DeviceInputRequest Source code in app/models/device_input.py 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 class DeviceInputRequest ( BaseRequestModel ): \"\"\" Docstring for DeviceInputRequest \"\"\" medical_device : str = Field ( ... , description = \"Name of the medical device\" , ) intended_purpose : str = Field ( ... , description = \"Intended purpose of the device\" , ) material_type : list [ str ] = Field ( description = \"Materials used in the device (e.g. Plastic, Metal, Electronic Components, etc.),\" ) device_type : list [ str ] = Field ( description = \"Type of medical device (e.g. Non-active, Active, Implantable, IVD, etc.)\" ) model_config = ConfigDict ( json_schema_extra = { \"example\" : { \"medical_device\" : \"Blood Glucose Meter\" , \"intended_purpose\" : \"A device intended to measure blood glucose levels in diabetic patients.\" , \"material_type\" : [ \"Plastic\" , \"Electronic Components\" ], \"device_type\" : [ \"Non-active\" , \"IVD\" ], } } )","title":"DeviceInputRequest"},{"location":"database_and_schemas/schemas/#fda-device-suggestions-model","text":"","title":"\ud83e\udded FDA Device Suggestions Model"},{"location":"database_and_schemas/schemas/#app.models.fda_device_suggestions.DeviceSuggestionRequest","text":"Bases: BaseRequestModel FDA Device Suggestion Request Model Source code in app/models/fda_device_suggestions.py 8 9 10 11 12 13 14 15 16 17 18 19 20 class DeviceSuggestionRequest ( BaseRequestModel ): \"\"\"FDA Device Suggestion Request Model\"\"\" device_name : str = Field ( ... , description = \"User input for device name search\" ) intended_purpose : str = Field ( ... , description = \"User input for intended purpose\" ) model_config = ConfigDict ( json_schema_extra = { \"example\" : { \"device_name\" : \"Stent\" , \"intended_purpose\" : \"Used to open narrowed blood vessels\" , } } )","title":"DeviceSuggestionRequest"},{"location":"database_and_schemas/schemas/#gspr-generator-model","text":"","title":"\ud83c\udfd7\ufe0f GSPR Generator Model"},{"location":"database_and_schemas/schemas/#gspr-table-model","text":"","title":"\ud83d\udcca GSPR Table Model"},{"location":"database_and_schemas/schemas/#health-model","text":"","title":"\u2764\ufe0f Health Model"},{"location":"database_and_schemas/schemas/#intended-user-model","text":"","title":"\ud83d\udc64 Intended User Model"},{"location":"database_and_schemas/schemas/#app.models.intended_user.IntendedUserResponse","text":"Bases: BaseResponseModel Response model for retrieving intended users for a given session. Source code in app/models/intended_user.py 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 class IntendedUserResponse ( BaseResponseModel ): \"\"\" Response model for retrieving intended users for a given session. \"\"\" session_id : str = Field ( ... , description = \"Unique session identifier\" ) intended_users : list [ str ] = Field ( default_factory = list , description = \"List of intended users retrieved from session\" , ) status : str = Field ( default = \"success\" , description = \"Status of the retrieval operation\" ) model_config = ConfigDict ( json_schema_extra = { \"example\" : { \"session_id\" : \"123e4567-e89b-12d3-a456-426614174000\" , \"intended_users\" : [ \"Healthcare Professionals\" , \"Patients\" ], \"status\" : \"success\" , } } )","title":"IntendedUserResponse"},{"location":"database_and_schemas/schemas/#app.models.intended_user.IntendedUserUpdateRequest","text":"Bases: BaseRequestModel Request model for updating or submitting intended users. Validates string values and ensures unique entries. Source code in app/models/intended_user.py 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 class IntendedUserUpdateRequest ( BaseRequestModel ): \"\"\" Request model for updating or submitting intended users. Validates string values and ensures unique entries. \"\"\" intended_users : list [ str ] = Field ( default_factory = list , description = \"List of intended users for the device or product\" , ) # \ud83e\uddf9 Step 1: Clean whitespace and validate non-empty strings @field_validator ( \"intended_users\" , mode = \"before\" ) @classmethod def clean_and_validate_users ( cls , v ): if not isinstance ( v , list ): raise ValueError ( \"intended_users must be a list of strings.\" ) cleaned = [] for item in v : if not isinstance ( item , str ): raise ValueError ( \"Each intended user must be a string.\" ) item = item . strip () if not item : raise ValueError ( \"Intended user cannot be empty or whitespace.\" ) cleaned . append ( item ) return cleaned # \ud83d\udeab Step 2: Ensure no duplicates (case-insensitive) @model_validator ( mode = \"after\" ) def ensure_unique_users ( self ): normalized = [ u . lower () for u in self . intended_users ] if len ( normalized ) != len ( set ( normalized )): raise ValueError ( \"Duplicate intended users detected (case-insensitive).\" ) return self model_config = ConfigDict ( json_schema_extra = { \"example\" : { \"intended_users\" : [ \"Healthcare Professionals\" , \"Patients\" ], } } )","title":"IntendedUserUpdateRequest"},{"location":"database_and_schemas/schemas/#app.models.intended_user.IntendedUserUpdateResponse","text":"Bases: BaseResponseModel Response after successfully updating intended users. Source code in app/models/intended_user.py 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 class IntendedUserUpdateResponse ( BaseResponseModel ): \"\"\" Response after successfully updating intended users. \"\"\" session_id : str = Field ( ... , description = \"Unique session identifier\" ) message : str = Field ( default = \"Intended users updated successfully.\" , description = \"Status message for the operation\" , ) model_config = ConfigDict ( json_schema_extra = { \"example\" : { \"session_id\" : \"123e4567-e89b-12d3-a456-426614174000\" , \"message\" : \"Intended users updated successfully.\" , } } )","title":"IntendedUserUpdateResponse"},{"location":"database_and_schemas/schemas/#llm-models","text":"","title":"\ud83e\udd16 LLM Models"},{"location":"database_and_schemas/schemas/#app.models.llm_models.AvailableModelsResponse","text":"Bases: BaseResponseModel Response model for getting available models. Source code in app/models/llm_models.py 8 9 10 11 class AvailableModelsResponse ( BaseResponseModel ): \"\"\"Response model for getting available models.\"\"\" models : List [ str ] = Field ( ... , description = \"Available models\" ) current_model : str = Field ( ... , description = \"Currently selected model\" )","title":"AvailableModelsResponse"},{"location":"database_and_schemas/schemas/#app.models.llm_models.SetModelRequest","text":"Bases: BaseModel Request model for setting the selected model. Source code in app/models/llm_models.py 14 15 16 class SetModelRequest ( BaseModel ): \"\"\"Request model for setting the selected model.\"\"\" model : str = Field ( ... , description = \"Model ID to select\" )","title":"SetModelRequest"},{"location":"database_and_schemas/schemas/#app.models.llm_models.SetModelResponse","text":"Bases: BaseResponseModel Response model for setting the selected model. Source code in app/models/llm_models.py 19 20 21 22 class SetModelResponse ( BaseResponseModel ): \"\"\"Response model for setting the selected model.\"\"\" model : str = Field ( ... , description = \"The model that was selected\" ) message : str = Field ( ... , description = \"Success message\" )","title":"SetModelResponse"},{"location":"database_and_schemas/schemas/#project-check-model","text":"","title":"\ud83d\udccb Project Check Model"},{"location":"database_and_schemas/schemas/#risk-model","text":"","title":"\u26a0\ufe0f Risk Model"},{"location":"database_and_schemas/schemas/#app.models.risk.RiskClassificationResponse","text":"Bases: BaseResponseModel Response model for retrieving full region-wise risk classifications. Includes both class and justification fields. Source code in app/models/risk.py 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 class RiskClassificationResponse ( BaseResponseModel ): \"\"\" Response model for retrieving full region-wise risk classifications. Includes both class and justification fields. \"\"\" session_id : str = Field ( ... , description = \"Unique session identifier\" ) risk_classification : dict [ str , dict [ str , str ]] = Field ( default_factory = dict , description = \"Region-wise risk classification (class + justification).\" , ) model_config = ConfigDict ( json_schema_extra = { \"example\" : { \"session_id\" : \"123e4567-e89b-12d3-a456-426614174000\" , \"risk_classification\" : { \"EU MDR\" : { \"class\" : \"Class IIa\" , \"justification\" : \"Based on intended use and duration of contact.\" , }, \"US FDA\" : { \"class\" : \"Class II\" , \"justification\" : \"Based on predicate devices and risk profile.\" , }, \"Indian MDR\" : { \"class\" : \"Class B\" , \"justification\" : \"Based on risk assessment criteria.\" , }, }, } } )","title":"RiskClassificationResponse"},{"location":"database_and_schemas/schemas/#app.models.risk.RiskClassificationUpdateRequest","text":"Bases: BaseRequestModel Request model for updating or submitting risk classifications. Each region maps to a classification string (e.g., 'Class IIa'). Source code in app/models/risk.py 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 class RiskClassificationUpdateRequest ( BaseRequestModel ): \"\"\" Request model for updating or submitting risk classifications. Each region maps to a classification string (e.g., 'Class IIa'). \"\"\" risk_classification : dict [ str , dict [ str , str ]] = Field ( default_factory = dict , description = \"Updated risk classification (region \u2192 {class} )\" , ) # \ud83e\uddf9 Step 1: Clean and validate input @field_validator ( \"risk_classification\" , mode = \"before\" ) @classmethod def validate_and_clean ( cls , v ): if not isinstance ( v , dict ): raise ValueError ( \"risk_classification must be a dictionary.\" ) cleaned = {} for region , data in v . items (): if not isinstance ( region , str ): raise ValueError ( \"Region names must be strings.\" ) if not isinstance ( data , dict ): raise ValueError ( \"Each region's value must be a dictionary.\" ) region_clean = region . strip () classification = data . get ( \"class\" , \"\" ) . strip () if not classification : raise ValueError ( f \"Missing or empty 'class' for region ' { region_clean } '.\" ) cleaned [ region_clean ] = { \"class\" : classification } return cleaned # \ud83d\udeab Step 2: Ensure unique regions (case-insensitive) @model_validator ( mode = \"after\" ) def ensure_unique_regions ( self ): lower_keys = [ r . lower () for r in self . risk_classification . keys ()] if len ( lower_keys ) != len ( set ( lower_keys )): raise ValueError ( \"Duplicate region names detected (case-insensitive).\" ) return self model_config = ConfigDict ( json_schema_extra = { \"example\" : { \"risk_classification\" : { \"EU MDR\" : { \"class\" : \"Class IIa\" }, \"US FDA\" : { \"class\" : \"Class II\" }, \"Indian MDR\" : { \"class\" : \"Class B\" }, } } } )","title":"RiskClassificationUpdateRequest"},{"location":"database_and_schemas/schemas/#app.models.risk.RiskClassificationUpdateResponse","text":"Bases: BaseResponseModel Response after successfully updating risk classifications. Source code in app/models/risk.py 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 class RiskClassificationUpdateResponse ( BaseResponseModel ): \"\"\" Response after successfully updating risk classifications. \"\"\" session_id : str = Field ( ... , description = \"Unique session identifier\" ) message : str = Field ( default = \"Risk classifications updated successfully.\" , description = \"Status message for update operation\" , ) model_config = ConfigDict ( json_schema_extra = { \"example\" : { \"session_id\" : \"123e4567-e89b-12d3-a456-426614174000\" , \"message\" : \"Risk classifications updated successfully.\" , } } )","title":"RiskClassificationUpdateResponse"},{"location":"database_and_schemas/schemas/#session-model","text":"","title":"\ud83d\uddc2\ufe0f Session Model"}]}